<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,shrink-to-fit=no"><link rel="icon" href="/assets/images/logo.png"><title>Concurrency in modern programming languages: Rust | Technorage</title><meta name="generator" content="Jekyll v4.1.1"><meta property="og:title" content="Concurrency in modern programming languages: Rust"><meta name="author" content="deepu"><meta property="og:locale" content="en_US"><meta name="description" content="Building a concurrent web server in Rust to compare concurrency performance with Go, JS, TS, Kotlin, and Java"><meta property="og:description" content="Building a concurrent web server in Rust to compare concurrency performance with Go, JS, TS, Kotlin, and Java"><link rel="canonical" href="https://deepu.tech/concurrency-in-modern-languages-rust/"><meta property="og:url" content="https://deepu.tech/concurrency-in-modern-languages-rust/"><meta property="og:site_name" content="Technorage"><meta property="og:type" content="article"><meta property="article:published_time" content="2020-12-24T00:00:00+01:00"><meta name="twitter:card" content="summary"><meta property="twitter:title" content="Concurrency in modern programming languages: Rust"><script type="application/ld+json">{"author":{"@type":"Person","name":"deepu"},"description":"Building a concurrent web server in Rust to compare concurrency performance with Go, JS, TS, Kotlin, and Java","headline":"Concurrency in modern programming languages: Rust","dateModified":"2020-12-24T00:00:00+01:00","datePublished":"2020-12-24T00:00:00+01:00","@type":"BlogPosting","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://deepu.tech/assets/images/logo.png"},"name":"deepu"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://deepu.tech/concurrency-in-modern-languages-rust/"},"url":"https://deepu.tech/concurrency-in-modern-languages-rust/","@context":"https://schema.org"}</script><link rel="canonical" href="https://deepu.tech/concurrency-in-modern-languages-rust/"><meta property="og:url" content=""><meta name="monetization" content="$ilp.uphold.com/Aw7eGpxKNyK7"><meta name="twitter:site" content="@deepu105"><meta name="twitter:creator" content="@deepu105"><meta name="twitter:title" content="Concurrency in modern programming languages: Rust"><meta name="twitter:description" content="Building a concurrent web server in Rust to compare concurrency performance with Go, JS, TS, Kotlin, and Java"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="https://i.imgur.com/XalVFUX.jpg"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.4.1/css/bootstrap.min.css" integrity="sha256-L/W5Wfqfa0sdBNIKN9cG6QA5F2qx4qICmU2VgLruv9Y=" crossorigin="anonymous"><link href="/assets/css/screen.css" rel="stylesheet"><link href="/assets/css/main.css" rel="stylesheet"></head><body class="layout-post"><noscript id="deferred-styles"><link href="https://fonts.googleapis.com/css?family=Righteous%7CMerriweather:300,300i,400,400i,700,700i" rel="stylesheet"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.9.0/css/all.css" crossorigin="anonymous"></noscript><nav class="navbar navbar-expand-lg navbar-light bg-white fixed-top mediumnavigation nav-down pr-md-0 pl-md-0"><div class="container d-flex align-items-center"><a class="navbar-brand" href="/"><h2>Deepu K Sasidharan</h2></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarMediumish" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarMediumish"><ul class="navbar-nav ml-auto"><li class="nav-item"><a class="nav-link" href="/">About</a></li><li class="nav-item active"><a class="nav-link" href="/blogs/"><i class="fas fa-blog"></i> Blog</a></li><li class="nav-item"><a class="nav-link" href="/books"><i class="fas fa-book"></i> Books</a></li><li class="nav-item"><a target="_blank" class="nav-link" href="https://www.youtube.com/playlist?list=PLxayiD7e52nPpb-sSaoOPc-zXGhmOaNHK"><i class="fab fa-youtube"></i> Videos</a></li><li class="nav-item"><a target="_blank" class="nav-link" href="https://speakerdeck.com/deepu105"><i class="fab fa-speaker-deck"></i> Presentations</a></li><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.slim.min.js" integrity="sha256-pasqAKBDmFT4eHoN2ndd6lN370kFiGUFyTiUHWhU7k8=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.8/lunr.min.js" integrity="sha256-34Si1Y6llMBKM3G0jQILVeoQKEwuxjbk4zGWXXMT4ps=" crossorigin="anonymous"></script><style>.lunrsearchresult .title {color: #d9230f;}
    .lunrsearchresult .url {color: silver;}
    .lunrsearchresult a {display: block; color: #777;}
    .lunrsearchresult a:hover, .lunrsearchresult a:focus {text-decoration: none;}
    .lunrsearchresult a:hover .title {text-decoration: underline;}</style><form class="bd-search" onsubmit="return lunr_search(document.getElementById('lunrsearch').value);"><input type="text" class="form-control text-small launch-modal-search" id="lunrsearch" name="q" maxlength="255" value="" placeholder="Type and enter..."></form><div id="lunrsearchresults"><ul></ul></div><script src="/assets/js/lunrsearchengine.js"></script></ul></div></div></nav><div class="site-content"><div class="container"><div class="main-content"><div class="mainheading"><h1 class="sitetitle">Technorage</h1><p class="lead">Where I rage about technology and stuff!</p></div><div class="container"><div class="row"><div class="col-lg-2 pl-0"><div class="sticky-top sticky-top-offset"><div class="popover-wrapper d-none d-lg-block"><a href="#"><h2 class="popover-title"><i class="fas fa-stream fa-lg"></i> TOC</h2></a><div class="popover-content"><div class="toc lead"><h3 class="font-weight-bold">Summary</h3><ul><li><a href="#concurrency-in-rust">Concurrency in Rust</a><ul><li><a href="#multi-threading"><a href="https://doc.rust-lang.org/book/ch16-00-concurrency.html">Multi-threading</a></a></li><li><a href="#asynchronous-processing"><a href="https://rust-lang.github.io/async-book/01_getting_started/01_chapter.html">Asynchronous processing</a></a></li></ul></li><li><a href="#benchmarking">Benchmarking</a><ul><li><a href="#multi-threaded-concurrent-webserver">Multi-threaded concurrent webserver</a></li><li><a href="#asynchronous-concurrent-webserver">Asynchronous concurrent webserver</a></li><li><a href="#asynchronous-multi-threaded-concurrent-webserver">Asynchronous multi-threaded concurrent webserver</a></li><li><a href="#asynchronous-multi-threaded-concurrent-webserver-with-tokio">Asynchronous multi-threaded concurrent webserver with Tokio</a></li></ul></li><li><a href="#conclusion">Conclusion</a></li><li><a href="#references">References</a></li></ul></div></div></div><div class="share"><p>Share</p><ul><li class="ml-1 mr-1"><a target="_blank" href="https://twitter.com/intent/tweet?text=Concurrency in modern programming languages: Rust by @deepu105 &url=https://deepu.tech/concurrency-in-modern-languages-rust/" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;" title="Twitter"><i class="fab fa-twitter"></i></a></li><li class="ml-1 mr-1"><a target="_blank" href="https://www.linkedin.com/shareArticle?mini=true&url=https://deepu.tech/concurrency-in-modern-languages-rust/" onclick="window.open(this.href, 'linkedin-share', 'width=550,height=435');return false;" title="Linkedin"><i class="fab fa-linkedin-in"></i></a></li><li class="ml-1 mr-1"><a target="_blank" href="https://news.ycombinator.com/submitlink?u=https://deepu.tech/concurrency-in-modern-languages-rust/&t=Concurrency in modern programming languages: Rust" onclick="window.open(this.href, 'hackernews-share', 'width=550,height=435');return false;" title="Hacker News"><i class="fab fa-hacker-news-square"></i></a></li><li class="ml-1 mr-1"><a target="_blank" href="https://www.reddit.com/submit?url=https://deepu.tech/concurrency-in-modern-languages-rust/&title=Concurrency in modern programming languages: Rust" onclick="window.open(this.href, 'reddit-share', 'width=550,height=435');return false;" title="Reddit"><i class="fab fa-reddit-square"></i></a></li><li class="ml-1 mr-1"><a target="_blank" href="https://facebook.com/sharer.php?u=https://deepu.tech/concurrency-in-modern-languages-rust/" onclick="window.open(this.href, 'facebook-share', 'width=550,height=435');return false;" title="Facebook"><i class="fab fa-facebook-f"></i></a></li></ul><div class="sep"></div><ul><li><a class="small smoothscroll" href="#disqus_thread"></a></li></ul></div><div class="ad-vertical-md"><script async type="text/javascript" src="//cdn.carbonads.com/carbon.js?serve=CE7ITK3I&placement=deeputech" id="_carbonads_js"></script></div></div></div><div class="col-lg-9 flex-first flex-lg-unordered"><div class="mainheading"><h1 class="posttitle">Concurrency in modern programming languages: Rust</h1><img data-src="https://i.imgur.com/XalVFUX.jpg" alt="Concurrency in modern programming languages: Rust" class="featured-image img-fluid lozad" src="/assets/images/placeholder.jpg"><div class="row post-top-meta"><div class="col-12 text-center text-md-left mb-4 mb-md-0"><img class="author-thumb lozad" src="/assets/images/placeholder.jpg" data-src="https://www.gravatar.com/avatar/7f408bc67dc9ae3b288ee92d16d3c4c2?s=250&d=mm&r=x" alt="Deepu K Sasidharan"> <a target="_blank" class="link-dark" href="https://www.deepu.tech">Deepu K Sasidharan</a><a target="_blank" href="https://twitter.com/deepu105" class="btn follow">Follow</a><span class="separator d-none d-md-inline-block">| </span><span class="author-description"><small><time class="post-date" datetime="2020-12-24">24 Dec 2020</time> </small><span class="separator d-inline-block">| </span><small>21 mins read</small> <span class="separator d-inline-block d-lg-none">| </span><span class="d-inline-block d-lg-none"><div class="share" style="margin-top: 0;"><ul><li class="ml-1 mr-1"><a target="_blank" href="https://twitter.com/intent/tweet?text=Concurrency in modern programming languages: Rust by @deepu105 &url=https://deepu.tech/concurrency-in-modern-languages-rust/" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;" title="Twitter"><i class="fab fa-twitter"></i></a></li><li class="ml-1 mr-1"><a target="_blank" href="https://www.linkedin.com/shareArticle?mini=true&url=https://deepu.tech/concurrency-in-modern-languages-rust/" onclick="window.open(this.href, 'linkedin-share', 'width=550,height=435');return false;" title="Linkedin"><i class="fab fa-linkedin-in"></i></a></li><li class="ml-1 mr-1"><a target="_blank" href="https://news.ycombinator.com/submitlink?u=https://deepu.tech/concurrency-in-modern-languages-rust/&t=Concurrency in modern programming languages: Rust" onclick="window.open(this.href, 'hackernews-share', 'width=550,height=435');return false;" title="Hacker News"><i class="fab fa-hacker-news-square"></i></a></li><li class="ml-1 mr-1"><a target="_blank" href="https://www.reddit.com/submit?url=https://deepu.tech/concurrency-in-modern-languages-rust/&title=Concurrency in modern programming languages: Rust" onclick="window.open(this.href, 'reddit-share', 'width=550,height=435');return false;" title="Reddit"><i class="fab fa-reddit-square"></i></a></li><li class="ml-1 mr-1"><a target="_blank" href="https://facebook.com/sharer.php?u=https://deepu.tech/concurrency-in-modern-languages-rust/" onclick="window.open(this.href, 'facebook-share', 'width=550,height=435');return false;" title="Facebook"><i class="fab fa-facebook-f"></i></a></li></ul></div></span></span></div></div></div><div class="panel series-wrapper"><p><strong>Part of "concurrency in modern programming languages" series</strong></p><div class="article-collection"><a href="/concurrency-in-modern-languages/" title="Part 1: Concurrency in modern programming languages: Introduction"></a> <a href="/concurrency-in-modern-languages-rust/" title="Part 2: Concurrency in modern programming languages: Rust" class="current-article"></a> <a href="/concurrency-in-modern-languages-go/" title="Part 3: Concurrency in modern programming languages: Golang"></a> <a href="/concurrency-in-modern-languages-js/" title="Part 4: Concurrency in modern programming languages: JavaScript on NodeJS"></a> <a href="/concurrency-in-modern-languages-ts/" title="Part 5: Concurrency in modern programming languages: TypeScript on Deno"></a></div></div><div class="article-post"><p>Please follow me on <a href="https://twitter.com/deepu105">Twitter</a> for updates and let me know what can be improved in the post.</p><hr><p>This is a multi-part series where I’ll be talking about concurrency in modern programming languages and will be building and benchmarking a concurrent web server, inspired by the example from the <a href="https://doc.rust-lang.org/book/ch20-00-final-project-a-web-server.html">Rust book</a>, in popular languages like Rust, Go, JavaScript (NodeJS), TypeScript (Deno), Kotlin and Java to compare concurrency and its performance between these languages/platforms. The chapters of this series are as below and I’ll try to publish them weekly.</p><ol><li><a href="https://deepu.tech/concurrency-in-modern-languages/">Introduction</a></li><li><strong>Concurrent web server in Rust</strong></li><li><a href="https://deepu.tech/concurrency-in-modern-languages-go/">Concurrent web server in Golang</a></li><li><a href="https://deepu.tech/concurrency-in-modern-languages-js/">Concurrent web server in JavaScript with NodeJS</a></li><li><a href="https://deepu.tech/concurrency-in-modern-languages-ts/">Concurrent web server in TypeScript with Deno</a></li><li>Concurrent web server in Java with JVM</li><li>Concurrent web server in Kotlin with JVM</li><li>Comparison and conclusion of benchmarks</li></ol><hr><h2 id="concurrency-in-rust">Concurrency in Rust</h2><blockquote><p>Handling concurrent programming safely and efficiently is another of Rust’s major goals.</p><p>– Rust docs</p></blockquote><p>Efficient and memory safe concurrency is one of the major goals of Rust and these are not just plain words, the language offers great features for concurrent programming and when combined with the best in class memory safety model makes it a great choice for concurrency use cases. As with everything else in Rust, the idea is that you spend more time upfront (read compile-time) fixing issues rather than spending time fixing issues in production (read runtime). So if you are new to Rust it might look like more time spent on writing code but it will considerable effort later on by avoiding a lot of issues that generally pop up in languages with not-so-great memory safety. The Rust team calls this <strong>“fearless concurrency”</strong>.</p><blockquote><p>As with everything else in Rust the idea is that you spend more time upfront (read compile-time) fixing issues rather than spending time fixing issues in production (read runtime).</p></blockquote><p>There are other languages like Go, which offers simpler and equally performant solutions for concurrency but they aren’t as powerful as Rust due to the flexibility offered by Rust. Basically, Rust provides you with building blocks required for concurrent, parallel, and asynchronous programming and you can extend or implement different solutions as you see fit or use a solution offered by the community. This allows for one to use the best possible solution for the use case rather than using the same hammer for all jobs.</p><p>With Rust, it’s possible to do multi-threaded concurrency or parallel programming as well as asynchronous programming. This means as we saw in the <a href="https://deepu.tech/concurrency-in-modern-languages/">previous chapter</a>, we can mix and match these models to get the best possible performance for any use case.</p><h3 id="multi-threading"><a href="https://doc.rust-lang.org/book/ch16-00-concurrency.html">Multi-threading</a></h3><p>Rust provides building blocks to create and manage OS threads as part of the standard library and it also provides implementations required for <a href="https://doc.rust-lang.org/book/ch16-02-message-passing.html">message-passing concurrency</a> (similar to Go) using channels and <a href="https://doc.rust-lang.org/book/ch16-03-shared-state.html#using-mutexes-to-allow-access-to-data-from-one-thread-at-a-time">shared-state concurrency</a> using Mutexes and Smart pointers. Rust’s type system and ownership model helps to avoid common concurrency issues like data race, locks, etc.</p><h3 id="asynchronous-processing"><a href="https://rust-lang.github.io/async-book/01_getting_started/01_chapter.html">Asynchronous processing</a></h3><p>Technically asynchronous programming is not part of concurrency but in practice, it goes hand in hand for many use cases and improves performance, and makes resource usage more efficient. The latest versions of Rust provides building blocks and language features required for asynchronous programming with the <code class="language-plaintext highlighter-rouge">async/.await</code> syntax. But do keep in mind that using an asynchronous programming model increases the overall complexity and the ecosystem is still evolving. While Rust provides the language features required the standard library doesn’t provide any implementations needed and hence you would have to use an external crate like <code class="language-plaintext highlighter-rouge">Futures</code> to be able to use the asynchronous programming model effectively.</p><h2 id="benchmarking">Benchmarking</h2><p>Now that we have some basic understanding of concurrency features in Rust, let us build a simple concurrent webserver in Rust. Since Rust offers multiple ways to achieve this we’ll be building three sample applications and comparing them. The Rust version used is the latest (1.48.0) at the time of writing.</p><h3 id="multi-threaded-concurrent-webserver">Multi-threaded concurrent webserver</h3><p>This example is closer to the example from the official <a href="https://doc.rust-lang.org/book/ch20-02-multithreaded.html">Rust book</a>, I have omitted import statements for brevity. You can find the full example on <a href="https://github.com/deepu105/concurrency-benchmarks/tree/main/rustws">GitHub here</a>. The <code class="language-plaintext highlighter-rouge">ThreadPool</code> struct is exactly the same as in the Rust book. We are not using any external dependency in this case.</p><div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
</pre></td><td class="rouge-code"><pre><span class="k">fn</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">listener</span> <span class="o">=</span> <span class="nn">TcpListener</span><span class="p">::</span><span class="nf">bind</span><span class="p">(</span><span class="s">"127.0.0.1:8080"</span><span class="p">)</span><span class="nf">.unwrap</span><span class="p">();</span> <span class="c">// bind listener</span>
    <span class="k">let</span> <span class="n">pool</span> <span class="o">=</span> <span class="nn">ThreadPool</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="mi">100</span><span class="p">);</span> <span class="c">// same number as max concurrent requests</span>

    <span class="k">let</span> <span class="k">mut</span> <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="c">// count used to introduce delays</span>

    <span class="c">// listen to all incoming request streams</span>
    <span class="k">for</span> <span class="n">stream</span> <span class="n">in</span> <span class="n">listener</span><span class="nf">.incoming</span><span class="p">()</span> <span class="p">{</span>
        <span class="k">let</span> <span class="n">stream</span> <span class="o">=</span> <span class="n">stream</span><span class="nf">.unwrap</span><span class="p">();</span>
        <span class="n">count</span> <span class="o">=</span> <span class="n">count</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
        <span class="n">pool</span><span class="nf">.execute</span><span class="p">(</span><span class="k">move</span> <span class="p">||</span> <span class="p">{</span>
            <span class="nf">handle_connection</span><span class="p">(</span><span class="n">stream</span><span class="p">,</span> <span class="n">count</span><span class="p">);</span> <span class="c">// spawning each connection in a new thread</span>
        <span class="p">});</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="k">fn</span> <span class="nf">handle_connection</span><span class="p">(</span><span class="k">mut</span> <span class="n">stream</span><span class="p">:</span> <span class="n">TcpStream</span><span class="p">,</span> <span class="n">count</span><span class="p">:</span> <span class="nb">i64</span><span class="p">)</span> <span class="p">{</span>
    <span class="c">// Read the first 1024 bytes of data from the stream</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">buffer</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">;</span> <span class="mi">1024</span><span class="p">];</span>
    <span class="n">stream</span><span class="nf">.read</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="n">buffer</span><span class="p">)</span><span class="nf">.unwrap</span><span class="p">();</span>

    <span class="c">// add 2 second delay to every 10th request</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">count</span> <span class="o">%</span> <span class="mi">10</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">{</span>
        <span class="nd">println!</span><span class="p">(</span><span class="s">"Adding delay. Count: {}"</span><span class="p">,</span> <span class="n">count</span><span class="p">);</span>
        <span class="nn">thread</span><span class="p">::</span><span class="nf">sleep</span><span class="p">(</span><span class="nn">Duration</span><span class="p">::</span><span class="nf">from_secs</span><span class="p">(</span><span class="mi">2</span><span class="p">));</span>
    <span class="p">}</span>

    <span class="k">let</span> <span class="n">header</span> <span class="o">=</span> <span class="s">"
HTTP/1.0 200 OK
Connection: keep-alive
Content-Length: 174
Content-Type: text/html; charset=utf-8
    "</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">contents</span> <span class="o">=</span> <span class="nn">fs</span><span class="p">::</span><span class="nf">read_to_string</span><span class="p">(</span><span class="s">"hello.html"</span><span class="p">)</span><span class="nf">.unwrap</span><span class="p">();</span>

    <span class="k">let</span> <span class="n">response</span> <span class="o">=</span> <span class="nd">format!</span><span class="p">(</span><span class="s">"{}</span><span class="se">\r\n\r\n</span><span class="s">{}"</span><span class="p">,</span> <span class="n">header</span><span class="p">,</span> <span class="n">contents</span><span class="p">);</span>

    <span class="n">stream</span><span class="nf">.write</span><span class="p">(</span><span class="n">response</span><span class="nf">.as_bytes</span><span class="p">())</span><span class="nf">.unwrap</span><span class="p">();</span> <span class="c">// write response</span>
    <span class="n">stream</span><span class="nf">.flush</span><span class="p">()</span><span class="nf">.unwrap</span><span class="p">();</span>
<span class="p">}</span>
</pre></td></tr></tbody></table></code></pre></div></div><p>As you can see we bind a TCP listener to port 8080 and listen to all incoming requests. Each request is processed in a new thread provided by a <code class="language-plaintext highlighter-rouge">ThreadPool</code>.</p><p>Let us run a benchmark using ApacheBench. We will make 10000 requests with 100 concurrent requests.</p><div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
</pre></td><td class="rouge-code"><pre>ab <span class="nt">-c</span> 100 <span class="nt">-n</span> 10000 http://127.0.0.1:8080/

This is ApacheBench, Version 2.3 &lt;<span class="nv">$Revision</span>: 1879490 <span class="nv">$&gt;</span>
...

Document Path:          /
Document Length:        176 bytes

Concurrency Level:      100
Time taken <span class="k">for </span>tests:   20.173 seconds
Complete requests:      10000
Failed requests:        0
Total transferred:      2830000 bytes
HTML transferred:       1760000 bytes
Requests per second:    495.72 <span class="o">[</span><span class="c">#/sec] (mean)</span>
Time per request:       201.726 <span class="o">[</span>ms] <span class="o">(</span>mean<span class="o">)</span>
Time per request:       2.017 <span class="o">[</span>ms] <span class="o">(</span>mean, across all concurrent requests<span class="o">)</span>
Transfer rate:          137.00 <span class="o">[</span>Kbytes/sec] received

Connection Times <span class="o">(</span>ms<span class="o">)</span>
              min  mean[+/-sd] median   max
Connect:        0    0   0.9      0       7
Processing:     0  201 600.0      0    2014
Waiting:        0  200 600.0      0    2013
Total:          0  201 600.0      0    2017

Percentage of the requests served within a certain <span class="nb">time</span> <span class="o">(</span>ms<span class="o">)</span>
  50%      0
  66%      1
  75%      1
  80%      3
  90%   2000
  95%   2001
  98%   2001
  99%   2002
 100%   2017 <span class="o">(</span>longest request<span class="o">)</span>
</pre></td></tr></tbody></table></code></pre></div></div><p>As you can see the request handler sleeps for 2 seconds for every 10th request hence if we set a realistic thread pool number of 8 for example it will limit us to a maximum of <code class="language-plaintext highlighter-rouge">(8 x 10) / 2 = 40</code> requests per second and hence we set a thread pool of 100 here to match the maximum concurrent requests, setting a value higher would not make any difference. I guess you can already see the problem here. The thread pool itself becomes the bottleneck. In a real use case, you may not be able to set so many threads as the OS may not be able to provide so many thus creating increased resource usage and bottleneck. In this simple use case, since each thread spawns and processes the request really fast we won’t encounter an issue.</p><p>So let’s see if we can have another solution without such a bottleneck.</p><h3 id="asynchronous-concurrent-webserver">Asynchronous concurrent webserver</h3><p>This example is closer to the example from the <a href="https://rust-lang.github.io/async-book/09_example/00_intro.html">Rust async docs</a>, I have omitted import statements for brevity. You can find the full example on <a href="https://github.com/deepu105/concurrency-benchmarks/tree/main/rustws_async">GitHub here</a>. The <code class="language-plaintext highlighter-rouge">TcpListener</code>, <code class="language-plaintext highlighter-rouge">TcpStream</code>, and <code class="language-plaintext highlighter-rouge">task</code> are from the <code class="language-plaintext highlighter-rouge">async_std</code> crate and <code class="language-plaintext highlighter-rouge">async-std</code> is the only external dependency used in this case.</p><div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
</pre></td><td class="rouge-code"><pre><span class="nd">#[async_std::main]</span>
<span class="k">async</span> <span class="k">fn</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">listener</span> <span class="o">=</span> <span class="nn">TcpListener</span><span class="p">::</span><span class="nf">bind</span><span class="p">(</span><span class="s">"127.0.0.1:8080"</span><span class="p">)</span><span class="k">.await</span><span class="nf">.unwrap</span><span class="p">();</span> <span class="c">// bind listener</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="c">// count used to introduce delays</span>

    <span class="k">loop</span> <span class="p">{</span>
        <span class="n">count</span> <span class="o">=</span> <span class="n">count</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
        <span class="c">// Listen for an incoming connection.</span>
        <span class="k">let</span> <span class="p">(</span><span class="n">stream</span><span class="p">,</span> <span class="mi">_</span><span class="p">)</span> <span class="o">=</span> <span class="n">listener</span><span class="nf">.accept</span><span class="p">()</span><span class="k">.await</span><span class="nf">.unwrap</span><span class="p">();</span>
        <span class="c">// spawn a new task to handle the connection</span>
        <span class="nn">task</span><span class="p">::</span><span class="nf">spawn</span><span class="p">(</span><span class="nf">handle_connection</span><span class="p">(</span><span class="n">stream</span><span class="p">,</span> <span class="n">count</span><span class="p">));</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="k">async</span> <span class="k">fn</span> <span class="nf">handle_connection</span><span class="p">(</span><span class="k">mut</span> <span class="n">stream</span><span class="p">:</span> <span class="n">TcpStream</span><span class="p">,</span> <span class="n">count</span><span class="p">:</span> <span class="nb">i64</span><span class="p">)</span> <span class="p">{</span>
    <span class="c">// Read the first 1024 bytes of data from the stream</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">buffer</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">;</span> <span class="mi">1024</span><span class="p">];</span>
    <span class="n">stream</span><span class="nf">.read</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="n">buffer</span><span class="p">)</span><span class="k">.await</span><span class="nf">.unwrap</span><span class="p">();</span>

    <span class="c">// add 2 second delay to every 10th request</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">count</span> <span class="o">%</span> <span class="mi">10</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">{</span>
        <span class="nd">println!</span><span class="p">(</span><span class="s">"Adding delay. Count: {}"</span><span class="p">,</span> <span class="n">count</span><span class="p">);</span>
        <span class="nn">task</span><span class="p">::</span><span class="nf">sleep</span><span class="p">(</span><span class="nn">Duration</span><span class="p">::</span><span class="nf">from_secs</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span><span class="k">.await</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="k">let</span> <span class="n">header</span> <span class="o">=</span> <span class="s">"
HTTP/1.0 200 OK
Connection: keep-alive
Content-Length: 174
Content-Type: text/html; charset=utf-8
    "</span><span class="p">;</span>
    <span class="k">let</span> <span class="n">contents</span> <span class="o">=</span> <span class="nn">fs</span><span class="p">::</span><span class="nf">read_to_string</span><span class="p">(</span><span class="s">"hello.html"</span><span class="p">)</span><span class="nf">.unwrap</span><span class="p">();</span>

    <span class="k">let</span> <span class="n">response</span> <span class="o">=</span> <span class="nd">format!</span><span class="p">(</span><span class="s">"{}</span><span class="se">\r\n\r\n</span><span class="s">{}"</span><span class="p">,</span> <span class="n">header</span><span class="p">,</span> <span class="n">contents</span><span class="p">);</span>

    <span class="n">stream</span><span class="nf">.write</span><span class="p">(</span><span class="n">response</span><span class="nf">.as_bytes</span><span class="p">())</span><span class="k">.await</span><span class="nf">.unwrap</span><span class="p">();</span> <span class="c">// write response</span>
    <span class="n">stream</span><span class="nf">.flush</span><span class="p">()</span><span class="k">.await</span><span class="nf">.unwrap</span><span class="p">();</span>
<span class="p">}</span>
</pre></td></tr></tbody></table></code></pre></div></div><p>As you can see we bind an asynchronous TCP listener to port 8080 and listen to all incoming requests. Each request is processed in a new task provided by <code class="language-plaintext highlighter-rouge">async_std</code>. We are not using any thread pools here and all the incoming requests are processed asynchronously and hence we don’t have a bottleneck for maximum connections.</p><p>Let us run a benchmark using ApacheBench. We will make 10000 requests with 100 concurrent requests.</p><div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
</pre></td><td class="rouge-code"><pre>ab <span class="nt">-c</span> 100 <span class="nt">-n</span> 10000 http://127.0.0.1:8080/

This is ApacheBench, Version 2.3 &lt;<span class="nv">$Revision</span>: 1879490 <span class="nv">$&gt;</span>
...

Document Path:          /
Document Length:        176 bytes

Concurrency Level:      100
Time taken <span class="k">for </span>tests:   20.186 seconds
Complete requests:      10000
Failed requests:        0
Total transferred:      2830000 bytes
HTML transferred:       1760000 bytes
Requests per second:    495.38 <span class="o">[</span><span class="c">#/sec] (mean)</span>
Time per request:       201.863 <span class="o">[</span>ms] <span class="o">(</span>mean<span class="o">)</span>
Time per request:       2.019 <span class="o">[</span>ms] <span class="o">(</span>mean, across all concurrent requests<span class="o">)</span>
Transfer rate:          136.91 <span class="o">[</span>Kbytes/sec] received

Connection Times <span class="o">(</span>ms<span class="o">)</span>
              min  mean[+/-sd] median   max
Connect:        0    1   0.8      0       6
Processing:     0  201 600.0      0    2010
Waiting:        0  201 600.0      0    2010
Total:          0  201 600.0      1    2014
WARNING: The median and mean <span class="k">for </span>the initial connection <span class="nb">time </span>are not within a normal deviation
        These results are probably not that reliable.

Percentage of the requests served within a certain <span class="nb">time</span> <span class="o">(</span>ms<span class="o">)</span>
  50%      1
  66%      1
  75%      2
  80%      3
  90%   2000
  95%   2001
  98%   2001
  99%   2003
 100%   2014 <span class="o">(</span>longest request<span class="o">)</span>
</pre></td></tr></tbody></table></code></pre></div></div><p>We got almost identical results here. Hence this version seems much more efficient than the multi-threaded version for this particular use case. Similar solutions can be built using other crates like <code class="language-plaintext highlighter-rouge">smol</code>, <code class="language-plaintext highlighter-rouge">hyper</code>, <code class="language-plaintext highlighter-rouge">tokio</code>, and so on. You can find some of them in this <a href="https://github.com/deepu105/concurrency-benchmarks">repo</a>.</p><p>Let’s see if we can combine the two to create an asynchronous multi-threaded version.</p><h3 id="asynchronous-multi-threaded-concurrent-webserver">Asynchronous multi-threaded concurrent webserver</h3><p>This example uses an async <code class="language-plaintext highlighter-rouge">ThreadPool</code>. I have omitted import statements for brevity. You can find the full example on <a href="https://github.com/deepu105/concurrency-benchmarks/tree/main/rustws_async_thread">GitHub here</a>. The <code class="language-plaintext highlighter-rouge">ThreadPool</code> struct is from the <code class="language-plaintext highlighter-rouge">futures</code> crate and it’s the only external dependency used in this case.</p><div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
</pre></td><td class="rouge-code"><pre><span class="k">fn</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">listener</span> <span class="o">=</span> <span class="nn">TcpListener</span><span class="p">::</span><span class="nf">bind</span><span class="p">(</span><span class="s">"127.0.0.1:8080"</span><span class="p">)</span><span class="nf">.unwrap</span><span class="p">();</span> <span class="c">// bind listener</span>

    <span class="k">let</span> <span class="k">mut</span> <span class="n">pool_builder</span> <span class="o">=</span> <span class="nn">ThreadPoolBuilder</span><span class="p">::</span><span class="nf">new</span><span class="p">();</span>
    <span class="n">pool_builder</span><span class="nf">.pool_size</span><span class="p">(</span><span class="mi">100</span><span class="p">);</span>
    <span class="k">let</span> <span class="n">pool</span> <span class="o">=</span> <span class="n">pool_builder</span><span class="nf">.create</span><span class="p">()</span><span class="nf">.expect</span><span class="p">(</span><span class="s">"couldn't create threadpool"</span><span class="p">);</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="c">// count used to introduce delays</span>

    <span class="c">// Listen for an incoming connection.</span>
    <span class="k">for</span> <span class="n">stream</span> <span class="n">in</span> <span class="n">listener</span><span class="nf">.incoming</span><span class="p">()</span> <span class="p">{</span>
        <span class="k">let</span> <span class="n">stream</span> <span class="o">=</span> <span class="n">stream</span><span class="nf">.unwrap</span><span class="p">();</span>
        <span class="n">count</span> <span class="o">=</span> <span class="n">count</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
        <span class="k">let</span> <span class="n">count_n</span> <span class="o">=</span> <span class="nn">Box</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="n">count</span><span class="p">);</span>

        <span class="c">// spawning each connection in a new thread asynchronously</span>
        <span class="n">pool</span><span class="nf">.spawn_ok</span><span class="p">(</span><span class="k">async</span> <span class="p">{</span>
            <span class="nf">handle_connection</span><span class="p">(</span><span class="n">stream</span><span class="p">,</span> <span class="n">count_n</span><span class="p">)</span><span class="k">.await</span><span class="p">;</span>
        <span class="p">});</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="k">async</span> <span class="k">fn</span> <span class="nf">handle_connection</span><span class="p">(</span><span class="k">mut</span> <span class="n">stream</span><span class="p">:</span> <span class="n">TcpStream</span><span class="p">,</span> <span class="n">count</span><span class="p">:</span> <span class="nb">Box</span><span class="o">&lt;</span><span class="nb">i64</span><span class="o">&gt;</span><span class="p">)</span> <span class="p">{</span>
    <span class="c">// Read the first 1024 bytes of data from the stream</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">buffer</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">;</span> <span class="mi">1024</span><span class="p">];</span>
    <span class="n">stream</span><span class="nf">.read</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="n">buffer</span><span class="p">)</span><span class="nf">.unwrap</span><span class="p">();</span>

    <span class="c">// add 2 second delay to every 10th request</span>
    <span class="k">if</span> <span class="p">(</span><span class="o">*</span><span class="n">count</span> <span class="o">%</span> <span class="mi">10</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">{</span>
        <span class="nd">println!</span><span class="p">(</span><span class="s">"Adding delay. Count: {}"</span><span class="p">,</span> <span class="n">count</span><span class="p">);</span>
        <span class="nn">thread</span><span class="p">::</span><span class="nf">sleep</span><span class="p">(</span><span class="nn">Duration</span><span class="p">::</span><span class="nf">from_secs</span><span class="p">(</span><span class="mi">2</span><span class="p">));</span>
    <span class="p">}</span>

    <span class="k">let</span> <span class="n">header</span> <span class="o">=</span> <span class="s">"
    HTTP/1.0 200 OK
    Connection: keep-alive
    Content-Length: 174
    Content-Type: text/html; charset=utf-8
        "</span><span class="p">;</span>

    <span class="k">let</span> <span class="n">contents</span> <span class="o">=</span> <span class="nn">fs</span><span class="p">::</span><span class="nf">read_to_string</span><span class="p">(</span><span class="s">"hello.html"</span><span class="p">)</span><span class="nf">.unwrap</span><span class="p">();</span>

    <span class="k">let</span> <span class="n">response</span> <span class="o">=</span> <span class="nd">format!</span><span class="p">(</span><span class="s">"{}</span><span class="se">\r\n\r\n</span><span class="s">{}"</span><span class="p">,</span> <span class="n">header</span><span class="p">,</span> <span class="n">contents</span><span class="p">);</span>

    <span class="n">stream</span><span class="nf">.write</span><span class="p">(</span><span class="n">response</span><span class="nf">.as_bytes</span><span class="p">())</span><span class="nf">.unwrap</span><span class="p">();</span> <span class="c">// write response</span>
    <span class="n">stream</span><span class="nf">.flush</span><span class="p">()</span><span class="nf">.unwrap</span><span class="p">();</span>
<span class="p">}</span>
</pre></td></tr></tbody></table></code></pre></div></div><p>This is very similar to the first <code class="language-plaintext highlighter-rouge">Threadpool</code> example except for the async invocation. Unfortunately, we have the same bottleneck from the thread pool in this case as well hence we set a thread pool of 100 here to match the maximum concurrent requests.</p><p>Let us run a benchmark using ApacheBench. We will make 10000 requests with 100 concurrent requests.</p><div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
</pre></td><td class="rouge-code"><pre>ab <span class="nt">-c</span> 100 <span class="nt">-n</span> 10000 http://127.0.0.1:8080/

This is ApacheBench, Version 2.3 &lt;<span class="nv">$Revision</span>: 1879490 <span class="nv">$&gt;</span>
...

Document Path:          /
Document Length:        176 bytes

Concurrency Level:      100
Time taken <span class="k">for </span>tests:   20.161 seconds
Complete requests:      10000
Failed requests:        0
Total transferred:      3030000 bytes
HTML transferred:       1760000 bytes
Requests per second:    496.00 <span class="o">[</span><span class="c">#/sec] (mean)</span>
Time per request:       201.615 <span class="o">[</span>ms] <span class="o">(</span>mean<span class="o">)</span>
Time per request:       2.016 <span class="o">[</span>ms] <span class="o">(</span>mean, across all concurrent requests<span class="o">)</span>
Transfer rate:          146.76 <span class="o">[</span>Kbytes/sec] received

Connection Times <span class="o">(</span>ms<span class="o">)</span>
              min  mean[+/-sd] median   max
Connect:        0    0   0.8      0       5
Processing:     0  201 600.0      0    2007
Waiting:        0  200 600.0      0    2007
Total:          0  201 600.0      0    2010

Percentage of the requests served within a certain <span class="nb">time</span> <span class="o">(</span>ms<span class="o">)</span>
  50%      0
  66%      1
  75%      2
  80%      2
  90%   2000
  95%   2000
  98%   2001
  99%   2002
 100%   2010 <span class="o">(</span>longest request<span class="o">)</span>
</pre></td></tr></tbody></table></code></pre></div></div><p>It does seem slightly faster by some milliseconds compared to previous solutions.</p><h3 id="asynchronous-multi-threaded-concurrent-webserver-with-tokio">Asynchronous multi-threaded concurrent webserver with Tokio</h3><p>This is another version of asynchronous multi-threaded webserver using <a href="https://github.com/tokio-rs/tokio">Tokio</a> and it was contributed by <a href="https://github.com/Recmo">Remco Bloemen</a>. I have omitted import statements for brevity. You can find the full example on <a href="https://github.com/deepu105/concurrency-benchmarks/tree/main/rustws_async_tokio">GitHub here</a>.</p><div class="language-rust highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
</pre></td><td class="rouge-code"><pre><span class="nd">#[tokio::main()]</span> <span class="c">// Tokio uses a threadpool sized for number of cpus by default</span>
<span class="k">async</span> <span class="k">fn</span> <span class="nf">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">let</span> <span class="n">listener</span> <span class="o">=</span> <span class="nn">TcpListener</span><span class="p">::</span><span class="nf">bind</span><span class="p">(</span><span class="s">"127.0.0.1:8080"</span><span class="p">)</span><span class="k">.await</span><span class="nf">.unwrap</span><span class="p">();</span>  <span class="c">// bind listener</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="c">// count used to introduce delays</span>

    <span class="c">// Listen for an incoming connection.</span>
    <span class="k">loop</span> <span class="p">{</span>
        <span class="n">count</span> <span class="o">=</span> <span class="n">count</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span>
        <span class="k">let</span> <span class="p">(</span><span class="n">socket</span><span class="p">,</span> <span class="mi">_</span><span class="p">)</span> <span class="o">=</span> <span class="n">listener</span><span class="nf">.accept</span><span class="p">()</span><span class="k">.await</span><span class="nf">.unwrap</span><span class="p">();</span>
        <span class="c">// spawning each connection in a new tokio thread asynchronously</span>
        <span class="nn">tokio</span><span class="p">::</span><span class="nf">spawn</span><span class="p">(</span><span class="k">async</span> <span class="k">move</span> <span class="p">{</span> <span class="nf">handle_connection</span><span class="p">(</span><span class="n">socket</span><span class="p">,</span> <span class="nn">Box</span><span class="p">::</span><span class="nf">new</span><span class="p">(</span><span class="n">count</span><span class="p">))</span><span class="k">.await</span> <span class="p">});</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="k">async</span> <span class="k">fn</span> <span class="nf">handle_connection</span><span class="p">(</span><span class="k">mut</span> <span class="n">stream</span><span class="p">:</span> <span class="n">TcpStream</span><span class="p">,</span> <span class="n">count</span><span class="p">:</span> <span class="nb">Box</span><span class="o">&lt;</span><span class="nb">i64</span><span class="o">&gt;</span><span class="p">)</span> <span class="p">{</span>
    <span class="c">// Read the first 1024 bytes of data from the stream</span>
    <span class="k">let</span> <span class="k">mut</span> <span class="n">buffer</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">;</span> <span class="mi">1024</span><span class="p">];</span>
    <span class="n">stream</span><span class="nf">.read</span><span class="p">(</span><span class="o">&amp;</span><span class="k">mut</span> <span class="n">buffer</span><span class="p">)</span><span class="k">.await</span><span class="nf">.unwrap</span><span class="p">();</span>

    <span class="c">// add 2 second delay to every 10th request</span>
    <span class="k">if</span> <span class="p">(</span><span class="o">*</span><span class="n">count</span> <span class="o">%</span> <span class="mi">10</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="p">{</span>
        <span class="nd">println!</span><span class="p">(</span><span class="s">"Adding delay. Count: {}"</span><span class="p">,</span> <span class="n">count</span><span class="p">);</span>
        <span class="nf">sleep</span><span class="p">(</span><span class="nn">Duration</span><span class="p">::</span><span class="nf">from_secs</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span><span class="k">.await</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="k">let</span> <span class="n">header</span> <span class="o">=</span> <span class="s">"
    HTTP/1.0 200 OK
    Connection: keep-alive
    Content-Length: 174
    Content-Type: text/html; charset=utf-8
        "</span><span class="p">;</span>

    <span class="k">let</span> <span class="n">contents</span> <span class="o">=</span> <span class="nf">read_to_string</span><span class="p">(</span><span class="s">"hello.html"</span><span class="p">)</span><span class="k">.await</span><span class="nf">.unwrap</span><span class="p">();</span>

    <span class="k">let</span> <span class="n">response</span> <span class="o">=</span> <span class="nd">format!</span><span class="p">(</span><span class="s">"{}</span><span class="se">\r\n\r\n</span><span class="s">{}"</span><span class="p">,</span> <span class="n">header</span><span class="p">,</span> <span class="n">contents</span><span class="p">);</span>

    <span class="n">stream</span><span class="nf">.write_all</span><span class="p">(</span><span class="n">response</span><span class="nf">.as_bytes</span><span class="p">())</span><span class="k">.await</span><span class="nf">.unwrap</span><span class="p">();</span> <span class="c">// write response</span>
<span class="p">}</span>
</pre></td></tr></tbody></table></code></pre></div></div><p>This is very similar to the previous example but works with less number of thread pools and uses async invocation. We do not have the bottleneck from the previous thread pool example in this case.</p><p>Let us run a benchmark using ApacheBench. We will make 10000 requests with 100 concurrent requests.</p><div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
</pre></td><td class="rouge-code"><pre>ab <span class="nt">-c</span> 100 <span class="nt">-n</span> 10000 http://127.0.0.1:8080/

This is ApacheBench, Version 2.3 &lt;<span class="nv">$Revision</span>: 1879490 <span class="nv">$&gt;</span>
...

Document Path:          /
Document Length:        176 bytes

Concurrency Level:      100
Time taken <span class="k">for </span>tests:   20.569 seconds
Complete requests:      10000
Failed requests:        0
Total transferred:      3030000 bytes
HTML transferred:       1760000 bytes
Requests per second:    486.17 <span class="o">[</span><span class="c">#/sec] (mean)</span>
Time per request:       205.688 <span class="o">[</span>ms] <span class="o">(</span>mean<span class="o">)</span>
Time per request:       2.057 <span class="o">[</span>ms] <span class="o">(</span>mean, across all concurrent requests<span class="o">)</span>
Transfer rate:          143.86 <span class="o">[</span>Kbytes/sec] received

Connection Times <span class="o">(</span>ms<span class="o">)</span>
              min  mean[+/-sd] median   max
Connect:        0    1   2.4      0      22
Processing:     0  202 600.3      1    2013
Waiting:        0  202 600.3      1    2012
Total:          0  203 600.3      2    2029

Percentage of the requests served within a certain <span class="nb">time</span> <span class="o">(</span>ms<span class="o">)</span>
  50%      2
  66%      3
  75%      5
  80%      7
  90%   2000
  95%   2003
  98%   2006
  99%   2008
 100%   2029 <span class="o">(</span>longest request<span class="o">)</span>
</pre></td></tr></tbody></table></code></pre></div></div><p>It does seem slightly slower by some milliseconds compared to previous solution.</p><h2 id="conclusion">Conclusion</h2><p>As I explained in the <a href="https://deepu.tech/concurrency-in-modern-languages/">first part</a> of this serious, this simple benchmarking is not an accurate representation for all concurrency use cases. It’s a simple test for a very particular use case, a simple concurrent web server that just serves a file. The idea is to see the differences in solutions and to understand how concurrency works in Rust. And for this particular use case, asynchronous solutions do seem to be the best choice.</p><p>So stay tuned for the next post where we will look at concurrency in Golang and build the same use case in Go.</p><hr><h2 id="references">References</h2><ul><li><a href="https://klau.si/blog/benchmarking-a-rust-web-application/">klau.si</a></li><li><a href="https://hackmd.io/@lbernick/SkgO7bCMw">hackmd.io</a></li><li><a href="https://doc.rust-lang.org/book/ch20-00-final-project-a-web-server.html">doc.rust-lang.org</a></li><li><a href="https://rust-lang.github.io/async-book">rust-lang.github.io</a></li></ul><hr><p>If you like this article, please leave a like or a comment.</p><p>You can follow me on <a href="https://twitter.com/deepu105">Twitter</a> and <a href="https://www.linkedin.com/in/deepu05/">LinkedIn</a>.</p><p>Cover image credit: Photo by <a href="https://unsplash.com/@jacobmejicanos?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Jacob Mejicanos</a> on <a href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></p><p><em>Also published at <a href="https://dev.to/deepu105/concurrency-in-modern-programming-languages-rust-19co">Dev.to</a></em></p></div><div class="after-post-cats"><ul class="tags mb-4"></ul></div><div class="after-post-tags"><ul class="tags"><li><a class="smoothscroll" href="/tags#async">#async</a></li><li><a class="smoothscroll" href="/tags#concurrency">#concurrency</a></li><li><a class="smoothscroll" href="/tags#languages">#languages</a></li><li><a class="smoothscroll" href="/tags#rust">#rust</a></li></ul></div><div class="row PageNavigation d-flex justify-content-between font-weight-bold"><a class="prev d-block col-md-6" href="/concurrency-in-modern-languages/">&laquo; Concurrency in modern programming languages: Introduction</a> <a class="next d-block col-md-6 text-lg-right" href="/concurrency-in-modern-languages-go/">Concurrency in modern programming languages: Golang &raquo;</a><div class="clearfix"></div></div></div></div></div><div class="container"><div id="comments" class="row justify-content-center mb-5"><div class="col-md-8"><section class="disqus"><div id="disqus_thread"></div><script type="text/javascript">var disqus_shortname = 'deepu-tech'; 
        var disqus_developer = 0;
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = window.location.protocol + '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();</script><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript><a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a></section></div></div></div></div><div class="alertbar"><div class="container text-center"><span>Never miss a <b>story</b> from us, subscribe to our newsletter</span><form action="https://tech.us7.list-manage.com/subscribe/post?u=00729f6c6d6bb180801b9484e&amp;id=f521dede4b" method="post" name="mc-embedded-subscribe-form" id="mc-embedded-subscribe-form" class="wj-contact-form validate" target="_blank" novalidate><div class="mc-field-group"><input type="email" placeholder="Email address" name="EMAIL" class="required email" id="mce-EMAIL" autocomplete="on" required> <input type="submit" value="Subscribe" name="subscribe" class="heart"></div></form></div></div></div><div class="jumbotron fortags lozad" data-background-image="/assets/images/jumbotron.jpg"><div class="d-md-flex h-100"><div class="col-md-4 transpdark align-self-center text-center h-100"><div class="d-md-flex align-items-center justify-content-center h-100"><h2 class="d-md-block align-self-center py-1 font-weight-light">Explore <span class="d-none d-md-inline">→</span></h2></div></div><div class="col-md-8 p-5 align-self-center text-center"><a class="mt-1 mb-1" href="/tags#jhipster">jhipster (3)</a> <a class="mt-1 mb-1" href="/tags#java">java (6)</a> <a class="mt-1 mb-1" href="/tags#microservices">microservices (5)</a> <a class="mt-1 mb-1" href="/tags#docker">docker (2)</a> <a class="mt-1 mb-1" href="/tags#azure">azure (2)</a> <a class="mt-1 mb-1" href="/tags#kubernetes">kubernetes (3)</a> <a class="mt-1 mb-1" href="/tags#typescript">typescript (5)</a> <a class="mt-1 mb-1" href="/tags#react">react (2)</a> <a class="mt-1 mb-1" href="/tags#javascript">javascript (12)</a> <a class="mt-1 mb-1" href="/tags#webdev">webdev (2)</a> <a class="mt-1 mb-1" href="/tags#terraform">terraform (1)</a> <a class="mt-1 mb-1" href="/tags#writing">writing (1)</a> <a class="mt-1 mb-1" href="/tags#medium">medium (1)</a> <a class="mt-1 mb-1" href="/tags#development">development (3)</a> <a class="mt-1 mb-1" href="/tags#tech">tech (1)</a> <a class="mt-1 mb-1" href="/tags#linux">linux (4)</a> <a class="mt-1 mb-1" href="/tags#fedora">fedora (3)</a> <a class="mt-1 mb-1" href="/tags#gnome">gnome (2)</a> <a class="mt-1 mb-1" href="/tags#desktop">desktop (1)</a> <a class="mt-1 mb-1" href="/tags#terminal">terminal (1)</a> <a class="mt-1 mb-1" href="/tags#ohmyzsh">ohmyzsh (1)</a> <a class="mt-1 mb-1" href="/tags#zsh">zsh (1)</a> <a class="mt-1 mb-1" href="/tags#go">go (5)</a> <a class="mt-1 mb-1" href="/tags#programming">programming (13)</a> <a class="mt-1 mb-1" href="/tags#languages">languages (12)</a> <a class="mt-1 mb-1" href="/tags#thepragmaticprogrammer">thepragmaticprogrammer (3)</a> <a class="mt-1 mb-1" href="/tags#vscode">vscode (1)</a> <a class="mt-1 mb-1" href="/tags#ide">ide (1)</a> <a class="mt-1 mb-1" href="/tags#opensource">opensource (1)</a> <a class="mt-1 mb-1" href="/tags#istio">istio (1)</a> <a class="mt-1 mb-1" href="/tags#functional">functional (4)</a> <a class="mt-1 mb-1" href="/tags#beginners">beginners (8)</a> <a class="mt-1 mb-1" href="/tags#showdev">showdev (2)</a> <a class="mt-1 mb-1" href="/tags#ruby">ruby (1)</a> <a class="mt-1 mb-1" href="/tags#Jekyll">Jekyll (1)</a> <a class="mt-1 mb-1" href="/tags#blogging">blogging (1)</a> <a class="mt-1 mb-1" href="/tags#architecture">architecture (1)</a> <a class="mt-1 mb-1" href="/tags#devops">devops (1)</a> <a class="mt-1 mb-1" href="/tags#distributedsystems">distributedsystems (1)</a> <a class="mt-1 mb-1" href="/tags#rust">rust (5)</a> <a class="mt-1 mb-1" href="/tags#bash">bash (1)</a> <a class="mt-1 mb-1" href="/tags#codenewbie">codenewbie (1)</a> <a class="mt-1 mb-1" href="/tags#codequality">codequality (2)</a> <a class="mt-1 mb-1" href="/tags#career">career (2)</a> <a class="mt-1 mb-1" href="/tags#computerscience">computerscience (4)</a> <a class="mt-1 mb-1" href="/tags#motivation">motivation (1)</a> <a class="mt-1 mb-1" href="/tags#books">books (1)</a> <a class="mt-1 mb-1" href="/tags#kotlin">kotlin (1)</a> <a class="mt-1 mb-1" href="/tags#scala">scala (1)</a> <a class="mt-1 mb-1" href="/tags#clojure">clojure (1)</a> <a class="mt-1 mb-1" href="/tags#WebAssembly">WebAssembly (1)</a> <a class="mt-1 mb-1" href="/tags#node">node (2)</a> <a class="mt-1 mb-1" href="/tags#python">python (1)</a> <a class="mt-1 mb-1" href="/tags#garbagecollection">garbagecollection (2)</a> <a class="mt-1 mb-1" href="/tags#nodejs">nodejs (2)</a> <a class="mt-1 mb-1" href="/tags#deno">deno (2)</a> <a class="mt-1 mb-1" href="/tags#v8">v8 (1)</a> <a class="mt-1 mb-1" href="/tags#memory-management">memory-management (1)</a> <a class="mt-1 mb-1" href="/tags#windows">windows (1)</a> <a class="mt-1 mb-1" href="/tags#vr">vr (1)</a> <a class="mt-1 mb-1" href="/tags#gaming">gaming (1)</a> <a class="mt-1 mb-1" href="/tags#polyglot">polyglot (1)</a> <a class="mt-1 mb-1" href="/tags#interview">interview (1)</a> <a class="mt-1 mb-1" href="/tags#womenintech">womenintech (1)</a> <a class="mt-1 mb-1" href="/tags#discuss">discuss (1)</a> <a class="mt-1 mb-1" href="/tags#pragmatic">pragmatic (1)</a> <a class="mt-1 mb-1" href="/tags#concurrency">concurrency (5)</a> <a class="mt-1 mb-1" href="/tags#async">async (3)</a> <a class="mt-1 mb-1" href="/tags#multithreading">multithreading (1)</a> <a class="mt-1 mb-1" href="/tags#golang">golang (1)</a> <a class="mt-1 mb-1" href="/tags#svelte">svelte (1)</a> <a class="mt-1 mb-1" href="/tags#web">web (1)</a> <a class="mt-1 mb-1" href="/tags#ubuntu">ubuntu (1)</a> <a class="mt-1 mb-1" href="/tags#kde">kde (1)</a></div></div></div><footer class="footer"><div class="container"><div class="row"><div class="col-md-6 col-sm-6 text-center text-lg-left">Copyright © 2021 Deepu K Sasidharan<br><a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img class="lozad" alt="Creative Commons License" style="border-width:0" src="/assets/images/placeholder.jpg" data-src="https://i.creativecommons.org/l/by/4.0/88x31.png"> </a>Content licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.</div><div class="col-md-6 col-sm-6 text-center text-lg-right"><a target="_blank" href="https://www.wowthemes.net/mediumish-free-jekyll-template/">Mediumish Jekyll Theme</a> by WowThemes.net | Domain by <a href="https://js.org" target="_blank" title="JS.ORG | JavaScript Community"><img src="/assets/images/placeholder.jpg" data-src="https://logo.js.org/dark_tiny.png" style="width:50px" alt="JS.ORG Logo" class="lozad"> </a>| Hosted with <i class="far fa-heart"></i> by <a href="https://pages.github.com/" target="_blank">Github</a></div></div></div></footer></div><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha256-WqU1JavFxSAMcLP2WIOI+GB2zWmShMI82mTpLDcqFUg=" crossorigin="anonymous"></script><script async src="/assets/js/mediumish.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.14.0/lozad.min.js" integrity="sha256-hstwhDmGVwZjIwt6SlTG6sQBREWrWTBjVTik/JLlb1Y=" crossorigin="anonymous"></script><script>// lazy loads images
        const lazyloadObserver = lozad()
        lazyloadObserver.observe();</script><script async src="/assets/js/ie10-viewport-bug-workaround.js"></script><script async id="dsq-count-scr" src="//deepu-tech.disqus.com/count.js"></script><script async src="https://www.googletagmanager.com/gtag/js?id=UA-74370272-6"></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-74370272-6');</script></body></html>