
var documents = [{
    "id": 0,
    "url": "/404.html",
    "title": "404",
    "body": "404 Page does not exist!Please use the search bar at the top or visit our homepage! "
    }, {
    "id": 1,
    "url": "/books",
    "title": "Books",
    "body": "Full Stack Development with JHipster - second edition:   Get it from:                  JHipster is an open source development platform that allows you to easily create web applications and microservices from scratch without spending time on wiring and integrating different technologies together. Updated to include JHipster 6, Java 11, Spring Boot 2. 1, Vue. js, and Istio, this second edition of Full Stack Development with JHipster will help you build full stack applications and microservices seamlessly.   You‚Äôll start by understanding JHipster and its associated tools, along with the essentials of full stack development, before building a monolithic web application. You‚Äôll then learn the JHipster Domain Language (JDL) with entity modeling using JDL Studio. With this book, you‚Äôll create production-ready web applications using Spring Boot, Spring Framework, Angular, and Bootstrap, and run tests and set up Continuous Integration pipelines with Jenkins. As you advance, you‚Äôll learn how to convert your monoliths to microservices and how to package your application for production with various deployment options, including Heroku and Google Cloud. You‚Äôll also learn about Docker and Kubernetes, along with an introduction to the Istio service mesh. Finally, you‚Äôll build your client-side with React and Vue. js and discover JHipster‚Äôs best practices. By the end of the book, you‚Äôll be able to leverage the best tools available to build modern web applications. Full Stack Development with JHipster:   Get it from:                        JHipster is a development platform to generate, develop, and deploy Spring Boot and Angular/React applications and Spring microservices. It provides you with a variety of tools that will help you quickly build modern web applications. This book will be your guide to building full stack applications with Spring and Angular using the JHipster tool set.   You will begin by understanding what JHipster is and the various tools and technologies associated with it. You will learn the essentials of a full stack developer before getting hands-on and building a monolithic web application with JHipster. From here you will learn the JHipster Domain Language with entity modeling and entity creation using JDL and JDL studio. Moving on, you will be introduced to client side technologies such as Angular and Bootstrap and will delve into technologies such as Spring Security, Spring MVC, and Spring Data. You will learn to build and package applications for production with various deployment options such as Heroku and more. During the course of the book, you will be introduced to microservice server-side technologies and how to break your monolithic application into microservices. Next, the book takes you through cloud deployment of microservices on Docker and Kubernetes. Going forward, you will learn to build your client side with React and master JHipster best practices. By the end of the book, you will be able to leverage the power of the best tools available to build modern web applications. "
    }, {
    "id": 2,
    "url": "/categories",
    "title": "Categories",
    "body": ""
    }, {
    "id": 3,
    "url": "/comment-policy",
    "title": "Comment policy",
    "body": "Keep it civil aka don‚Äôt be a jerk: We‚Äôre going to get into the thick of a lot of heated discussions and that‚Äôs okay. These discussions often entail topics that we all personally care a lot about and will passionately defend. But in order for discussions to thrive here, we need to remember to criticize ideas, not people. ¬†¬†So, remember to avoid:  name-calling ad hominem attacks Responding to a post‚Äôs tone instead of its actual content.  knee-jerk contradictionComments that we find to be hateful, inflammatory, or harassing may be removed. If you don‚Äôt have something nice to say about another user, don‚Äôt say it. Treat others the way you‚Äôd like to be treated. Always strive to add value to every interaction and discussion you participate in: There are a lot of discussions that happen every day on Disqus. Before joining in a discussion, browse through some of the most recent and active discussions happening in the community, especially if you‚Äôre new there. ¬†¬†If you are not sure your post adds to the conversation, think over what you want to say and try again later. Keep it tidy: Help make moderators‚Äô lives easier by taking a moment to ensure that what you‚Äôre about to post is in the right place. That means:  don‚Äôt post off-topic comments or discussions don‚Äôt cross-post the same thing multiple times review any specific posting guidelines for the community check if another active discussion on your topic has already been postedIf you see something, say something: Moderators are at the forefront of combatting spam, mediating disputes and enforcing community guidelines and, so are you. ¬†¬†If you see an issue, contact the moderators if possible or flag any comments for review. If you believe someone has violated the Basic Rules, report it to Disqus by flagging the user‚Äôs profile. No Self-promotion A discussion or comment that contains only a link to your blog, a product, or your article on another site will almost always be removed. Choose Your (Curse) Words Wisely Comments that contain profanity are automatically held for moderator review before being posted. Depending on the context of the comment, it may be removed. Profanity used to insult, antagonize, or inflame will always be removed. Don‚Äôt Be a Jerk Personal attacks and harassment will not be tolerated. Sexist, racist, misogynist, homophobic, and broad, offensive generalizations about groups of people are simply not allowed. Comments or discussions written intentionally to provoke will also be removed. Don‚Äôt Copy and Paste If you didn‚Äôt write it, or haven‚Äôt properly cited the article you‚Äôre quoting, don‚Äôt post it. English Only We currently only support English-only discussions on Disqus channels. Non-English comments and discussions will be removed. Related: Guide to building community guidelines: "
    }, {
    "id": 4,
    "url": "/",
    "title": "Deepu K Sasidharan",
    "body": "                                             I'm a Software Designer by passion &amp; profession. I'm also the co-lead of JHipster.          My expertise includes solution ideation, visualization, and prototyping.          I code using various Languages like Java, JavaScript, TypeScript, Go, Python and so on.          I'm an open-source software aficionado and a technology advocate by passion.          I'm also passionate about developer experience and user experience.          I also love Astronomy, Quadcopters, and Robotics.          I have authored a book on JHipster and write frequently about Java, JavaScript, Go, CloudNative and so on.                                Book:                       Full Stack Development with JHipster - second edition.         Get it on        Packt and        Amazon                                               OSS projects:                                            JHipster Generator:                          A cool generator for Angular/React/VueJS + Spring stack                                                    Angular Clock:                          A beautiful responsive clock face and clock widget for angular JS.          Built in SVG                                                          JHipster Registry:                          Service Registry, based on Spring Cloud Netflix Eureka and Spring         Cloud Config                                                    JHipster Entity Audit Generator:                          A yeoman generator to enable entity audit in JHipster generated apps                                                          JDL Studio:                 An awesome online JDL editor and visualizer                                            JHipster Bootswatch Theme Generator:                          A yeoman generator to enable Bootswatch themes in JHipster generated         apps                                                          Angular Object Diff:                          An AngularJS plugin to generate and view object difference                                                    UML and Sequence Diagram Generator:                                  A sequence diagram generator using angularJS and an UML Diagram         Generator based on PlantUML. Experimental.                                                             Follow me on social media:                                                                                                                                                                           Blogs on Dev. to:                                      Upcoming talks:                                                            Featured posts:                                                                                                                                                                                                                                                                     üöÄüíÜüöÄ Demystifying memory management in modern programming languages                              :               Please follow me on Twitter for updates and let me know if something can be improved in the post. :                                                                                                                                                                       Deepu K Sasidharan                                08 Jan 2020 | 9 mins read                                                                                                                                                                                                                                                                                                                                                                                                                                                        My first impressions of Rust                              :               Please follow me on Twitter for updates. :                                                                                                                                                                       Deepu K Sasidharan                                07 Nov 2019 | 24 mins read                                                                                                                                                                                                                                                                                                                                                                                                                                                        My reflections on Golang                              :               Please follow me on Twitter for updates. :                                                                                                                                                                       Deepu K Sasidharan                                12 Jul 2019 | 20 mins read                                                                                                                                                                                                                                                                                                                                                                                  My beautiful Linux development environment                              :               Please follow me on Twitter for updates. :                                                                                                                                                                       Deepu K Sasidharan                                16 Jun 2019 | 7 mins read                                                                                                                                                                                                                   "
    }, {
    "id": 5,
    "url": "/robots.txt",
    "title": "",
    "body": "      Sitemap: {{ ‚Äúsitemap. xml‚Äù   absolute_url }}   "
    }, {
    "id": 6,
    "url": "/blogs/index.html",
    "title": "Blogs",
    "body": "  {{ site. name }}      {{ site. description }}         Featured:       {% for post in site. posts %}    {% if post. featured == true %}            {% include featuredbox. html %}          {% endif %}  {% endfor %}        All Stories:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 7,
    "url": "/blogs/page/2/index.html",
    "title": " - page 2",
    "body": "  {{ site. name }}      {{ site. description }}         Featured:       {% for post in site. posts %}    {% if post. featured == true %}            {% include featuredbox. html %}          {% endif %}  {% endfor %}        All Stories:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 8,
    "url": "/blogs/page/3/index.html",
    "title": " - page 3",
    "body": "  {{ site. name }}      {{ site. description }}         Featured:       {% for post in site. posts %}    {% if post. featured == true %}            {% include featuredbox. html %}          {% endif %}  {% endfor %}        All Stories:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 9,
    "url": "/blogs/page/4/index.html",
    "title": " - page 4",
    "body": "  {{ site. name }}      {{ site. description }}         Featured:       {% for post in site. posts %}    {% if post. featured == true %}            {% include featuredbox. html %}          {% endif %}  {% endfor %}        All Stories:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 10,
    "url": "/blogs/page/5/index.html",
    "title": " - page 5",
    "body": "  {{ site. name }}      {{ site. description }}         Featured:       {% for post in site. posts %}    {% if post. featured == true %}            {% include featuredbox. html %}          {% endif %}  {% endfor %}        All Stories:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 11,
    "url": "/memory-management-in-jvm/",
    "title": "üöÄüíÜüöÄ Visualizing memory management in JVM(Java, Kotlin, Scala, Groovy, Clojure)",
    "body": "2020/01/23 - Please follow me on Twitter for updates and let me know if something can be improved in the post. In this multi-part series, I aim to demystify the concepts behind memory management and take a deeper look at memory management in some of the modern programming languages. I hope the series would give you some insights into what is happening under the hood of these languages in terms of memory management. In this chapter, we will look at the memory model of the Java Virtual Machine(JVM) used by languages like Java, Kotlin, Scala, Clojure, JRuby and so on. If you haven‚Äôt read the first part of this series, please read it first as I explained the difference between the Stack and Heap memory there which would be useful to understand this chapter. JVM memory modelFirst, let us see what the memory model of JVM is. This is based on JDK 11 onwards. Below is the memory available to a JVM process and is allocated by the Operating System(OS).  This is the native memory allocated by the OS and the amount depends on OS, processor, and JRE. Let us see what the different areas are for: Heap Memory: This is where JVM stores objects or dynamic data. This is the biggest block of memory area and this is where Garbage Collection(GC) takes place. The size of heap memory can be controlled using the Xms(Initial) and Xmx(Max) flags. The entire heap memory is not committed to the Virtual Machine(VM) as some of it is reserved as virtual space and the heap can grow to use this. Heap is further divided into ‚ÄúYoung‚Äù and ‚ÄúOld‚Äù generation space.  Young generation: Young generation or ‚ÄúNew Space‚Äù is where new objects live and is further divided into ‚ÄúEden Space‚Äù and ‚ÄúSurvivor Space‚Äù. This space is managed by ‚ÄúMinor GC‚Äù also sometimes called ‚ÄúYoung GC‚Äù     Eden Space: This is where new objects are created. When we create a new object, memory is allocated here.    Survivor Space: This is where objects that survived the minor GC are stored. This is divided into two halves, S0 and S1.     Old generation: Old generation or ‚ÄúTenured Space‚Äù is where objects that reached the maximum tenure threshold during minor GC live. This space is managed up by ‚ÄúMajor GC‚Äù. Thread Stacks: This is the stack memory area and there is one stack memory per thread in the process. This is where thread-specific static data including method/function frames and pointers to objects are stored. The stack memory limit can be set using the Xss flag. Meta Space: This is part of the native memory and doesn‚Äôt have an upper limit by default. This is what used to be Permanent Generation(PermGen) Space in earlier versions of JVM. This space is used by the class loaders to store class definitions. If this space keeps growing, the OS might move data stored here from RAM to virtual memory which might slow down the application. To avoid that its possible to set a limit on meta space used with the XX:MetaspaceSize and -XX:MaxMetaspaceSize flag in which case application might just throw out of memory errors. Code Cache: This is where the Just In Time(JIT) compiler stores compiled code blocks that are often accessed. Generally, JVM has to interpret byte code to native machine code whereas JIT-compiled code need not be interpreted as it is already in native format and is cached here. Shared Libraries: This is where native code for any shared libraries used are stored. This is loaded only once per process by the OS. JVM memory usage (Stack vs Heap)Now that we are clear about how memory is organized let‚Äôs see how the most important parts of it are used when a program is executed. Let‚Äôs use the below Java program, the code is not optimized for correctness hence ignore issues like unnecessary intermediatory variables, improper modifiers and such, the focus is to visualize stack and heap memory usage. 123456789101112131415161718192021222324252627282930313233class Employee {  String name;  Integer salary;  Integer sales;  Integer bonus;  public Employee(String name, Integer salary, Integer sales) {    this. name = name;    this. salary = salary;    this. sales = sales;  }}public class Test {  static int BONUS_PERCENTAGE = 10;  static int getBonusPercentage(int salary) {    int percentage = salary * BONUS_PERCENTAGE / 100;    return percentage;  }  static int findEmployeeBonus(int salary, int noOfSales) {    int bonusPercentage = getBonusPercentage(salary);    int bonus = bonusPercentage * noOfSales;    return bonus;  }  public static void main(String[] args) {    Employee john = new Employee( John , 5000, 5);    john. bonus = findEmployeeBonus(john. salary, john. sales);    System. out. println(john. bonus);  }}Click on the slides and move forward/backward using arrow keys to see how the above program is executed and how the stack and heap memory is used:                                                Note: If the slides look cut off at edges, then click on the title of the slide or here to open it directly in SpeakerDeck. As you can see:  Static fields are kept in a separate block on the Stack Every function call is added to the thread‚Äôs stack memory as a frame-block All local variables including arguments and the return value is saved within the function frame-block on the Stack All primitive types like int are stored directly on the Stack. This applies to static fields as well All object types like Employee, Integer, String are created on the Heap and is referenced from the Stack using Stack pointers. This applies to static fields as well Functions called from the current function is pushed on top of the Stack When a function returns its frame is removed from the Stack Once the main process is complete the objects on the Heap do not have any more pointers from Stack and becomes orphan Unless you make a copy explicitly, all object references within other objects are done using pointersThe Stack as you can see is automatically managed and is done so by the operating system rather than JVM itself. Hence we do not have to worry much about the Stack. The Heap, on the other hand, is not automatically managed by the OS and since its the biggest memory space and holds dynamic data, it could grow exponentially causing our program to run out of memory over time. It also becomes fragmented over time slowing down applications. This is where the JVM helps. It manages the Heap automatically using the garbage collection process. JVM Memory management: Garbage collectionNow that we know how JVM allocates memory, let us see how it automatically manages the Heap memory which is very important for the performance of an application. When a program tries to allocate more memory on the Heap than that is freely available(depending on the Xmx config) we encounter out of memory errors. JVM manages the heap memory by garbage collection. In simple terms, it frees the memory used by orphan objects, i. e, objects that are no longer referenced from the Stack directly or indirectly(via a reference in another object) to make space for new object creation.  The garbage collector in JVM is responsible for:  Memory allocation from OS and back to OS.  Handing out allocated memory to the application as it requests it.  Determining which parts of the allocated memory is still in use by the application.  Reclaiming the unused memory for reuse by the application. There are many different algorithms available for garbage collection but Mark &amp; Sweep is the most commonly used one. Mark &amp; Sweep Garbage collection: JVM uses a separate daemon thread that runs in the background for garbage collection and the process runs when certain conditions are met. Mark &amp; Sweep GC generally involves two phases and sometimes there is an optional third phase depending on the algorithm used.   Marking: First step where garbage collector identifies which objects are in use and which ones are not in use. The objects in use or reachable from GC roots(Stack pointers) recursively are marked as alive.  Sweeping: The garbage collector traverses the heap and removes any object that is not marked alive. This space is now marked as free.  Compacting: After deleting unused objects, all the survived objects will be moved to be together. This will decrease fragmentation and increase the performance of allocation of memory to newer objectsThis type of GC is also referred to us stop-the-world GC as they introduce pause-times in the application while performing GC. JVM offers few different algorithms to choose from when it comes to GC and there might be few more options available depending on the JDK vendor you use(Like the Shenandoah GC, available on OpenJDK). The different implementations focus on different goals like:  Throughput: Time spent collecting garbage instead of application time affects throughput. The throughput ideally should be high(I. e when GC times are low).  Pause-time: The duration for which GC stops the application from executing. The pause-time ideally should be very low.  Footprint: Size of the heap used. This ideally should be kept low. Collectors available as of JDK 11: As of JDK 11, which is the current LTE version, the below garbage collectors are available and the default used is chosen by JVM based on hardware and OS used. We can always specify the GC to be used with the -XX switch as well.  Serial Collector: It uses a single thread for GC and is efficient for applications with small data sets and is most suitable for single-processor machines. This can be enabled using -XX:+UseSerialGC switch.  Parallel Collector: This one is focused on high throughput and uses multiple threads to speed up the GC process. This is intended for applications with medium to large data sets running on multi-threaded/multi-processor hardware. This can be enabled using -XX:+UseParallelGC switch.  Garbage-First(G1) Collector: The G1 collector is a mostly concurrent collector(Means only expensive work is done concurrently). This is for multi-processor machines with a large amount of memory and is enabled as default on most modern machines and OS. It has a focus on low pause-times and high throughput. This can be enabled using -XX:+UseG1GC switch.  Z Garbage Collector: This is a new experimental GC introduced in JDK11. It is a scalable low-latency collector. It‚Äôs concurrent and does not stop the execution of application threads, hence no stop-the-world. It is intended for applications that require low latency and/or use a very large heap(multi-terabytes). This can be enabled using -XX:+UseZGC switch. GC process: Regardless of the collector used, JVM has two types of GC process depending on when and where its performed, the minor GC and major GC. Minor GC: This type of GC keeps the young generation space compact and clean. This is triggered when below conditions are met:  JVM is not able to get the required memory from the Eden space to allocate a new objectInitially, all the areas of heap space are empty. Eden memory is the first one to be filled, followed by survivor space and finally by tenured space. Let us look at the minor GC process: Click on the slides and move forward/backward using arrow keys to see the process:                                                Note: If the slides look cut off at edges, then click on the title of the slide or here to open it directly in SpeakerDeck.  Let us assume that there are already objects on the Eden space when we start(Blocks 01 to 06 marked as used memory) The application creates a new object(07) JVM tries to get required memory from Eden space, but there is no free space in Eden to accommodate our object and hence JVM triggers minor GC The GC recursively traverses the object graph starting from stack pointers to mark objects that are used as alive(Used memory) and remaining objects as garbage(Orphans) JVM chooses one random block from S0 and S1 as the ‚ÄúTo Space‚Äù, let‚Äôs assume it was S0. The GC now moves all the alive objects into the ‚ÄúTo Space‚Äù, S0, which was empty when we started and increments their age by one.  The GC now empties the Eden space and the new object is allocated memory in the Eden space Let us assume that some time has passed and there are more objects on the Eden space now(Blocks 07 to 13 marked as used memory) The application creates a new object(14) JVM tries to get required memory from Eden space, but there is no free space in Eden to accommodate our object and hence JVM triggers second minor GC The mark phase is repeated and alive/orphan objects are marked including the ones in survivor space ‚ÄúTo Space‚Äù JVM chooses the free S1 as the ‚ÄúTo Space‚Äù now and S0 becomes ‚ÄúFrom Space‚Äù. The GC now moves all the alive objects from Eden space and the ‚ÄúFrom Space‚Äù, S0, into the ‚ÄúTo Space‚Äù, S1, which was empty when we started and increments their age by one. Since some objects don‚Äôt fit here, they are moved to the ‚ÄúTenured Space‚Äù as the survivor space cannot grow and this process is called premature promotion. This can happen even if one of the survivor space is free The GC now empties the Eden space and the ‚ÄúFrom Space‚Äù, S0, and the new object is allocated memory in the Eden space This keeps on repeating for each minor GC and the survivors are shifted between S0 and S1 and their age is incremented. Once the age reaches the ‚Äúmax-age threshold‚Äù, 15 by default, the object is moved to the ‚ÄúTenured space‚ÄùSo we saw how minor GC reclaims space from the young generation. It is a stop-the-world process but it‚Äôs so fast that it is negligible most of the time. Major GC: This type of GC keeps the old generation(Tenured) space compact and clean. This is triggered when below conditions are met:  Developer calls System. gc(), or Runtime. getRunTime(). gc() from the program.  JVM decides there is not enough tenured space as it gets filled up from minor GC cycles.  During minor GC, if the JVM is not able to reclaim enough memory from the Eden or survivor spaces.  If we set a MaxMetaspaceSize option for the JVM and there is not enough space to load new classes. Let us look at the major GC process, it‚Äôs not as complex as minor GC:  Let us assume that many minor GC cycles have passed and the tenured space is almost full and JVM decides to trigger a ‚ÄúMajor GC‚Äù The GC recursively traverses the object graph starting from stack pointers to mark objects that are used as alive(Used memory) and remaining objects as garbage(Orphans) in the tenured space. If the major GC was triggered during a minor GC the process includes the young(Eden &amp; Survivor) and tenured space The GC now removed all orphan objects and reclaims the memory During a major GC event, if there are no more objects in the Heap, the JVM reclaims memory from the metaspace as well by removing loaded classes from it this is also referred to as full GCConclusionThis post should give you an overview of the JVM memory model and memory management. This is not exhaustive, there are a lot more advanced concepts and tuning options available for specific use cases and you can learn about them from https://docs. oracle. com. But for most JVM(Java, Kotlin, Scala, Clojure, JRuby, Jython) developers this level of information would be sufficient and I hope it helps you write better code considering these in mind for more performant applications and keeping these in mind would help you to avoid the next memory leak issue you might encounter otherwise. I hope you had fun learning about the JVM internals, stay tuned for the next post in the series. References https://docs. oracle. com http://pythontutor. com/java. html https://www. journaldev. com https://www. yourkit. com https://dzone. com https://www. infoq. comIf you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. Also published on Dev. to "
    }, {
    "id": 12,
    "url": "/life-of-a-full-stack-developer/",
    "title": "üò± ü§Ø üò± Life of a Full-stack developer üò± ü§Ø üò±",
    "body": "2020/01/19 - Please follow me on Twitter for updates and let me know what can be improved in the post. Hello friends, the second edition of my book ‚ÄúFull Stack Development with JHipster‚Äù, co-authored with Sendil Kumar N, is published this week and I thought of dedicating it to all the Full Stack Developers out there. Disclaimer: This article contains excerpts from my book ‚ÄúFull Stack Development with JHipster ‚Äì Second Edition‚Äù published by Packt. According to the Stack Overflow developer survey 2019, full stack developer is the most popular developer title. The software industry defines a full stack developer as someone who can work on different areas of an application stack. The term stack refers to the different components and tools that make up an application. In terms of web application development, the stack can be broadly classified into two areas‚Äîfrontend and backend stack, also known as the client-side and server-side stack. The term frontend generally refers to the part of the code that is responsible for rendering the user interface, and the term backend refers to the part that is responsible for the business logic, database interactions, user authentication, server configuration, and so on. There is also the DevOps part of the application, which includes continuous integration, production deployment, and so on. A full-stack Java web application developer is expected to work on both frontend and backend technologies, ranging from writing HTML/JavaScript for the user interface to writing Java class files for business logic and SQL queries for database operations. They are also expected to work on DevOps, ranging from production deployments to setting up continuous integration and continuous delivery (CI/CD) as required. With an ever-evolving software architecture landscape, the scope of technologies that a full stack web developer is expected to work with has increased dramatically. It is no longer enough that we can write HTML and JavaScript to build a user interface ‚Äî we are expected to know client-side frameworks, such as Angular, React, and Vue. js. It is also not enough that we are proficient in enterprise Java and SQL ‚Äî we are expected to know server-side frameworks, such as Spring, Hibernate, Play, and Quarkus. Modern full-stack web development: The life of a full stack developer would be worthy of a whole book by itself, so let‚Äôs leave that topic for another day. Expectations from #java full stack developer these days. . spring/#quarkus/micronautsql/nosql#react/angular/vueWebpack/bazel/rollupJs/ts, html, css/sass#docker, #kubernetesaws/azure/gcp#devops, terraform/cloudformationShell scripting, maven/gradleMilking a unicorn ü¶Ñ pic. twitter. com/bCFYHsBbKs &mdash; Deepu K Sasidharan ( ‡¥¶‡µÄ‡¥™‡µÅ, ‡Æ§‡ØÄ‡Æ™‡ØÅ, ‡§¶‡•Ä‡§™‡•Ç ) (@deepu105) August 5, 2019Instead, let‚Äôs look at a user story from a full-stack Java web application and see what is involved. What a day looks like: Let‚Äôs use an example of developing a user management module for a typical Java web application. Let‚Äôs assume that you would be writing unit test cases for all of the code, and so we won‚Äôt look at it in detail here:  You would start by designing the architecture for the feature. You would decide on the plugins and frameworks to use, patterns to follow, and so on.  You will be modeling the domain model for the feature depending on the database technology used.  Then, you would create server-side code and database queries to persist and fetch data from the database.  Once the data is ready, you would implement the server-side code for any business logic.  Then, you would implement an API that can be used to provide data for the presentation over an HTTP connection.  You would write integration tests for the API.  Since the backend is ready, you would start writing frontend code in JavaScript or similar technology.  You would write client-side services to fetch data from the backend API.  You would write client-side components to display the data on a web page.  You would build the page and style it as per the design provided.  You would write some automated end-to-end tests for the web page.  You are not done yet. Once you have tested whether everything works locally, you would create pull requests or check the code into the version control system used.  You would wait for the continuous integration process to verify everything and fix anything that is broken.  Once everything is green and the code is accepted, you would typically start the deployment of this feature to a staging or acceptance environment, either on-premises or to a cloud provider using technologies like Docker and Kubernetes. If you choose the latter, you would be expected to be familiar with the cloud technologies used as well. You would also be upgrading the database schema as necessary and writing migration scripts when required.  Once the feature is accepted, you might be responsible for deploying it into the production environment in a similar way, troubleshooting issues where necessary. In some teams, you might swap the steps with other team members so that you would be deploying a feature developed by your coworker while they deploy yours.  You might also be responsible, along with your coworkers, for making sure that the production environment is up and running, including the database, virtual machines, and so on. As you can see, it is no easy task. The range of responsibilities spans from making stylesheet updates on the client-side to running database migration scripts on a virtual machine in the production cloud service. If you are not familiar enough with the setup, then this would be a herculean task, and you would soon be lost in the vast ocean of frameworks, technologies, and design patterns out there. Challenges: Full-stack development is not for the faint-hearted. It takes a lot of time and effort to keep yourself up to date with the various technologies and patterns in multiple disciplines of software development. The following are some of the common problems you might face as a full stack Java developer:  Client-side development is not just about writing plain HTML and JavaScript anymore. It is becoming as complex as server-side development, with build tools, transpilers, frameworks, and patterns.  There is a new framework almost every week in the JavaScript world, and if you are coming from outside a Java background, it could be very overwhelming for you.  Container technologies such as Docker &amp; Kubernetes revolutionized the software industry, but they also introduced a lot of new stuff to learn and keep track of, such as orchestration tools and container management tools.  Cloud services are growing day by day. To stay on track, you would have to familiarize yourself with their APIs and related orchestration tools.  Java server-side technologies have also undergone a major shift in recent times with the introduction of JVM languages, such as Scala, Groovy, and Kotlin, forcing you to keep yourself up to date with them. On the other side, server-side frameworks are becoming more feature-rich, and therefore more complex. The most important thing of all is to make sure that all of these work well together when required. This task will need a lot of configuration, some glue code, and endless cups of coffee. Conclusion: It‚Äôs very easy to get lost here, and this is where technologies such as JHipster and Spring Boot step in to help. They help by providing the wiring between moving parts so that you only need to concentrate on writing business code. JHipster also helps by providing the abstractions to deploy and manage the application to various cloud providers. A full-stack developer is one of the toughest roles in our industry these days and I think it is one that is under-appreciated a lot. If you are a full stack developer be proud as it takes some courage to be one. You may not be an expert in a single technology or framework but you are a magician of sorts. You can juggle between so many technologies and frameworks without breaking a sweat. You are the real 10x developer, what the heck, you are a 100x developer, not because you use specific keys on your keyboard more than others, its because your job used to be something that required at least four people to work together. You may not get enough credits, though you deserve it just for the effort that is required to keep up, you are awesome. Though the satisfaction of being able to work on all aspects of application development is rewarding, It is still a shame that we are not getting the salary that is the sum paid to four people who were needed to do this work üòâ So if you are a proud full stack developer let me know in the comments and tell us how your day looks like. If you liked this article you might like my book as well. You can get it from Packt and Amazon.  If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. Cover image credit: Photo by Arian Darvishi on Unsplash Also published on Dev. to "
    }, {
    "id": 13,
    "url": "/memory-management-in-programming/",
    "title": "üöÄüíÜüöÄ Demystifying memory management in modern programming languages",
    "body": "2020/01/08 - Please follow me on Twitter for updates and let me know if something can be improved in the post. In this multi-part series, I aim to demystify the concepts behind memory management and take a deeper look at memory management in some of the modern programming languages. I hope the series would give you some insights into what is happening under the hood of these languages in terms of memory management. Learning about memory management will also help us to write more performant code as the way we write code also has an impact on memory management regardless of the automatic memory management technique used by the language. Part 1: Introduction to Memory managementMemory management is the process of controlling and coordinating the way a software application access computer memory. It is a serious topic in software engineering and its a topic that confuses some people and is a black box for some. What is it?: When a software runs on a target Operating system on a computer it needs access to the computers RAM(Random-access memory) to:  load its own bytecode that needs to be executed store the data values and data structures used by the program that is executed load any run-time systems that are required for the program to executeWhen a software program uses memory there are two regions of memory they use, apart from the space used to load the bytecode, Stack and Heap memory. Stack: The stack is used for static memory allocation and as the name suggests it is a last in first out(LIFO) stack (Think of it as a stack of boxes).  Due to this nature, the process of storing and retrieving data from the stack is very fast as there is no lookup required, you just store and retrieve data from the topmost block on it.  But this means any data that is stored on the stack has to be finite and static(The size of the data is known at compile-time).  This is where the execution data of the functions are stored as stack frames(So, this is the actual execution stack). Each frame is a block of space where the data required for that function is stored. For example, every time a function declares a new variable, it is ‚Äúpushed‚Äù onto the topmost block in the stack. Then every time a function exits, the topmost block is cleared, thus all of the variables pushed onto the stack by that function, are cleared. These can be determined at compile time due to the static nature of the data stored here.  Multi-threaded applications can have a stack per thread.  Memory management of the stack is simple and straightforward and is done by the OS.  Typical data that are stored on stack are local variables(value types or primitives, primitive constants), pointers and function frames.  This is where you would encounter stack overflow errors as the size of the stack is limited compared to the Heap.  There is a limit on the size of value that can be stored on the Stack for most languages. Stack used in JavaScript, objects are stored in Heap and referenced when needed. Here is a video of the same. Heap: Heap is used for dynamic memory allocation and unlike stack, the program needs to look up the data in heap using pointers (Think of it as a big multi-level library).  It is slower than stack as the process of looking up data is more involved but it can store more data than the stack.  This means data with dynamic size can be stored here.  Heap is shared among threads of an application.  Due to its dynamic nature heap is trickier to manage and this is where most of the memory management issues arise from and this is where the automatic memory management solutions from the language kick in.  Typical data that are stored on the heap are global variables, reference types like objects, strings, maps, and other complex data structures.  This is where you would encounter out of memory errors if your application tries to use more memory than the allocated heap(Though there are many other factors at play here like GC, compacting).  Generally, there is no limit on the size of the value that can be stored on the heap. Of course, there is the upper limit of how much memory is allocated to the application. Why is it important?: Unlike Hard disk drives, RAM is not infinite. If a program keeps on consuming memory without freeing it, ultimately it will run out of memory and crash itself or even worse crash the operating system. Hence software programs can‚Äôt just keep using RAM as they like as it will cause other programs and processes to run out of memory. So instead of letting the software developer figure this out, most programming languages provide ways to do automatic memory management. And when we talk about memory management we are mostly talking about managing the Heap memory. Different approaches?: Since modern programming languages don‚Äôt want to burden(more like trust üëÖ) the end developer to manage the memory of his/her application most of them have devised a way to do automatic memory management. Some older languages still require manual memory handling but many do provide neat ways to do that. Some languages use multiple approaches to memory management and some even let the developer choose what is best for him/her(C++ is a good example). The approaches can be categorized as below Manual memory management: The language doesn‚Äôt manage memory for you by default, it‚Äôs up to you to allocate and free memory for the objects you create. For example, C and C++. They provide the malloc, realloc, calloc, and free methods to manage memory and it‚Äôs up to the developer to allocate and free heap memory in the program and make use of pointers efficiently to manage memory. Let‚Äôs just say that it‚Äôs not for everyone üòâ. Garbage collection(GC): Automatic management of heap memory by freeing unused memory allocations. GC is one of the most common memory management in modern languages and the process often runs at certain intervals and thus might cause a minor overhead called pause times. JVM(Java/Scala/Groovy/Kotlin), JavaScript, C#, Golang, OCaml, and Ruby are some of the languages that use Garbage collection for memory management by default.   Mark &amp; Sweep GC: Also known as Tracing GC. Its generally a two-phase algorithm that first marks objects that are still being referenced as ‚Äúalive‚Äù and in the next phase frees the memory of objects that are not alive. JVM, C#, Ruby, JavaScript, and Golang employ this approach for example. In JVM there are different GC algorithms to choose from while JavaScript engines like V8 use a Mark &amp; Sweep GC along with Reference counting GC to complement it. This kind of GC is also available for C &amp; C++ as an external library.  Reference counting GC: In this approach, every object gets a reference count which is incremented or decremented as references to it change and garbage collection is done when the count becomes zero. It‚Äôs not very preferred as it cannot handle cyclic references. PHP, Perl, and Python, for example, uses this type of GC with workarounds to overcome cyclic references. This type of GC can be enabled for C++ as well. Resource Acquisition is Initialization (RAII): In this type of memory management, an object‚Äôs memory allocation is tied to its lifetime, which is from construction until destruction. It was introduced in C++ and is also used by Ada and Rust. Automatic Reference counting(ARC): Its similar to Reference counting GC but instead of running a runtime process at a specific interval the retain and release instructions are inserted to the compiled code at compile-time and when an object reference becomes zero its cleared automatically as part of execution without any program pause. It also cannot handle cyclic references and relies on the developer to handle that by using certain keywords. Its a feature of the Clang compiler and provides ARC for Objective C &amp; Swift. Ownership: It combines RAII with an ownership model, any value must have a variable as its owner(and only one owner at a time) when the owner goes out of scope the value will be dropped freeing the memory regardless of it being in stack or heap memory. It is kind of like Compile-time reference counting. It is used by Rust, in my research I couldn‚Äôt find any other language using this exact mechanism.  We have just scratched the surface of memory management. Each programming language uses its own version of these and employs different algorithms tuned for different goals. In the next parts of the series, we will take a closer look at the exact memory management solution in some of the popular languages. Stay tuned for upcoming parts of this series:  Part 2: Memory management in JVM(Java, Kotlin, Scala, Groovy) Part 3: Memory management in V8(JavaScript) Part 4: Memory management in Go Part 5: Memory management in Rust Part 6: Memory management in Python Part 7: Memory management in C++ Part 8: Memory management in C#References http://homepages. inf. ed. ac. uk https://javarevisited. blogspot. com http://net-informations. com https://gribblelab. org https://medium. com/computed-comparisons https://en. wikipedia. org/wiki/Garbagecollection(computer_science) https://en. wikipedia. org/wiki/Automatic_Reference_Counting https://blog. sessionstack. com/If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. Image credits:Stack visualization: Created based on pythontutor. Ownership illustration: Link Clark, The Rust team under Creative Commons Attribution Share-Alike License v3. 0. Also published on Dev. to "
    }, {
    "id": 14,
    "url": "/languages-to-learn-in-2020/",
    "title": "7 Languages to learn in 2020 with free resources to get started",
    "body": "2020/01/01 - Please follow me on Twitter for updates and let me know if there is something that could be improved in the post. We are at the dawn of another decade and the software industry is becoming bigger than ever. If you have to bet on a career than it would be software development. If you are already a software developer then there is so much to learn out there in the next decade. Let us start with programming Languages that you absolutely must learn if you haven‚Äôt already. These are the Languages that are on the rise and the ones that are not going away any time soon. My recommendations are also based on practicality and the advantage the language would you give you on the software development marketplace. So let‚Äôs start in no particular order. Kotlin: Kotlin is one of the fastest-growing languages in the last few years and is an excellent choice for a JVM language. It has great interoperability with Java, has great features and is not very complex to learn. Why:  JVM is still one of the biggest and most used platforms, especially trusted and used in enterprises world over.  JVM has a pretty great Job market and there is always a demand for JVM developers in the foreseeable future.  Kotlin‚Äôs interoperability with Java helps with adopting it incrementally.  Has simple and intuitive syntax, a great feature set and great concurrency and asynchronous programming support with Coroutines.  It is the language of choice these days for Android programming and hence gives you a wider scope if you wish to dive into mobile application development. Who should learn it:  If you are a Java programmer and you are looking to learn a language that you can use without having to switch completely to a new stack.  If you are interested in the JVM but you think Java is not cool anymore.  Web application developers or full-stack developers who want to learn a new language.  If you are interested in Android application development then Kotlin is the place to start. Where to start:  The official tutorial is a great place to start and its free with an interactive playground. The official getting started guides can be found here.  This is a nice and free tutorial on medium for Android development with Kotlin.  This Udemy course is great if you want to focus on Android development with Kotlin. It‚Äôs not a free course though. Golang: Golang is a simple language by design and has become hugely popular thanks to the marketing from google and early adoption by popular tools like Docker and Kubernetes. Here is my detailed review of the language.                               My reflections on Golang:             12-Jul-2019                           #go #programming #languages #thepragmaticprogrammer                                    Why:  One of the simplest language to learn and a great community.  It has pretty good performance and can be used as a general-purpose language if you are not bothered by the boilerplate.  A great choice for use cases with heavy concurrency or parallelism requirements.  It has a good demand in the job market and its adoption is only increasing with many big names using Golang for their main platforms. Who should learn it:  Developers working with languages like C, C++ would be at home with Go, while you might find the features limited, once you get used to it its a great language to have in your arsenal.  System programmers looking to learn a new language will find Go pretty descent.  DevOps engineers who are more on the Ops side looking to learn a language would find Go quite handy.  If you are writing microservices than Golang is a good choice for that and you should learn it.  If you are a front-end developer wishing to venture into web assembly, then Go is one of the easiest languages to start with as it supports web assembly. Where to start:  The official tour of Go is a great place to start and its free with an interactive playground.  This freeCodeCamp video tutorial if you prefer videos. TypeScript: You like it or not JavaScript is here to stay as long as the internet is around. So if you are not already a fan why not embrace it in the form of TypeScript instead of hating it.                               My love-hate relationship with JavaScript:             21-Nov-2019                           #javascript #programming #languages #thepragmaticprogrammer                                    Why:  JavaScript is the most used language and has the biggest ecosystem and TypeScript being a strict superset of JavaScript means you can make use of it any use case that JavaScript can handle.  TypeScript is one of the rapidly growing languages and will help with some of the shortcomings in JavaScript.  Demand for front-end engineers is never going away and with MVVM frameworks like Angular, React and Vue it‚Äôs only rising.  The extent of the JavaScript/TypeScript ecosystem spreads from front-end to desktop to serverside to robotics. So you can say JavaScript is everywhere. Who should learn it:  JavaScript developers should learn TypeScript, it will make maintaining big JavaScript projects easier and will help you write better code.  If you are coming from a strictly typed language background and you are thinking of exploring the world of frontend engineering then TypeScript is a great place to start.  If you are Java developer and want to do front-end, then TypeScript is easier to start with due to its similarity to Java.  You want to get your hands dirty with Angular, React or Vue but you hate JavaScript then TypeScript should be your logical choice.  If you are planning to learn Angular framework then knowing TypeScript is a must.  If you are considering a career in IT as a front-end developer, then JavaScript is the ultimate choice and once you learned JavaScript then TypeScript is a logical next step. Where to start:  This is a detailed tutorial on TypeScript and is free.  This is a free quickstart guide if you don‚Äôt want to spend too much time.  This video tutorial from one of my conference deep dive session if you want to see advanced TypeScript features in action. Python: Python has been around for a while and in recent times it has seen a sudden increase in popularity. The popularity of data science and machine learning should be attributed to that as Python has become the go-to Language in those fields. Why:  Python is a general-purpose language and like JavaScript, it has a wide scope of application.  It‚Äôs a dynamic language like JavaScript and hence great for scripting.  It‚Äôs becoming the go-to language for machine learning and data science.  It has a great job market and a huge community. Who should learn it:  If you are looking to get into data science or machine learning, then Python is your language.  DevOps engineers will find Python easy to start with and great for general-purpose scripting.  If you are looking to learn a general-purpose language then Python is a great choice. Where to start:  The official Python tutorial here.  This free and interactive tutorial.  This w3school tutorial with interactive playground. Rust: Rust is the most loved language according to the Stack Overflow developer survey last few years, not only this, the language is gaining momentum and is one of the fastest-growing languages. Here is my detailed review of Rust.                               My first impressions of Rust:             07-Nov-2019                           #rust #programming #languages #thepragmaticprogrammer                                    Why:  A great alternative to C/C++ with similar performance and better memory safety.  Extremely memory safe, highly performant and flexible language.  Suitable for low-level programming and hence a great choice for systems programming, concurrency and so on.  It has web assembly support. Who should learn it:  C/C++ programmers should consider learning Rust. Its a better alternative to C/C++ IMO and is more future proof.  If you are a systems programmer, then you should learn Rust as it‚Äôs becoming a fast-growing choice in that space.  If you are a front-end developer wishing to venture into web assembly, then Rust is a great choice as it supports web assembly. It might not be as easy as Golang to start with but definitely a great choice.  If you are a developer writing low-level programs that requires extreme memory safety, performance and memory efficiency then Rust is a great choice with its memory safety guarantee, Ownership model and pointer support. You can tune your programs to be very memory efficient.  If you are into concurrency and parallelism then Rust has great support for that with a pluggable multi-threading model which you can tune to your likeness. With libraries like Tokio, you can achieve great concurrency performance while maintaining memory safety. Where to start:  The official Rust book is the best place to get started. It‚Äôs free and interactive.  The official Rust by examples if you want to learn hands-on. Java: If you are a millennial you might think that Java is too old school and not cool anymore, but I assure you that Java will outlive a lot of languages that are considered new and cool. Java is one of the most mature languages out there and the with current release model of Java new features are being added twice a year closing the gap with other modern languages. Why:  JVM is still one of the biggest and most used platforms, especially trusted and used in enterprises world over.  JVM has a pretty great Job market and there is always a demand for JVM developers in the foreseeable future.  It has simple syntax, a great feature set, and a huge ecosystem and community.  It is the language of choice for enterprises and has some of the most stable and trusted web application frameworks and libraries in the ecosystem.  It has one of the best ecosystems around it for building web applications and especially enterprise web applications. Who should learn it:  If you are a front end engineer and you want to become a full-stack engineer then JVM is a great choice as it has the best Job market for full-stack engineers.  Web application developers or full-stack developers who want to learn a JVM language.  If you are considering a career in IT as a backend developer, but you are unsure then JVM and Java is a safe bet and it has a great community and ecosystem to help you. Where to start:  This w3school interactive tutorial to get a nice introduction.  This interactive tutorial on JavaTpoint.  This video tutorial. C#¬†: C# is one of the popular languages in the programming world and is the go-to choice in the . NET world. It is a multiparadigm language suitable for different styles of programming. Like Java, JavaScript and Python it has retained its position in the top 10 languages in most of the language surveys. Why:  It‚Äôs kind of a defacto choice for Windows programming and Windows is still the most used OS in the world.  Well integrated with Windows and . NET platform with great support for enterprise applications.  general-purpose language can be used for web applications, desktop applications, CLI tools and so on.  It has a great Job market because Windows has a major market share in terms of OS usage and enterprise usage. Who should learn it:  If you are thinking of programming applications for Windows or . NET then this should be your language of choice.  If you are a Java developer and want to learn . NET then C# is the logical choice as it has a great syntax and concept resemblance to Java. Where to start:  This w3school interactive tutorial to get a nice introduction.  This exhaustive tutorial on JavaTpoint. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. Cover image credit: Based on official logos. Also published on Dev. to "
    }, {
    "id": 15,
    "url": "/three-tips-for-clean-code/",
    "title": "3 tips for clean & efficient code",
    "body": "2019/12/16 - Please follow me on Twitter for updates and let me know what can be improved in the post. One of the most important aspect of software engineering is code quality and one of the most important criteria should be readability and maintainability of your code, especially when working in teams where others have to read and understand your code. The best code in my opinion is that doesn‚Äôt need any explanation or even documentation and that even a complete beginner can read and understand.  It is easy to write complex and cryptic piece of code. It is much harder to write simple and readable code. It is easy to get carried away and write long and complex functions and code that shows off how smart you are and how you can write something in the smartest way, especially when you area beginner and you are trying impress your peers. But the smartest way might not be the most readable and maintainable way. It doesn‚Äôt take a lot of skill to do that IMO, but writing simple and clean code that is easy to read and maintain takes skill. Its not a skill that you can acquire overnight, its something you develop over the years. Below are some tips to make your code more efficient, readable, easy to navigate and more maintainable. This is not an exhaustive list, its just some of them that could help. 1. Fail fast and early: When writing any logic try to do the failure assertions as early as possible and fail fast. It makes programs feel faster as you wouldn‚Äôt execute a lot of stuff first just to fail at the end for something that you could have checked to begin with. This approach also makes your code easier to understand as it makes intent much clearer. Consider the below function, let us use JavaScript on NodeJS for simplicity. Note that i‚Äôm using the syncrnous methods from the NodeJS FileSystem API for simplicity. 123456789101112131415function processFile(filePath) {  if (fs. existsSync(filePath)) {    // check if file exists    var fileContent = fs. readFileSync(filePath,  utf8 ); // read the file content    if (fileContent !==   ) {      console. log( Content found );      // do stuff    } else {      throw Error( No content found on file! );    }  } else {    throw Error( File not found! );  }}We are fetching the given file and doing some processing on it, if the file is not found or if the content is empty we throw an error. There is nothing wrong with this method but if you have a lot of steps in processing the reader has to go through all that first to see the error handling hence the intent is not that clear, also the cyclomatic complexity of the function is higher due to multiple if/else. Consider the below version of the same function 123456789101112131415function processFile(filePath) {  if (!fs. existsSync(filePath)) {    // check if file does not exist    throw Error( File not found! );  }  var fileContent = fs. readFileSync(filePath,  utf8 ); // read the file content  if (fileContent ===   ) {    throw Error( No content found on file! );  }  console. log( Content found );  // do stuff}This does the same logic but is less complex and more readable. It has less cyclomatic complexity and the intent is clear 2. Return early: Similar to failing early it is also much nicer to return early, i. e use the language‚Äôs ability to flow code based on returns to reduce the complexity of code and improve readability and intent. Consider the below logic added to our function 1234567891011121314151617181920function processFile(filePath) {  . . .   console. log( Content found );  // check if the file content is base64 encoded: Lib used https://github. com/miguelmota/is-base64  if (isBase64(fileContent. trim())) {    console. log( Decoding content );    // check if the base64 content is image and return a placeholder    if (isBase64(fileContent. trim(), { allowMime: true })) {      return  Image content ;    } else {      // decode to string      var buffer = Buffer. from(fileContent,  base64 );      var decoded = buffer. toString( ascii );      return decoded;    }  } else {    return fileContent;  }}The logic checks if the content is base64 encoded, and if not decodes it. Again the function works fine but consider the below version as well 12345678910111213141516171819function processFile(filePath) {  . . .   console. log( Content found );  // check if the base64 content is image and return a placeholder  if (isBase64(fileContent, { allowMime: true })) {    return  Image content ;  }  // check if the file content is not base64 encoded: Lib used https://github. com/miguelmota/is-base64  if (!isBase64(fileContent. trim())) {    return fileContent;  }  console. log( Decoding content );  // decode to string  var buffer = Buffer. from(fileContent,  base64 );  var decoded = buffer. toString( ascii );  return decoded;}Isn‚Äôt this much simpler and easier to reason with. So try to return early and keep the code flow simple. 3. Write small focused functions: Finally do not write huge functions, even if you are doing imperative style of programming try to break it down into small functions as much as possible. The above example is not a huge function, but still you could break it logically into two as below 12345678910111213141516171819202122function decodeBase64(fileContent) {  // check if the base64 content is image and return a placeholder  if (isBase64(fileContent, { allowMime: true })) {    return  Image content ;  }  // check if the file content is not base64 encoded: Lib used https://github. com/miguelmota/is-base64  if (!isBase64(fileContent. trim())) {    return fileContent;  }  console. log( Decoding content );  // decode to string  var buffer = Buffer. from(fileContent,  base64 );  var decoded = buffer. toString( ascii );  return decoded;}function processFile(filePath) {  . . .   console. log( Content found );  return decodeBase64(fileContent);}Having smaller focused functions helps with following  Unit testing becomes easier.  Functions become reuseable and composable.  Easier to focus and read, without having to build a mental model of the entire logic Easier to change something in a small function than in a huge one, as you will have less cases to worry about.  Easier to debug and easier to spot bugs.  reduces side effects as the function does something very focused. Bonus: Write pure functions: This is not a functional programming thing, though it was made popular by FP. In general mutations are always tricky and could cause unwanted bugs. When we try to avoid side effects(includes external date mutations) by keeping small functions pure we also reduce the surface area for such bugs. So keep your pure functions separate from impure functions and try to write as much as pure functions. Do side-effects and external data/state mutations from within a unction only if its unavoidable. You can follow this regardless of programming paradigm you are following. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. Cover image credit: Photo by Christopher Robin Ebbinghaus on Unsplash Also published on Dev. to "
    }, {
    "id": 16,
    "url": "/golang-for-javascript-developers-part-2/",
    "title": "Golang for JavaScript developers - Part 2",
    "body": "2019/12/12 - Please follow me on Twitter for updates and let me know what can be improved in the post. If you are a JavaScript developer thinking about learning another programming language, then Golang is a great choice. It is simple, has a lot of momentum, is very performant and has some similarities to JavaScript. This post is not a comparison of the languages or is stating that they are very similar. Its a guide for JavaScript developers to grasp Golang quickly. There are many aspects of Go that are entirely different from JavaScript. We will touch upon that as well. In the previous part of this series, we learned about things that are more similar between JS and Go. We touched upon:  Functions Scope Flow control Memory managementIn this part of the series, we will touch upon things that are more different between JS and Go. If you haven‚Äôt read the previous part please read it first. Things that are more differentAs you can see there are more things in this part than previous, but please also note that some differences are quite subtle so it would be easy to digest for a JavaScript developer. Types &amp; Variables: This is one of the main differences. JavaScript is dynamic and loosely typed and Go is static and strictly typed. JavaScript 123456789101112131415var foo = {  message:  hello };var bar = foo;// mutatebar. message =  world ;console. log(foo. message === bar. message); // prints 'true'// reassignbar = {  message:  mars };console. log(foo. message === bar. message); // prints 'false'Go 1234567891011121314151617181920212223242526272829var foo = struct {  message string}{ hello }var bar = foo // will create a copy of foo and assign to bar// mutates only bar// note bar. message is short for (*bar). messagebar. message =  world fmt. Println(foo. message == bar. message) // prints  false // reassign barbar = struct {  message string}{ mars }fmt. Println(foo. message == bar. message) // prints  false var barPointer = &amp;foo // assigns pointer to foo// mutates foobarPointer. message =  world fmt. Println(foo. message == barPointer. message) // prints  true // reassigns foo*barPointer = struct {  message string}{ mars }fmt. Println(foo. message == bar. message) // prints  true Similarities:  There is no much similarity other than the name of keywords var and const. var keyword in Go is closer to let keyword in JS in terms of behavior.  Multiple var can be declared together like var a, foo, bar int; similar to JS. But in Go, you can go further and initialize them as well like var a, foo, bar = true, 10,  hello . In JS you can do a destructuring assignment for similar effect like var [a, foo, bar] = [true, 10,  hello ]Differences:  Go needs type information at compile time either by specified type or from type inference.  Go has value types(primitives, arrays, and structs), reference types(slice, map &amp; channels) and pointers. JS has value types(primitives) and reference types(objects, arrays, functions).  The type of a variable cannot be changed after the declaration in Go.  Variables assignments cannot use short-circuit expressions in Go.  var has a shorthand syntax with := inside Go functions.  Go strictly doesn‚Äôt let you have unused variables, any unused variable must be named as _, which is a reserved character.  JS does not have private/public access modifiers(There is a proposal to add it), In Go, however, you can modify that using the naming convention. Starting a filed, variable name with uppercase will make it public and lowercase will make it private.  const in Go is not the same as in JavaScript. Only primitives like character, string, boolean, or numeric values can be assigned to constants in Go.  Arrays in Go are different from JS as they are fixed length. JS arrays are dynamic and hence are more similar to Go slices which are slices of an array with dynamic length. JavaScript 1234567const foo = [ Rick ,  Morty ];// Adds to the end of the array. foo. push( Beth );// Removes from the end of the array. element = foo. pop();Go 12345678910foo := []string{ Rick ,  Morty } // creates a slice// Adds to the end of the array. foo = append(foo,  Beth )// Removes from the end of the array. n := len(foo) - 1 // index of last elementelement := foo[n] // optionally also grab the last elemenfoo = foo[:n]   // remove the last element JavaScript has Object, Map/Set and WeakMap/WeakSet that can be used as dictionaries and sets. Go has only a simple Map which is more similar to JavaScript Object and hence serves the purpose. Also, note that maps in Go are not ordered. JavaScript 123456789const dict = {  key1: 10,  key2:  hello };const stringMap = {  key1:  hello ,  key2:  world };Go 123456789var dict = map[string]interface{}{   key1 : 10,   key2 :  hello ,}var stringMap = map[string]string{   key1 :  hello ,   key2 :  world ,}Mutability: Another major difference between JS and Go is how variable mutations are handled. In JavaScript, every non-primitive variable is passed by reference and there is no way to change that behavior whereas in Go everything except slice, map &amp; channels are passed by value and we can choose to change that by explicitly passing a pointer to a variable instead. Because of this in Go, we have more control over mutability than in JS. Another notable difference is that in Javascript we can prevent reassignment of variables using the const keyword which is not possible in Go. We saw some mutability in action in the above section, let‚Äôs see a bit more JavaScript 123456789let foo = {  msg:  hello };function mutate(arg) {  arg. msg =  world ;}mutate(foo);console. log(foo. msg); // prints 'world'Go 1234567891011121314151617type Foo struct {  msg string}var foo = Foo{ hello }var tryMutate = func(arg Foo) {  arg. msg =  world }tryMutate(foo)fmt. Println(foo. msg) // prints 'hello'var mutate = func(arg *Foo) {  arg. msg =  world }mutate(&amp;foo)fmt. Println(foo. msg) // prints 'world'Error handling: The only similarity in terms of error handling between Go and JS is that errors are also just value types. In both languages, you can pass errors as values. Apart from the above error handling are quite different in both. In JavaScript, we can either;  use a try/catch mechanism to catch errors from synchronous functions and asynchronous functions that use async/await handle errors by passing them to callback functions or using promises for asynchronous functions. In Go there is no try/catch mechanism, the only way to handle the error is by returning it as a value from a function or by halting execution with a panic function or using the recover function in a defer block to rescue the execution. This makes error handling quite verbose in Go and you will often see the famous if err != nil statement in Go. JavaScript 123456789101112131415161718192021222324252627282930313233function errorCausingFunction() {  throw Error( Oops );}try {  errorCausingFunction();} catch (err) {  console. error(`Error: ${err}`);} finally {  console. log(`Done`);}// prints// Error: Error: Oops// Done// or the async wayfunction asyncFn() {  try {    errorCausingFunction();    return Promise. resolve();  } catch (err) {    return Promise. reject(err);  }}asyncFn()  . then(res =&gt; console. log(`:)`))  . catch(err =&gt; console. error(`Error: ${err}`))  . finally(res =&gt; console. log(`Done`));// prints// Error: Error: Oops// DoneGo 123456789101112131415161718192021222324252627282930var errorCausingFunction = func() error {  return fmt. Errorf( Oops )}err := errorCausingFunction()defer fmt. Println( Done ) // Closest to finally, but executes only at end of the enclosing functionif err != nil {  fmt. Printf( Error: %s\n , err. Error())} else {  fmt. Println( :) )}// prints// Error: Oops// Done// orerr := errorCausingFunction()defer func() { // Closest thing to finally behaviour, but executes only at end of the enclosing function  if err := recover(); err != nil {    fmt. Println( Recovered from err , err) // closest thing to catch behaviour  }  fmt. Println( Done )}()if err != nil {  panic(err)} else {  fmt. Println( :) )}Composition instead of inheritance: In JavaScript, we can use inheritance to extend or share behavior while Go choose composition instead. There is also prototype level inheritance in JavaScript and the possibility of doing composition due to the flexible nature of the language. JavaScript 123456789101112131415161718192021222324class Animal {  species;  constructor(species) {    this. species = species;  }  species() {    return this. species;  }}class Person extends Animal {  name;  constructor(name) {    super( human );    this. name = name;  }  name() {    return this. name;  }}var tom = new Person( Tom );console. log(`${tom. name} is a ${tom. species}`); // prints 'Tom is a human'Go 12345678910111213141516171819202122232425262728293031323334type IAnimal interface {	Species() string}type IPerson interface {	IAnimal // composition of IAnimal interface	Name() string}type Animal struct {	species string}type Person struct {	Animal // composition of Animal struct	name  string}func (p *Person) Name() string {	return p. name}func (p *Animal) Species() string {	return p. species}func NewPerson(name string) IPerson {	return &amp;Person{Animal{ human }, name}}func main() {	var tom IPerson = NewPerson( Tom )	fmt. Printf( %s is a %s\n , tom. Name(), tom. Species()) // prints 'Tom is a human'}Concurrency: Concurrency is one of the most important features of Golang and this is where it really shines. JavaScript technically is single-threaded and hence there is no real native concurrency there. The addition of service workers brings some support for parallelism but is still no match for the power and simplicity of goroutines. Concurrency is not the same as asynchronous or reactive programming for which JavaScript has great support. 1234567891011121314151617181920212223// Sequentialasync function fetchSequential() {  const a = await fetch( http://google. com/ );  console. log(a. status);  await a. text();  const b = await fetch( http://twitter. com/ );  console. log(b. status);  await b. text();}// Concurrent but not multi threadedasync function fetchConcurrent() {  const values = await Promise. all([    fetch( http://google. com/ ),    fetch( http://twitter. com/ )  ]);  values. forEach(async resp =&gt; {    console. log(resp. status);    await resp. text();  });}Go, on the other hand, is fully geared towards concurrency and parallelism. The concepts are built into the language using goroutines and channels. It is also possible to do asynchronous programming in Go but it looks more verbose than the JS equivalent. This means you can write API as sync and use it in an async way using goroutines and Go community generally advocates against writing asynchronous APIs. 12345678910111213141516171819202122232425262728293031323334// Sequentialfunc fetchSequential() {	respA, _ := http. Get( http://google. com/ )	defer respA. Body. Close()	fmt. Println(respA. Status)	respB, _ := http. Get( http://twitter. com/ )	defer respB. Body. Close()	fmt. Println(respB. Status)}// Concurrent and multithreadedfunc fetchConcurrent() {	resChanA := make(chan *http. Response, 0)	go func(c chan *http. Response) {		res, _ := http. Get( http://google. com/ )		c &lt;- res	}(resChanA)	respA := &lt;-resChanA	defer respA. Body. Close()	fmt. Println(respA. Status)	resChanB := make(chan *http. Response, 0)	go func(c chan *http. Response) {		res, _ := http. Get( http://twitter. com/ )		c &lt;- res	}(resChanB)	respB := &lt;-resChanB	defer respB. Body. Close()	fmt. Println(respB. Status)}Compilation: JavaScript is interpreted and not compiled. Some JS engines use JIT compilation but to developers, it doesn‚Äôt matter as we do not have to compile JavaScript in order to run it. Transpiling using TypeScript or Babel doesn‚Äôt count üòâ Go is compiled and hence offers compile-time type safety and to an extent memory safety. Paradigm: JavaScript is Object-oriented primarily but you can easily write imperative or functional-style code due to the flexibility of the language. The language is quite free form and really doesn‚Äôt enforce anything. It is not opinionated and doesn‚Äôt provide any tooling out of the box. The developer would need to set up his/her own tooling. Go is imperative primarily, you can do a little bit of OOP and functional but is not as easy to do as in JavaScript. The language is quite strict and opinionated and enforces things like code style and formating. It also provides built-in capabilities for testing, formatting, building and so on. ConclusionSomeone asked me in the comments of the previous part in the series that why should a JS developer choose Go among all the available options. In my opinion, JS is not a perfect language and hence learning few other languages will greatly benefit a JS developer to use JS more pragmatically and would help to cement her/his knowledge of fundamental programming concepts better. There are of course many options out there like Rust, Go, Haskel, Kotlin and so on, but I think Go is a great place to start as its one of the simplest among all the available options and has wide adoption. My second choice would be Kotlin or Rust. References: http://www. pazams. com/Go-for-Javascript-Developers/ https://github. com/miguelmota/golang-for-nodejs-developersIf you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. Cover image photo created using images from norfolkjs (designed by Lookmai Rattana) and juststickers Also published on Dev. to "
    }, {
    "id": 17,
    "url": "/docker-env-cleanup/",
    "title": "How to clean up your Docker environment",
    "body": "2019/12/06 - Please follow me on Twitter for updates and let me know what can be improved in the post. Cleanup your Docker setupIf you are using Docker on your PC or Mac, over time it is gonna accumulate a lot of Junk, the majority of which being dangling images and orphan volumes. It could take up a lot of space in your machine. You should clean this up once in a while, thankfully there are some docker commands to help us here and along with some bash magic, we can nicely do this in 3 easy steps. Clean up old containers: Docker has a docker rm command to remove containers, we can use this along with some docker ps filters to remove all containers that are not being used currently. This is perfectly fine as it doesn‚Äôt affect anything that is running and if you want to use any of the removed images again, docker will download it for you. So the below command should do the trick. 1docker rm -v $(docker ps -a -q -f status=exited);docker ps -a -q -f status=exited provides a list of container Ids that are in exited status and docker rm -v removes those along with their associated volumes. Run docker rm --help and docker ps --help to see what the flags mean. Note: If you want anything from these volumes, you should back it up before doing this. Clean up dangling volumes: A dangling volume is one that exists and is no longer connected to any containers. There is a similar rm command for volumes as well. We can use this along with docker volume ls command with a filter to remove volumes that are dangling. Below is the command for that. 1docker volume rm $(docker volume ls -q -f dangling=true);docker volume ls -q -f dangling=true returns the volume names that are not connected to any containers and docker volume rm removes them. Run docker volume rm --help and docker volume ls --help to see what the flags mean. Note: If you want anything from these volumes, you should back it up before doing this. Clean up dangling images: Finally, we need to clean up dangling images. Docker images are made up of multiple layers and dangling images are layers that have no relationship to any tagged images. They no longer serve any purpose and consume disk space and hence can be safely removed. We can use the docker image prune -a command from Docker to remove unused images but for some reason, this command was not working for me and hence I had to resort to the image rm command as below. 1docker image rm $(docker images -q -f dangling=true);docker images -q -f dangling=true returns the image names that are not related to any tagged images and docker image rm removes them. Run docker image rm --help and docker images --help to see what the flags mean. Clean up everythingUpdate: Seems like docker provides a native command to clean up everything. 1docker system prune --volumesYou can run this to achieve the same result as below command and a bit more. Thanks to cyberjack for pointing it out. I‚Äôll leave the below for educational purposes. Now we can add these commands as a handy bash function so that we can do this cleanup with a single command like I always do. It frees up a lot of disk space and helps when I‚Äôm having some weird cache issues with docker-compose üòâ. Add the below function to your ~/. bashrc or ~/. zshrc and reload your terminal or source the file by running . ~/. zshrc or . ~/. bashrc. 12345function dpurgeall(){ docker rm -v $(docker ps -a -q -f status=exited); docker volume rm $(docker volume ls -qf dangling=true); docker image rm $(docker images -qf dangling=true);}Now you can simply run dpurgeall and it will clean up your Docker environment. If there is nothing to clean up the command will just exist so nothing to worry there. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. Cover image credit: Photo by chuttersnap on Unsplash Also published on Dev. to "
    }, {
    "id": 18,
    "url": "/golang-for-javascript-developers-part-1/",
    "title": "Golang for JavaScript developers - Part 1",
    "body": "2019/12/04 - Please follow me on Twitter for updates and let me know what can be improved in the post. If you are a JavaScript developer thinking about learning another programming language, then Golang is a great choice. It is simple, has a lot of momentum, very performant and has some similarities to JavaScript. Edit: Someone asked me in the comments that why should a JS developer choose Go among all the available options. In my opinion, JS is not a perfect language and hence learning few other languages will greatly benefit a JS developer to use JS more pragmatically and would help to cement her/his knowledge of fundamental programming concepts better. There are of course many options out there like Rust, Go, Haskel, Kotlin and so on, but I think Go is a great place to start as its one of the simplest among all the available options and has wide adoption. My second choice would be Kotlin or Rust. This post is not a comparison of the languages or is stating that they are very similar. Its a guide for JavaScript developers to grasp Golang quickly. There are many aspects of Go that are entirely different from JavaScript we will touch upon that as well. Things that are more similarThere are many things in Go which are quite similar to concepts in JavaScript. Most are not the same but similar. let us get them out of our way first. In the first part of this series, we will see how they are similar and note any key differences as well. Functions: The most similar feature in JS and Go are the functions. Similarities:  Functions are first-class citizens.  Functions can be assigned to variables.  Functions can be passed as arguments to other functions and can be returned from functions.  Functions can be nested.  Functions can be curried(partial functions).  Functions can memorize its surrounding context thus creating closures.  Functions can be named or anonymous. Anonymous functions can be immediately invoked(IIFE)JavaScript 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970// A normal function with access to `this`function standardFunction(arg1, arg2) {  return `${arg1}:${arg2}`;}// A function assigned to a variableconst assignedFunction1 = standardFunction;// An arrow function assigned to a variableconst assignedArrowFunction = (arg1, arg2) =&gt; {  return `${arg1}:${arg2}`;};// A higher-order-function that accepts functions as argument and returns a functionfunction functionAsArgumentAndReturn(addFn, arg1, arg2) {  const out = addFn(arg1, arg2);  // This returns a closure  return function(numArg) {    return out + numArg;  };}const out = functionAsArgumentAndReturn(  (a, b) =&gt; {    return a + b;  },  5,  10)(10);// returns 25// Nested functionsfunction nested() {  console. log( outer fn );  function nested2() {    console. log( inner fn );    const arrow = () =&gt; {      console. log( inner arrow );    };    arrow();  }  nested2();}nested(); // prints:// outer fn// inner fn// inner arrow// this is a higher-order-function that returns a functionfunction add(x) {  // A function is returned here as closure  // variable x is obtained from the outer scope of this method and memorized in the closure  return y =&gt; x + y;}// we are currying the add method to create more variationsvar add10 = add(10);var add20 = add(20);var add30 = add(30);console. log(add10(5)); // 15console. log(add20(5)); // 25console. log(add30(5)); // 35// An anonymous function invoked immediately(IIFE)(function() {  console. log( anonymous fn );})();// prints: anonymous fnGo 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879// A normal function, this cannot be nestedfunc standardFunction(arg1 string, arg2 string) string {	return fmt. Sprintf( %s:%s , arg1, arg2)}func main() {	// A function assigned to a variable	var assignedFunction1 = standardFunction	// An anonymous function assigned to a variable and nested	var assignedFunction2 = func(arg1 string, arg2 string) string {		return fmt. Sprintf( %s:%s , arg1, arg2)	}	// A higher-order-function that accepts functions as argument and returns a function	var functionAsArgumentAndReturn = func(addFn func(int, int) int, arg1 int, arg2 int) func(int) int {		var out = addFn(arg1, arg2)		// This returns a closure		return func(numArg int) int {			return out + numArg		}	}	var out = functionAsArgumentAndReturn(		func(a, b int) int {			return a + b		},		5,		10,	)(10)	fmt. Println(out) // prints 25	// Nested anonymous functions	var nested = func() {		fmt. Println( outer fn )		var nested2 = func() {			fmt. Println( inner fn )			var nested3 = func() {				fmt. Println( inner arrow )			}			nested3()		}		nested2()	}	nested() // prints:	// outer fn	// inner fn	// inner arrow	// this is a higher-order-function that returns a function	var add = func(x int) func(y int) int {		// A function is returned here as closure		// variable x is obtained from the outer scope of this method and memorized in the closure		return func(y int) int {			return x + y		}	}	// we are currying the add method to create more variations	var add10 = add(10)	var add20 = add(20)	var add30 = add(30)	fmt. Println(add10(5)) // 15	fmt. Println(add20(5)) // 25	fmt. Println(add30(5)) // 35	// An anonymous function invoked immediately(IIFE)	(func() {		fmt. Println( anonymous fn )	})()	// prints: anonymous fn	assignedFunction1( a ,  b )	assignedFunction2( a ,  b )}Differences:  JavaScript Functions have two forms; regular functions, and arrow functions whereas in Go there is normal functions and interface functions. Normal Go functions do not have a this and hence are more similar to arrow functions whereas interface functions have something similar to a this and hence closer to normal functions in JavaScript. Go doesn‚Äôt have the concept of a global this. JavaScript 1234567891011121314151617181920function normalFnOutsideClass() {  console. log(`I still can access global this: ${this}`);}const arrowFnOutsideClass = () =&gt; {  console. log(`I don't have any this`);};class SomeClass {  name =  Foo ;  normalFnInsideClass = function() {    console. log(`I can access the callee as this: ${this. name}`);  };  arrowFnInsideClass = () =&gt; {    console. log(`I can access the class reference as this: ${this. name}`);  };}new SomeClass(). normalFnInsideClass();new SomeClass(). arrowFnInsideClass();Go 12345678910111213141516171819type SomeStruct struct {	name string}func (this *SomeStruct) normalFnInsideStruct() {	// you can name the variable this or anything else	fmt. Printf( I can access the struct reference as this\n: %s , this. name)}func main() {	var normalFnOutsideStruct = func() {		fmt. Println( I can access variables in my scope )	}	normalFnOutsideStruct()	var structVal = SomeStruct{ Foo }	structVal. normalFnInsideStruct()} JavaScript functions are the same as any other value type and hence can even hold additional attributes which is not possible in Go.  Go functions can have implicit named returns.  Only anonymous functions can be nested in Go.  Go functions can return multiple values, whereas in JavaScript you can return only one value. However, in JS you can work around that by using destructuring so you can do similar looking functions in bothJavaScript 123456function holdMyBeer() {  return [ John , 2];}let [a, b] = holdMyBeer();console. log(`Hey ${a}, hold my ${b} beer\n`);Go 12345678func holdMyBeer() (string, int64) {	return  John , 2}func main() {	a, b := holdMyBeer()	fmt. Printf( Hey %s, hold my %d beer\n , a, b)}Scope: The scope is the context in which a variable is valid, this decides where a variable can be used and both JS and Go has many similarities here Similarities:  Both have function Scope and Functions can memorize their surrounding scope.  Both have block scope.  Both have a global scope. Differences:  Go doesn‚Äôt have the concept of this which is a tricky concept in JavaScript. IMO this makes things much simpler in Go.  Variables in the same scope cannot be re-declared in Go. Go var is closer to let keyword in JS. Flow control: Flow control in Golang is quite similar but simpler than JavaScript in many aspects. Similarities:  for loops are very similar in both.  while loops are very similar, though Go uses the same for keyword.  forEach is also similar in functionality but the syntax is quite different.  You can break/continue from a loop. You can use labels to do so as well.  if/else syntax is quite similar, Go version is a bit more powerfulJavaScript 123456789101112131415161718192021222324252627282930313233343536373839// For loopfor (let i = 0; i &lt; 10; i++) {  console. log(i);}// While looplet i = 0;while (i &lt; 10) {  console. log(i);  i++;}// Do whilelet j = 0;do {  j += 1;  console. log(j);} while (j &lt; 5);// ForEach loop[ John ,  Sam ,  Ram ,  Sabi ,  Deepu ]. forEach((v, i) =&gt; {  console. log(`${v} at index ${i}`);});// for of loopfor (let i of [ John ,  Sam ,  Ram ,  Sabi ,  Deepu ]) {  console. log(i);}// For in loopconst obj = {  a:  aVal ,  b:  bVal };for (let i in obj) {  console. log(obj[i]);}Go 123456789101112131415161718192021222324252627282930313233343536373839func main() {	// For loop	for i := 0; i &lt; 10; i++ {		fmt. Println(i)	}	// While loop	i := 0	for i &lt; 10 {		fmt. Println(i)		i++	}	// Do while	j := 0	for {		j += 1		fmt. Println(j)		if j == 5 {			break		}	}	// ForEach and for of loop	for i, v := range []string{ John ,  Sam ,  Ram ,  Sabi ,  Deepu } {		fmt. Printf( %v at index %d\n , v, i)	}	// For in loop	var obj = map[string]string{		 a :  aVal ,		 b :  bVal ,	}	for i, v := range obj {		fmt. Printf( %v at index %s\n , v, i)	}}Differences:  There is no ternary operator in Go.  switch statement syntax is similar but Go defaults to break and JS defaults to fall through. In Go, you can use the fallthrough keyword for that functionality while in JS, we have the break keyword.  JS has many more ways of iterations, like while, forEach, for in &amp; for of loops and so on which are not available in Go though most of them can be achieved using the for syntax.  if/else can have an init assignment in Go. In the below code the assignment for val has scope only within the if and else blocks and not outside of it. This is not possible in JS. Go 12345if val := getVal(); val &lt; 10 {  return val} else {  return val + 1}Memory management: Memory management is also quite similar except for details in both JS and Go. Similarities:  Both are garbage collected at runtime.  Both have heap and stack memory which means the same in both. Differences:  Go has pointers that are exposed to users while their memory management is abstracted away whereas in JavaScript pointers are abstracted away completely and you only work with values and references.  Go uses a concurrent tricolor mark-and-sweep algorithm with a focus on latency whereas JS engines normally implement different algorithms with Mark-Sweep being a very popular choice. V8 engine, for example, uses both Mark-Sweep and a Scavenge algorithm. Misc:  Commenting is same in both, with // and /* */ Both JS and Go supports importing other modules, though the behavior is not the same SetTimeout is similar in both. setTimeout(somefunction, 3*1000) vs time. AfterFunc(3*time. Second, somefunction).  Both have a spread operator console. log(. . . array) vs fmt. Println(array. . . ). Go spread works only on interface arrays/slices though.  Both have rest operator for method arguments . . . nums vs nums . . . int. ConclusionIn this part, we saw concepts that are similar in both languages. In the next part of the series, we will see things that are more different between JS and Go. There are more things in the next part, that are different, than this, but please also note that some differences are quite subtle so it would be easy to digest for a JavaScript developer. In the next chapter we will see:  Types &amp; Variables Error handling Mutability Composition instead of inheritance Concurrency Compilation ParadigmReferences: http://www. pazams. com/Go-for-Javascript-Developers/ https://github. com/miguelmota/golang-for-nodejs-developersIf you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. Cover image photo created using images from norfolkjs (designed by Lookmai Rattana) and juststickers Also published on Dev. to "
    }, {
    "id": 19,
    "url": "/reflections-on-javascript/",
    "title": "My love-hate relationship with JavaScript",
    "body": "2019/11/21 - Please follow me on Twitter for updates and let me know what can be improved in the post. There are three types of programmers, the ones who love JavaScript, the ones who hate JavaScript and the ones who do both. JavaScript is the second language(First was C/C++) I learned when I was trying to run my Wordpress blog. It was even before I started my career. When I started my engineering career I started as a Java Web app developer, which meant I had the chance to work on JavaScript as well for the front-end part. I was pretty good at JS/HTML/CSS and soon I was doing a lot of front-end focused Java Web apps. I also learned JQuery and fell in love with it. During the initial years of my career, JavaScript was undoubtedly the language I loved the most as I found it insanely flexible and easy, especially when I wanted to hack something together fast, even though I was doing an equal amount of coding in Java as well. My former immature self even used to believe that JavaScript was the best programming language in the world and I used to vehemently debate anyone who thought JavaScript wasn‚Äôt good, I mean I did have some good reasons to think so. Fast forward to now and I think I know better and in my attempts at being more pragmatic, I started looking at languages and frameworks more objectively and without bias. Now I wouldn‚Äôt say JavaScript is the best language out there, but its a very important one, I know its flaws and there are things I dislike in the JS ecosystem which now I‚Äôm mature enough to admit. Don‚Äôt get me wrong, I still love JavaScript(TypeScript even more) and I have seen the rise and fall of frameworks from JQuery to current MVVM frameworks and worked with most of them. JavaScript is one of the most loved and most hated language at the same time. You may notice that many of the things I like about JavaScript are the same I dislike as well and that‚Äôs why the title. So after more than 10 years of working with JavaScript and its huge ecosystem here is what I think about the language. Please note that a lot of them are personal preference based opinions and hence might sound a bit biased. What I like about JavaScriptFirst, let us talk about things that I love in JavaScript Beginner friendly but also powerful: JavaScript is one of the easiest languages for beginners. Regardless of its quirks, it‚Äôs easy to get started. You don‚Äôt even need to install or set up anything. If you have a web browser on your computer that is all you need to write JavaScript. There is also an infinite amount of help available on the internet. The basic syntax is quite easy and the basic concepts are easy to follow as well. This doesn‚Äôt mean it is a simple language, we will talk about that later. JavaScript is also a really powerful language as you can get almost anything done with JavaScript like building a web page, a server app, a mobile app, a robot and so on (doesn‚Äôt mean you should üòú). There is no other language that I have seen which is as versatile as JavaScript. But remember learning JavaScript is easy but becoming a good JavaScript developer is quite hard. Dynamic &amp; Extremely flexible: JavaScript is the most dynamic language that I have used, there are things that you can do it JavaScript which is not even thinkable in many other languages. You can get away with a lot in JavaScript as its a very forgiving language. Changing the type of variables at runtime? no problem, add variables and methods to a class you have no control over? no problem, write code that generates code? no problem. The list just goes on. This kind of dynamic behavior is really useful for some use-cases, especially scripting or a templating engine for example. But it‚Äôs not without its costs. Flexibility is the biggest strength and biggest weakness of JavaScript, it is extremely handy when it comes to scripting and stuff but means makes maintenance harder in larger codebases, we will see about that in the dislike section. I spend a good amount of time in my career creating prototypes and PoCs and the dynamic nature and flexibility of JavaScript made that productive and easy, but I would never recommend those for real applications that need to be maintained. For example, you can do the below in JavaScript to build dynamic functions 1234567891011121314151617const functions = {};for (let i = 0; i &lt; 10; i++) {  functions[`myAwesomeFunc${i}`] = new Function(     fnName ,    `console. log('Hello world from ' + fnName + ' fn created by index ${i}');`  );}Object. values(functions). forEach(fn =&gt; {  fn(fn. name);});// prints// Hello world from anonymous fn created by index 0// . . . // Hello world from anonymous fn created by index 9Multiparadigm: JavaScript started as an imperative scripting language and later added features to make OOP possible and due to a lot of features it has you can use it as a functional programming language as well. I like this in a language as you can use the best of all paradigms to get your work done efficiently. Functions as first-class citizens: Functions in JavaScript are first-class citizens and they don‚Äôt differ from any other type of objects in JavaScript. You can pass them around, create them at runtime, change them, store them and so on. You can even add attributes to a function. 1234567function foo(msg) {  console. log(`Hello world! ${msg}`);}foo. bar =  Yo ;foo(foo. bar); // prints 'Hello world! Yo'Useful syntax sugars(personal preference): JavaScript provides a lot of useful syntax sugars like async/await, spread/rest operators, destructuring, ternary operator and so on and I really like them as they make code less verbose for trained eyes. Of course, if you are very new to JS they might seem a bit confusing. Metaprogramming: JavaScript has great support for Metaprogramming. It provides the Proxy and Reflect objects that allow you to intercept and define custom behavior to existing language operators. Definitely an advanced feature which has its own use-cases. Less verbose and clean syntax(personal preference): I might be a bit biased here as JavaScript and Java are the languages I have worked with most and so when it comes to syntax I might be unconsciously finding them nicer. It definitely is possible to write unreadable code in JavaScript but at the same time you can write beautiful expressive code as well and I find the JS syntax more readable than many other languages. Can run anywhere: Technically JavaScript can run anywhere. It is undoubtedly the biggest programming platform in the world, especially due to the internet, as JavaScript is the language of the web. You can run JS in a browser, mobile devices, server-side, Desktop apps, OS, IoT, robots, virtual reality, smartwatches, from other languages like Java and so on. This is an interesting article from Anil Dash about this topic. Biggest community: JavaScript has the biggest community out there, its the most popular programming language after all. The NPM repository has more packages than most other languages combined and you will find help easily for anything related to JS on the web and there is a huge ecosystem around JavaScript making it really easy to work with. Whatever need you have, you can be sure there will be a JavaScript library or tool for that.  As long as web browsers and internet is around JavaScript will be around: Whenever people say Java and JavaScript are like dinosaurs(old, outdated and bulky) I try to correct them. IMO, JS and Java are like cockroaches they can survive anything and I‚Äôm pretty sure JavaScript will be around for the foreseeable future unless there is a huge revolution in the internet industry making way to something else. So your skills in JS is gonna be pretty relevant and hence is an important skill to have. NodeJS: One of the reasons the JavaScript community grew is also because of NodeJS, It paved the way for JS to be considered outside of the web browser and boy did that explode. I like NodeJS as it lets anyone build and publish reusable packages to the community without having to spend too much effort. Of course, there are issues like fragmentation and bloat to address but NodeJS still is an important tool in a programmer‚Äôs arsenal. Typescript: You might argue TypeScript is its own language, but technically its a syntax superset of JavaScript and hence I would rather place it here. TypeScript addresses a lot of common issues in JavaScript like support for static typing, scalability and so on. So this is definitely something I would put in the like column. I wish every JavaScript runtime had native support for TypeScript(like Deno for example) or that JS evolves into TypeScript(that would be super cool). What I don‚Äôt like about JavaScriptNow let‚Äôs talk about things that I don‚Äôt like in JavaScript language and ecosystem. Fragmentation (Browser implementations, version compatibility): For me the biggest issue for JavaScript is fragmentation. The JS model is that the end-user can choose the implementation, which means the programmer has very little control over what implementation her/his code will run against. There are two major parts at play here when it comes to implementation; Vendor: There are so many different JS engines with slightly different implementations making the life of programmers hell. For example, there is the V8 engine used by Chrome, NodeJs, Opera and so on and SpiderMonkey from Mozilla, JavaScriptCore from apple and many more. The problem is the ECMAScript standard for JS doesn‚Äôt have any reference implementation and vendors slightly change implementation details to fit their needs making the same code behave differently in different engines. remember Internet explorer? A major share of the front-end code written in the last two decades is just for browser compatibility, as the huge portion of the JQuery codebase which was to make it work in Internet explorer. While I‚Äôm glad that the IE browser is finally EOL, there are still subtle bugs arising from these differing implementations every now and then for someone building JS apps. Version: Another reason for fragmentation is the ECMAScript version, again vendors go ahead and implement versions as and when they like making it impossible for developers to rely on any particular version as they wouldn‚Äôt know if end-user has a browser that supports this version. This leads way to an unwanted middleman like Babel transpiling your code to the common denominator, mostly to ES5 adding complexity and overhead. One of the biggest issues even present today because of these factors is the JS module system, everyone uses a module system(requireJS, commonJS or ES modules) but still, there is no consensus on what should be the standard implementation and its quite frustrating. This is probably why JS is the only language with such dedicated websites like caniuse. com I wish there was a single-engine managed by the community and used by all the browsers and runtimes thus making fragmentation less of an issue. Beauracracy: JavaScript being a huge community comes with its own Beauracracy and process layer similar to Java, there are different governing bodies like ECMA International, ISO, JS Foundation, W3C and so on which has stakes in the future of JavaScript, then there are different browser vendors like Google, Mozilla, and Apple with their own agenda, all this makes language evolution slow, messy and painful. Language quirks: Sometimes I wonder if JavaScript was designed by someone during an acid(LSD) + Ecstasy trip as there are quirks in the language that is mind-numbing. I don‚Äôt think you will find so many quirks in any other languages and hence it gives criticizers of JavaScript a field day. There is a whole repo dedicated to documenting this https://github. com/denysdovhan/wtfjs Here is a sample, don‚Äôt even try to understand what happens here. 1234567console. log(  (![] + [])[+[]] +    (![] + [])[+!+[]] +    ([![]] + [][[]])[+!+[] + [+[]]] +    (![] + [])[!+[] + !+[]]);// prints 'fail'Npm hell: NodeJS was like a blessing to JavaScript community and it brought NPM along which really has exploded and now it is kind of annoyance that JavaScript developers have learned to live with. Have you ever tried to find the number of files in a node_modules folder? NPM is a good package manager and has some pretty great features like npm link for example but its nested dependency structure along with fluid versioning makes it a recipe for disaster and countless hours of painful debugging sessions. Also, there is the issue of a monolithic registry holding so many packages used by so many applications. Remember leftpad? Error prone (a side effect of flexibility): With JavaScript, it is too easy to shoot in the foot. Well, JavaScript will give you 100 different types of loaded guns, it will hold your hand while you point your gun and will pull the trigger if you hesitate and once you have shot at your foot, it will cut off your leg and make you eat it. I didn‚Äôt want to go all cannibalistic here but that‚Äôs how it is with JavaScript. A lot of it has to do with the fact that JavaScript was never designed for the scale that it has today. It was a simple dynamic scripting language. Since JavaScript is too dynamic and flexible it lets you do all sorts of stuff that many other languages will not allow and combine that with the huge list of quirks, bugs are just waiting to happen. Today the situation is much better with newer versions and with many tools like ESList, VSCode, TypeScript and so on that help you a lot to avoid common mistakes, but even with all that it really takes experience and hard work to write large JavaScript programs without subtle bugs. In my career, most of the debugging sessions that I have done would be in JavaScript. Yet another framework syndrome: There is also the phenomena that is unique to JavaScript, its called Yet another framework syndrome, new frameworks and libraries are invented on a daily basis, almost, and the churn is so great that if you take a break of one year from JS world and comeback you won‚Äôt be able to recognize anything and will find yourself learning some new framework. This means teams maintaining JavaScript applications are constantly spending time migrating to newer frameworks from obsolete ones and so on. I had to spend a lot of time migrating from JQuery to AngularJS, AngularJS to Angular, Angular to React and so on in my career. The churn rate in Java, for example, is extremely low compared to this. The JS community also seems to suffer from not invented here syndrome much more than other language communities, you will find at least a dozen options for everything here. Complexity: As I said earlier, JavaScript is very beginner-friendly and easy to learn but it is not a simple language at its current form. It has evolved a lot and along with all the simplicity on its cover has quite a lot of complex features underneath and it keeps on growing, and due to its legacy and dynamic nature it has too many ways to do the same thing, which I dislike in any language, and has a complex ecosystem that one must learn to use JavaScript at scale. You would have to learn stuff like Webpack, NodeJS, NPM, Babel, ESLint and so on to be productive. It is also very easy to write complex unreadable code in JavaScript using callbacks and stuff, generally referred to as callback hell! Add to this the dynamic nature, legacy quirks and the complexity keeps on increasing. Scalability: JavaScript by itself is not scalable at all, you will be productive when the codebase is small but as it grows the issues starts to appear, due to the lack of a type system, large codebases become a nightmare to maintain unless you are using something like TypeScript on top. Even with that large JavaScript codebases are much more difficult to traverse and maintain compared to other languages, I have experience of this from JHipster for example. Soon you will find yourself adding build tools, linters, transpilers and so on to ease maintenance. NitpicksWell, when it comes to JavaScript you either love it, hate it or both, there are no real nitpicks at least for me. ConclusionIf you search on the internet for opinions on JavaScript, you will find tons and tons of content, some praising it, some bashing it, and some objective. A lot can be said about JavaScript and its community. For most its a love-hate relationship, some are brave enough to admit that. If you absolutely hate JavaScript then either you haven‚Äôt worked with it a lot or you are holding some prejudice against it. Try it, its a fun language(at least it will keep you awake a lot üòú), it has its purpose and like it or not its the language of the modern web, and it does a pretty good job there. If you think you can be more productive on the web using any other language, then maybe you should try building a large website using that language, then learn JS and try the same. IMO JS is not going anywhere and if anything it is only getting more and more adoption, so it would be foolish not to know the most popular language. Every programmer should learn JavaScript, you never know when it would be handy. If you absolutely love JavaScript and use JavaScript to everything, then maybe you should also learn few other languages like Java, Go or Rust and you would see why JavaScript is not ideal for many use-cases(It can, of course, do it, any Turing complete language can, that doesn‚Äôt mean you should do it) The key is not knowing how to use JavaScript, it is knowing when to use JavaScript and when not. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. Cover image credit: Made with imgflip Also published on Dev. to "
    }, {
    "id": 20,
    "url": "/functional-programming-in-rust/",
    "title": "Easy functional programming techniques in Rust for everyone",
    "body": "2019/11/14 - There is a lot of hype around functional programming(FP) and a lot of cool kids are doing it but it is not a silver bullet. Like other programming paradigms/styles, functional programming also has its pros and cons and one may prefer one paradigm over the other. If you are a Rust developer and wants to venture into functional programming, do not worry, you don‚Äôt have to learn functional programming oriented languages like Haskell or Clojure(or even Scala or JavaScript though they are not pure functional programming languages) since Rust has you covered and this post is for you. If you are looking for functional programming in Java, Golang or TypeScript check other posts in the series. I‚Äôm not gonna dive into all functional programming concepts in detail, instead, I‚Äôm gonna focus on things that you can do in Rust which are in line with functional programming concepts. I‚Äôm also not gonna discuss the pros and cons of functional programming in general. Please note that some introductions in this post are repeated from my other posts in the series for your ease of reading. What is functional programming?: As per Wikipedia,  Functional programming is a programming paradigm‚Äîa style of building the structure and elements of computer programs‚Äîthat treats computation as the evaluation of mathematical functions and avoids changing-state and mutable data. Hence in functional programming, there are two very important rules  No Data mutations: It means a data object should not be changed after it is created.  No implicit state: Hidden/Implicit state should be avoided. In functional programming state is not eliminated, instead, its made visible and explicitThis means:  No side effects: A function or operation should not change any state outside of its functional scope. I. e, A function should only return a value to the invoker and should not affect any external state. This means programs are easier to understand.  Pure functions only: Functional code is idempotent. A function should return values only based on the arguments passed and should not affect(side-effect) or depend on the global state. Such functions always produce the same result for the same arguments. Apart from these there are functional programming concepts below that can be applied in Rust, we will touch upon these further down.  Higher-order-functions Closures Currying Recursion Lazy evaluations Referential transparencyUsing functional programming doesn‚Äôt mean its all or nothing, you can always use functional programming concepts to complement Object-oriented or imperative concepts in Rust. The benefits of functional programming can be utilized whenever possible regardless of the paradigm or language you use. And that is exactly what we are going to see. Functional programming in Rust: Rust is primarily geared towards procedural/imperative style of programming but it also lets you do a little bit of functional and object-oriented style of programming as well. And that is my favorite kind of mix. So let us see how we can apply some of the functional programming concepts above in Rust using the language features. First-class and higher-order functions: First-class functions(function as a first-class citizen) means you can assign functions to variables, pass a function as an argument to another function or return a function from another. Functions in Rust are a bit more complex than other languages, it‚Äôs not as straightforward as in Go or JavaScript. There are different kinds of functions and two different ways of writing them. The first one is a function that cannot memoize its outer context and the second one is closures which can memoize its outer context. Hence concepts like currying and higher-order-functions are possible in Rust but may not be as easy to wrap your head around as in other languages. Also, functions that accept a closure can also accept a pointer to a function depending on the context. In many places, Rust functions and closures can be interchangeable. It would have been nicer if functions were simple and we could do all the below without having to rely on closures. But Rust chose these compromises for better memory safety and performance. A function can be considered as a higher-order-function only if it takes one or more functions as parameters or if it returns another function as a result. In Rust, this is quite easy to do with closures, it might look a bit verbose but if you are familiar with Rust then you should be fine. 123456789101112131415161718192021222324fn main() {  let list = vec![    String::from( Orange ),    String::from( Apple ),    String::from( Banana ),    String::from( Grape ),  ];  // we are passing the array and a closure as arguments to map_for_each method.   let out = map_for_each(list, |it: &amp;String| -&gt; usize {    return it. len();  });  println!( {:?} , out); // [6, 5, 6, 5]}// The higher-order-function takes an array and a closure as argumentsfn map_for_each(list: Vec&lt;String&gt;, fun: fn(&amp;String) -&gt; usize) -&gt; Vec&lt;usize&gt; {  let mut new_array: Vec&lt;usize&gt; = Vec::new();  for it in list. iter() {    // We are executing the closure passed    new_array. push(fun(it));  }  return new_array;}There are also more complex versions that you can write with generics like below for an example 12345678910111213141516171819fn main() {  let list = vec![2, 5, 8, 10];  // we are passing the array and a closure as arguments to map_for_each method.   let out = map_for_each(list, |it: &amp;usize| -&gt; usize {    return it * it;  });  println!( {:?} , out); // [4, 25, 64, 100]}// The higher-order-function takes an array and a closure as arguments, but uses generic typesfn map_for_each&lt;A, B&gt;(list: Vec&lt;A&gt;, fun: fn(&amp;A) -&gt; B) -&gt; Vec&lt;B&gt; {  let mut new_array: Vec&lt;B&gt; = Vec::new();  for it in list. iter() {    // We are executing the closure passed    new_array. push(fun(it));  }  return new_array;}But then we could also simply do it this way using built-in functional methods like map, fold(reduce) and so on which is much less verbose. Rust provides a lot of useful functional style methods for working on collections like map, fold, for_each, filter and so on. 12345678fn main() {  let list = [ Orange ,  Apple ,  Banana ,  Grape ];  // we are passing a closure as arguments to the built-in map method.   let out: Vec&lt;usize&gt; = list. iter(). map(|x| x. len()). collect();  println!( {:?} , out); // [6, 5, 6, 5]}Closures in Rust can memorize and mutate its outer context but due to the concept of ownership in Rust, you cannot have multiple closures mutating the same variables in the outer context. Currying is also possible in Rust but again due to ownership and lifetime concepts, it might feel a bit more verbose. 1234567891011121314151617fn main() {  // this is a higher-order-function that returns a closure  fn add(x: usize) -&gt; impl Fn(usize) -&gt; usize {    // A closure is returned here    // variable x is obtained from the outer scope of this method and memorized in the closure by moving ownership    return move |y| -&gt; usize { x + y };  };  // we are currying the add method to create more variations  let add10 = add(10);  let add20 = add(20);  let add30 = add(30);  println!( {} , add10(5)); // 15  println!( {} , add20(5)); // 25  println!( {} , add30(5)); // 35}Pure functions: As we saw already a pure function should return values only based on the arguments passed and should not affect or depend on the global state. It is possible to do this in Rust easily. Take the below, this is a pure function. It will always return the same output for the given input and its behavior is highly predictable. We can safely cache the method if needed. 123fn sum(a: usize, b: usize) -&gt; usize {  return a + b;}But since Rust variables are immutable by default, unless specified a function cannot mutate any variables passed to it and cannot capture any variable in its context. So if we try to affect external state like below the compiler will complain ‚Äúcan‚Äôt capture dynamic environment in a fn item‚Äù 1234567891011use std::collections::HashMap;fn main() {  let mut holder = HashMap::new();  fn sum(a: usize, b: usize) -&gt; usize {    let c = a + b;    holder. insert(String::from(format!( ${a}+${b} , a = a, b = b)), c);    return c;  }}In Rust, in order to capture external state, we would have to use closures, so we can rewrite the above as 12345678910111213use std::collections::HashMap;fn main() {  let mut holder = HashMap::new();  let sum = |a: usize, b: usize| -&gt; usize {    let c = a + b;    holder. insert(String::from(format!( ${a}+${b} , a = a, b = b)), c);    return c;  };  println!( {} , sum(10, 20));}But the compilation will still fail with the message ‚Äúcannot borrow sum as mutable, as it is not declared as mutable‚Äù. So in order to do external state mutation, we would have to explicitly specify the function as mutable like let mut sum = . . . So Rust will help you keep your functions pure and simple by default. Of course, that doesn‚Äôt mean you can avoid side effects that don‚Äôt involve variable mutations, for those you have to take care of it yourself. Recursion: Functional programming favors recursion over looping. Let us see an example for calculating the factorial of a number. In traditional iterative approach: 123456789101112fn main() {  fn factorial(mut num: usize) -&gt; usize {    let mut result = 1;    while num &gt; 0 {      result *= num;      num = num - 1;    }    return result;  }  println!( {} , factorial(20)); // 2432902008176640000}The same can be done using recursion as below which is favored in functional programming ‚Äì But recursion is not the solution always, for some cases a simple loop is more readable. 12345678910fn main() {  fn factorial(num: usize) -&gt; usize {    return match num {      0 =&gt; 1,      _ =&gt; num * factorial(num - 1),    };  }  println!( {} , factorial(20)); // 2432902008176640000}The downside of the recursive approach is that it will be slower compared to an iterative approach most of the times(The advantage we are aiming for is code simplicity and readability) and might result in stack overflow errors since every function call needs to be saved as a frame to the stack. To avoid this tail recursion is preferred, especially when the recursion is done too many times. In tail recursion, the recursive call is the last thing executed by the function and hence the functions stack frame need not be saved by the compiler. Most compilers can optimize the tail recursion code the same way iterative code is optimized hence avoiding the performance penalty. But unfortunately, Rust does not support this yet. Consider using recursion when writing Rust code for readability and immutability, but if performance is critical or if the number of iterations will be huge use the standard iterative approach. Lazy evaluation: Lazy evaluation or non-strict evaluation is the process of delaying the evaluation of an expression until it is needed. In general, Rust does strict/eager evaluation. We can utilize higher-order-functions, closures, and memoization techniques to do lazy evaluations. Take this example where Rust eagerly evaluates everything. 123456789101112131415161718192021fn main() {  fn add(x: usize) -&gt; usize {    println!( executing add ); // this is printed since the functions are evaluated first    return x + x;  }  fn multiply(x: usize) -&gt; usize {    println!( executing multiply ); // this is printed since the functions are evaluated first    return x * x;  }  fn add_or_multiply(add: bool, on_add: usize, on_multiply: usize) -&gt; usize {    if add {      on_add    } else {      on_multiply    }  }  println!( {} , add_or_multiply(true, add(4), multiply(4))); // 8  println!( {} , add_or_multiply(false, add(4), multiply(4))); // 16}This will produce the below output and we can see that both functions are executed always 123456executing addexecuting multiply8executing addexecuting multiply16We can use higher-order-functions to rewrite this into a lazily evaluated version 123456789101112131415161718192021222324fn main() {  fn add(x: usize) -&gt; usize {    println!( executing add ); // this is printed since the functions are evaluated first    return x + x;  }  fn multiply(x: usize) -&gt; usize {    println!( executing multiply ); // this is printed since the functions are evaluated first    return x * x;  }  type FnType = fn(t: usize) -&gt; usize;  // This is now a higher-order-function hence evaluation of the functions are delayed in if-else  fn add_or_multiply(add: bool, on_add: FnType, on_multiply: FnType, t: usize) -&gt; usize {    if add {      on_add(t)    } else {      on_multiply(t)    }  }  println!( {} , add_or_multiply(true, add, multiply, 4)); // 8  println!( {} , add_or_multiply(false, add, multiply, 4)); // 16}This outputs the below and we can see that only required functions were executed 1234executing add8executing multiply16You can also use memoization/caching techniques to avoid unwanted evaluations in pure and referentially transparent functions like below 12345678910111213141516171819202122232425262728293031323334353637383940414243use std::collections::HashMap;fn main() {  let mut cached_added = HashMap::new();  let mut add = |x: usize| -&gt; usize {    return match cached_added. get(&amp;x) {      Some(&amp;val) =&gt; val,      _ =&gt; {        println!( {} ,  executing add );        let out = x + x;        cached_added. insert(x, out);        out      }    };  };  let mut cached_multiplied = HashMap::new();  let mut multiply = |x: usize| -&gt; usize {    return match cached_multiplied. get(&amp;x) {      Some(&amp;val) =&gt; val,      _ =&gt; {        println!( executing multiply );        let out = x * x;        cached_multiplied. insert(x, out);        out      }    };  };  fn add_or_multiply(add: bool, on_add: usize, on_multiply: usize) -&gt; usize {    if add {      on_add    } else {      on_multiply    }  }  println!( {} , add_or_multiply(true, add(4), multiply(4))); // 8  println!( {} , add_or_multiply(false, add(4), multiply(4))); // 16}This outputs the below and we can see that functions were executed only once for the same values. 1234executing addexecuting multiply816These may not look that elegant especially to seasoned Rust programmers. Fortunately, most of the functional APIs, like the iterators, provided by Rust do lazy evaluations and there are libraries like rust-lazy and Thunk which can be used to make functions lazy. Also, Rust provides some advanced types with which lazy evaluations can be implemented. Doing Lazy evaluations in Rust might not be worth the code complexity some of the times, but if the functions in question are heavy in terms of processing then it is absolutely worth it to lazy evaluate them. Type system: Rust is a strong statically typed language and also has great type inference. There are also advanced concepts like type aliasing and so on. Referential transparency: From Wikipedia:  Functional programs do not have assignment statements, that is, the value of a variable in a functional program never changes once defined. This eliminates any chances of side effects because any variable can be replaced with its actual value at any point of execution. So, functional programs are referentially transparent. Rust has great ways to ensure referential transparency, variables in Rust are immutable by default and even reference passing is immutable by default. So you would have to explicitly mark variables or references as mutable to do so. So in Rust, it is actually quite easy to avoid mutations. For example, the below will produce an error 12345fn main() {  let list = [ Apple ,  Orange ,  Banana ,  Grape ];  list = [ John ,  Raju ,  Sabi ,  Vicky ];}And so does all of the below 12345678910111213141516fn main() {  let list = vec![    String::from( Orange ),    String::from( Apple ),    String::from( Banana ),    String::from( Grape ),  ];  list. push(String::from( Strawberry )); // This will fail as the reference is immutable  fn mutating_fn(val: String) {    val. push('!'); // this will fail unless the argument is marked mutable reference or value passed is marked mutable reference  }  mutating_fn(String::from( Strawberry )); // this will fail if the reference is not passed as mutable}In order to compile these, we would have to riddle it with mut keywords 1234567891011121314151617fn main() {  let mut list = vec![    String::from( Orange ),    String::from( Apple ),    String::from( Banana ),    String::from( Grape ),  ];  list. push(String::from( Strawberry )); // This will work as the reference is mutable  fn mutating_fn(val: &amp;mut String) {    val. push('!'); // this will work as the argument is marked as a mutable reference  }  mutating_fn(&amp;mut String::from( Strawberry )); // this will work as the reference is passed as mutable}There are even more advanced concepts in Rust when it comes to data mutation and all that makes it easier to write immutable code. Data structures: When using functional programming techniques it is encouraged to use data types such as Stacks, Maps, and Queues as they also have functional implementations. Hence Hashmaps are better than arrays or hash sets as data stores in functional programming. Rust provides such data types and is hence conforms to the functional specifications regarding data structures. Conclusion: This is just an introduction for those who are trying to apply some functional programming techniques in Rust. There are a lot more that can be done in Rust. As I said earlier functional programming is not a silver bullet but it offers a lot of useful techniques for more understandable, maintainable and testable code. It can co-exist perfectly well with imperative and object-oriented programming styles. In fact, we all should be using the best of everything to solve the problem at hand instead of getting too obsessed about a single methodology. I hope you find this useful. If you have any questions or if you think I missed something please add a comment. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. Also published on Dev. to "
    }, {
    "id": 21,
    "url": "/first-impression-of-rust/",
    "title": "My first impressions of Rust",
    "body": "2019/11/07 - Please follow me on Twitter for updates. So I started learning Rust a while ago and since my post about what I thought of Go was popular, I decided to write about what my first impressions of Rust were as well. But unlike Go, I actually didn‚Äôt build any real-world application in Rust, so my opinions here are purely personal and some might not be accurate as I might have misunderstood something. So do give me the consideration of a Rust newbie. If you find something I said here is inaccurate please do let me know. Also, my impressions might actually change once I start using the language more. If it does, I‚Äôll make sure to update the post. As I have said in some of my other posts, I consider myself to be more pragmatic than my younger self now. Some of the opinions are also from that pragmatic perspective(or at least I think so). I have weighed practicality, readability, and simplicity over fancy features, syntax sugars, and complexity. Also, some things which I didn‚Äôt like but found not such a big deal are put under nitpicks rather than the dislike section as I thought it was fairer that way. One thing that sets Rust apart from languages like Go is that Rust is not garbage collected, and I understand that many of the language features/choices where designed with that in mind. Rust is primarily geared towards procedural/imperative style of programming but it also lets you do a little bit of functional and object-oriented style of programming as well. And that is my favorite kind of mix. So, without any further ado, let‚Äôs get into it. What I like about RustThings that I really liked, in no particular order. No Garbage collection: One of the first things you would notice in Rust, especially if you are coming from garbage collected languages like Java or Golang is the lack of garbage collection. Yes, there is no GC in Rust, then how does it ensure my program runs efficiently in the given memory and how does it prevent out of memory errors? Rust has something called ownership, so basically any value in Rust must have a variable as its owner(and only one owner at a time) when the owner goes out of scope the value will be dropped freeing the memory regardless of it being in stack or heap memory. For example, in the below example the value of foo is dropped as soon as the method execution completes and the value of bar is dropped right after the block execution. 1234567891011fn main() {  let foo =  value ; // owner is foo and is valid within this method  {    let bar =  bar value ; // owner is bar and is valid within this block scope    println!( value of bar is {} , bar); // bar is valid here  }  println!( value of foo is {} , foo); // foo is valid here  println!( value of bar is {} , bar); // bar is not valid here as its out of scope}So by scoping variables carefully, we can make sure the memory usage is optimized and that is also why Rust lets you use block scopes almost everywhere. Also, the Rust compiler helps you in dealing with duplicate pointer references and so on. The below is invalid in Rust since foo is now using heap memory rather than stack and assigning a reference to a variable is considered a move. If deep copying(expensive) is required it has to be performed using the clone function which performs a copy instead of move. 1234567891011fn main() {  let foo = String::from( hello ); // owner is foo and is valid within this method  {    let bar = foo; // owner is bar and is valid within this block scope, foo in invalidated now    println!( value of bar is {} , bar); // bar is valid here  }  println!( value of foo is {} , foo); // foo is invalid here as it has moved}The ownership concept can be a bit weird to get used to, especially since passing a variable to a method will also move it(if its not a literal or reference), but given that it saves us from GC I think its worth it and the compiler takes care of helping us when we make mistakes. Immutable by default: Variables are immutable by default. If you want to mutate a variable you have to specifically mark it using the mut keyword. 12let foo =  hello  // immutablelet mut bar =  hello  // mutableVariables are by default passed by value, in order to pass a reference we would have to use the &amp; symbol. Quite similar to Golang. 12345678910111213141516fn main() {  let world = String::from( world );  hello_ref(&amp;world); // pass by reference. Keeps ownership  // prints: Hello world  hello_val(world); // pass by value and hence transfer ownership  // prints: Hello world}fn hello_val(msg: String) {  println!( Hello {} , msg);}fn hello_ref(msg: &amp;String) {  println!( Hello {} , msg);}When you pass a reference it is still immutable so we would have to explicitly mark that mutable as well as below. This makes accidental mutations very difficult. The compiler also ensures that we can only have one mutable reference in a scope. 1234567891011121314151617fn main() {  let mut world = String::from( world );  hello_ref(&amp;mut world); // pass by mutable reference. Keeps ownership  // prints: Hello world!  hello_val(world); // pass by value and hence transfer ownership  // prints: Hello world!}fn hello_val(msg: String) {  println!( Hello {} , msg);}fn hello_ref(msg: &amp;mut String) {  msg. push_str( ! ); // mutate string  println!( Hello {} , msg);}Pattern matching: Rust has first-class support for pattern matching and this can be used for control flow, error handling, variable assignment and so on. pattern matching can also be used in if, while statements, for loops and function parameters. 123456789101112131415fn main() {  let foo = String::from( 200 );  let num: u32 = match foo. parse() {    Ok(num) =&gt; num,    Err(_) =&gt; {      panic!( Cannot parse! );    }  };  match num {    200 =&gt; println!( two hundred ),    _ =&gt; (),  }}Generics: One thing I love in Java and TypeScript is the generics. It makes static typing more practical and DRY. Strongly typed languages(Looking at you Golang) without generics are annoying to work with. Fortunately, Rust has great support for generics. It can be used in types, functions, structs, and enums. The icing on the cake is that Rust converts the Generic code using specific code during compile time thus there is no performance penalty in using them. 1234567891011121314151617struct Point&lt;T&gt; {  x: T,  y: T,}fn hello&lt;T&gt;(val: T) -&gt; T {  return val;}fn main() {  let foo = hello(5);  let foo = hello( 5 );  let integer = Point { x: 5, y: 10 };  let float = Point { x: 1. 0, y: 4. 0 };}Static types and advanced type declarations: Rust is a strictly typed language with a static type system. It also has great type inference which means we don‚Äôt have to define types manually for everything. Rust also allows for complex type definitions. 12345type Kilometers = i32;type Thunk = Box&lt;dyn Fn() + Send + 'static&gt;;type Result&lt;T&gt; = std::result::Result&lt;T, std::io::Error&gt;;Nice and simple error handling: Error handling in Rust is quite nice, there are recoverable and unrecoverable errors. For recoverable errors, you can handle them using pattern matching on the Result enum or using the simple expect syntax. There is even a shorthand operator to propagate errors from a function. Take that Go. 1234567891011121314use std::fs::File;fn main() {  let f = File::open( hello. txt ). expect( Failed to open hello. txt );  // or  let f = match File::open( hello. txt ) {    Ok(file) =&gt; file,    Err(error) =&gt; {      panic!( Problem opening the file: {:?} , error)    },  };}Tuples: Rust has built-in support for tuples, and this is highly helpful when you have to return multiple values from a function or when you want to unwrap a value and so on. Block expressions: In Rust, you can have block expressions with their own scope almost anywhere. It also lets you assign a variable value from block expressions, if statement, loops and so on. 12345678fn main() {  let foo = {    println!( Assigning foo );    5  };  let bar = if foo &gt; 5 { 6 } else { 10 };}Beautiful compiler output: Rust simply has the best error output during compilation that I have seen. It can‚Äôt get better than this I think. It is so helpful.  Built-in tooling: Like many modern programming languages, Rust also provides a lot of build-in standard tooling and honestly, I think this is one of the best that I have come across. Rust has Cargo which is the built-in package manager and build system. It is an excellent tool. It takes care of all common project needs like compiling, building, testing and so on. It can even create new projects with a skeleton and manage packages globally and locally for the project. That means you don‚Äôt have to worry about setting up any tooling to get started in Rust. I love this, it saves so much time and effort. Every programming language should have this. Rust also provides built-in utilities and asserts to write tests which then can be executed using Cargo. In Rust, related functionality is grouped into modules, modules are grouped together into something called crates and crates are grouped into packages. We can refer to items defined in one module from another module. Packages are managed by cargo. You can specify external packages in the Cargo. toml file. Reusable public packages can be published to the crates. io registry. There are even offline built-in docs that you can get by running rustup docs and rustup docs --book which is amazing. Thanks to Mohamed ELIDRISSI for pointing it out to me. Concurrency: Rust has first-class support for memory safe concurrent programming. Rust uses threads for concurrency and has 1:1 threading implementation. i. e, 1 green thread per operating system thread. Rust compiler guarantees memory safety while using the threads. It provides features like waiting for all threads to finish, sharing data with move closures or channels(similar to Go). It also lets you use shared state and sync threads. 12345678910111213141516use std::thread;use std::time::Duration;fn main() {  thread::spawn(|| {    for i in 1. . 10 {      println!( hi number {} from the spawned thread! , i);      thread::sleep(Duration::from_millis(1));    }  });  for i in 1. . 5 {    println!( hi number {} from the main thread! , i);    thread::sleep(Duration::from_millis(1));  }}Macros and meta-programming: While I don‚Äôt like all aspects of macros in Rust, there are more things to like here than dislike. The annotation macros, for example, are quite handy. Not a fan of the procedure macros though. For advanced users, you can write your own macro rules and do metaprogramming. Traits: Traits are synonymous to interfaces in Java, it is used to define shared behaviors that can be implemented on structs. Traits can even specify default methods. The only thing I dislike here is the indirect implementation. 123456789101112131415161718192021222324252627282930pub trait Summary {  fn summarize_author(&amp;self) -&gt; String;  fn summarize(&amp;self) -&gt; String {    format!( (Read more from {}. . . ) , self. summarize_author())  }}pub struct NewsArticle {  pub author: String,  pub content: String,}impl Summary for NewsArticle {  fn summarize_author(&amp;self) -&gt; String {    format!( @{} , self. author)  }}fn main() {  let article = NewsArticle {    author: String::from( Iceburgh ),    content: String::from(       The Pittsburgh Penguins once again are the best hockey team in the NHL.  ,    ),  };  println!( New article available! {} , article. summarize());}Ability to use unsafe features if required:  Useful in advanced use-cases where you know what you are doing. A necessary evil IMO. I like it since its doable only within an unsafe { } block making it very explicit. I would have moved this to the dislike section if that was not the case.  When you use these, the Rust compiler cannot guarantee memory and runtime safety and you are on your own to get this right. So definitely for advanced and experienced users. What I don‚Äôt like about RustThings that I didn‚Äôt like very much, in no particular order. Complexity: I don‚Äôt like it when a language offers multiples ways to do the same things. This is one think Golang does pretty well, there are no two ways to do the same thing and hence it is easier for people to work on larger codebases and to review code. Also, you don‚Äôt have to always think of the best possible way to do something. Unfortunately, Rust does this and I‚Äôm not a fan of it. IMO it makes the language more complex.  Too many ways for iterations -&gt; loops, while, for, iterators.  Too many ways for creating procedures -&gt; Functions, closures, macrosEdit: Based on discussions here and on Reddit, I say my perception of complexity only have increased. It seems like once you get past all the niceties there are a lot of things that would take some time to wrap your head around. I‚Äôm pretty sure if you are experienced in Rust, it would be a cakewalk for you but the language indeed is quite complex, especially the ways functions and closures behave in different contexts, lifetimes in structs and stuff. Shadowing of variables in the same context: So Rust lets you do this 123456{  let foo =  hello ;  println!( {} , foo);  let foo =  world ;  println!( {} , foo);} Kind of beats being immutable by default(I understand the reasoning of being able to perform transformations on an immutable variable, especially when passing references to a function and getting it back) IMO lets people practice bad practices unintentionally, I would have rather marked the variable mutable as I consider the above mutation as well.  You can as easily accidentally shadow a variable as you would accidentally mutate one in Languages like JavaScript Gives people a gun to shoot in the footEdit: I saw a lot of comments here and on Reddit explaining why this is good. While I agree that it is useful in many scenarios, so is the ability of mutation. I think it would have been perfectly fine not to have this and people would have still loved Rust and all of them would have defended the decision not have this. So my opinion on this hasn‚Äôt changed. Functions are not first-class citizens: While it is possible to pass a function to another they are not exactly first-class citizens like in JavaScript or Golang. You cannot create closures from functions and you cannot assign functions to variables. Closures are separate from functions in Rust, they are quite similar to Java lambdas from what I see. While closures would be sufficient to perform some of the functional style programming patterns it would have been much nicer if it was possible using just functions thus making language a bit more simple. Edit: Oh by! this opinion triggered a lot of discussions here and on Reddit. So seems like Functions and closures are similar and different based on context, It also seems like Functions are almost like first-class citizens, but if you are used to languages like Go or JavaScript where functions are much more straight forward then you are in for a crazy ride. Functions in Rust seems much much more complex. A lot of people who commented seemed to miss the fact that my primary complaint was that having two constructs(closures and functions) that look and act quite similar in most of the scenarios makes things more complex. At least in Java and JS where there are multiple constructs(arrow functions, lambdas) those where due to the fact that they were added much later to the language and those are still something I don‚Äôt like in those languages. The best explanation was from Yufan Lou and another from zesterer. I‚Äôm not gonna remove this from stuff I don‚Äôt like since I still don‚Äôt like the complexity here. Implicit implementation of traits: I‚Äôm not a fan of implicit stuff as its easier to abuse this and harder to read. You could define a struct in one file and you could implement a trait for that struct in another file which makes it less obvious. I prefer when the implementation is done by intent like in Java which makes it more obvious and easier to follow. While the way in Rust is not ideal, it is definitely better than Golang which is even more indirect. NitpicksFinally some stuff I still don‚Äôt like but I don‚Äôt consider them a big deal.  I don‚Äôt see the point of having the const keyword when let is immutable by default. It seems more like syntax sugar for the old school constants concept. Diane pointed out the difference const provides and that makes sense.  The block expression and implicit return style are a bit error-prone and confusing to get used to, I would have preferred explicit return. Also, it‚Äôs not that readable IMO.  If you have read my other post about Go, you might know that I‚Äôm not a fan of structs. Structs in Rust is very similar to structs in Golang. So like in Go, it would be easy to achieve unreadable struct structures. But fortunately, the structs in Rust seem much nicer than Go as you have functions, can use spread operator, shorthand syntax and so on here. Also, you can make structs which are Tuples. The structs in Rust are more like Java POJOs. I would have moved this to the liked section if having optional fields in structs where easier. Currently, you would have to wrap stuff in an Optional enum to do this. Also lifetimes :( Given strings are the most used data types, it would have been nice to have a simpler way of working with strings(like in Golang) rather than working with the Vector types for mutable strings or slice types for immutable string literals. This makes code more verbose than it needs to be. This is more likely a compromise due to the fact that Rust is not garbage collected and has a concept of ownership to manage memory. https://doc. rust-lang. org/rust-by-example/std/str. html - Edit: I have moved this point to nitpicks rather than dislikes after a discussion on the comments with robertorojasrConclusionI like programming languages that focus more on simplicity rather than fancy syntax sugars and complex features. In my post ‚ÄúMy reflections on Golang‚Äù, I explain why I consider Golang to be too simple for my taste. Rust, on the other hand, is leaning towards the other side of the spectrum. While it is not as complex as Scala it is not as simple as Go as well. So its somewhere in between, not exactly the sweet spot but almost near that quite close to where JavaScript is maybe. So overall I can say that there are more things in Rust for me to like than to dislike which is what I would expect from a nice programming language. Also, bear in mind that I‚Äôm not saying Rust should do anything differently or that there are better ways to do things that I complained about. I‚Äôm just saying that I don‚Äôt like those things but I can live with it given the overall advantages. Also, I fully understand why some of those concepts are the way they are, those are mostly tradeoffs to focus on memory safety and performance. But don‚Äôt be fooled by what you see over the hood, Rust is definitely not something you should start with as your first programming language IMO, as it has a quite a lot of complex concepts and constructs underneath but if you are already familiar with programming then it shouldn‚Äôt be an issue after banging your head on the doors a few times :P So far I can say that I like Rust more than Golang even without implementing a real project with it and might choose Rust over Go for system programming use cases and for high-performance requirements. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. Cover image credit: Image from Link Clark, The Rust team under Creative Commons Attribution Share-Alike License v3. 0. Also published on Dev. to "
    }, {
    "id": 22,
    "url": "/microservices-the-good-bad-and-the-ugly/",
    "title": "Microservices - the good, bad, and the ugly",
    "body": "2019/10/29 - So you are attending this awesome conference where speaker after speaker talks about how awesome microservices are. You hear a speaker from a Tech giant presenting how they scaled up and solved their issues using microservices running on containers or something, and you wonder shouldn‚Äôt we do the same as well? The reality is that there is no silver bullet in software engineering. Microservices doesn‚Äôt magically solve every scaling issues, some times they introduce more problems then they solve. Well, this is not a microservice bashing post, as someone who likes microservice architectures(sometimes for their sheer complexity and sometimes for the ingenuity), I think it‚Äôs important to know the cost of doing microservice architectures in real-world use cases. I talked briefly about this in my book as well. Microservice architecturesIn a microservice architecture, you generally split your domain model into individual loosely coupled services that can be deployed and scaled individually. Each of the services is in itself a small application with its own architecture and even runtime sometimes. The services might offer REST endpoints that can be aggregated by an application acting as a gateway or the services could be communicating with each other using a messaging system. Some services might have Web GUI some are headless services offering just an API. In microservice architectures, each service is responsible for handling its data and ideally do not share database schema with other services. Such architectures make it easy to provide different clients for Mobile and Desktop experience which can be scaled independently based on demand.  There are different architecture patterns for building microservices. The patterns used also decides the way services communicate and the way they are aggregated. This article details some of these patterns quite nicely. So let‚Äôs break down the benefits and issues of microservice architecture and see when it makes sense to adopt one and when to avoid one. General benefits of Microservice architecturesIn general, Microservices provide(As it depends on how you actually implement it) or at least promise the below benefits, which can be grouped into three major categories Loose coupling: Microservice components are more loosely coupled than traditional architectures. Such systems employ event-driven or message-driven architectures to achieve communication between loosely coupled components. This results in better isolation of components and makes it easy to unit test them and faster to startup. Such systems also provide other benefits like, for example, a memory leak in one of the services, are isolated and hence will not bring down the entire application. Hence overall single point of failures are reduced Loosely coupled individual components will start up much faster than a big monolith making it possible to parallelize and improve overall start-up for large systems. It also makes it easy to refactor existing features as you can gradually refactor things rather than having to refactor an entire system in one go. Because of such loose coupling, each service can choose to use a database/datastore that is more appropriate whereas in a monolith you might compromise with a single database type. For example, a service dealing with a lot of unstructured data can choose a NoSQL database while a service that is handling transactions or structured data can opt for a SQL database. Faster development &amp; release cycle: In a well-implemented microservice architecture, development turnaround is faster and hence you get a better time to market for new features and easier refactoring of existing features. A complex problem domain can be easily tackled by splitting it into separately manageable services making it easier to understand and maintain in the long run. Technology adoption is easier, components can be independently upgraded in incremental migration making it possible to have a different stack for each component. It is also possible to have different microservices in a system use different implementation languages and just communicate using a common messaging format like gRPC or a message queue or pub/sub,thus making it possible to have teams with different language skills hence less dependency on a single language or stack. Teams will be less dependent on each other as communication between systems is governed by a public API or contract letting you change internals without having to worry about breaking someone else‚Äôs code. Best suited for agile teams. Such teams can have better focus as they only need to worry about a single service. Fine-grained scaling: One of the most important benefits of a microservice architecture is the ability to scale individual components based on load. If implemented properly this will result in ideal load distribution and reduced overall infrastructure cost. Services with more demand can be scaled up while the ones with less demand can be scaled down utilizing infrastructure more efficiently. Deploying services independently also makes the application more reliable and makes patching easier as you do not have to upgrade the entire application to fix an issue in a single service. More complex and efficient scaling models can be established. Critical services can be scaled more effectively. Infrastructure is used more efficiently. Continuous delivery of such complex applications also would be easier than its equivalent monolith as components are smaller and any issue in deployment can be investigated easily and rectified on a per-component basis General issues with microservice architecturesWell with any architectures, there are disadvantages of Microservice architectures as well. Complexity: Complexity is one of the biggest side effects of this architecture. While microservices can reduce the domain complexity by breaking the problem into smaller services,there could be complexities of a distributed system in terms of;  Overall stack as different components might have different technology stacks forcing the team to invest more time in keeping up with them.  Scaling is more efficient but it would require advanced features such as service discovery, DNS routing, and so on.  Communication between components might require a messaging system(Queue, PubSub, Event store).  Business transactions on a distributed system might involve updating multiple databases making rollbacks more complex and error-prone.  The entire application is more complex to deploy as there are complexities with containers, orchestration, and virtualization involved.  Requires a complex infrastructure. Most often will require containers (Docker), Orchestration(Kubernetes) and multiple JVM or app containers to run on. Integration testing: End-to-end tests and integration tests become harder to perform there are more moving parts in the stack and more complex communication between components. The testing infrastructure required also becomes more difficult to set up and maintain. Team size and experience: The technical stack for microservices is more complex and most of the time harder to learn and hence it would demand a more experienced team with more senior-level skillset than that would be required for a similar monolithic application. It will also require a bigger team to maintain the application as there are more components and more technologies involved. Implementing requirements that span multiple services would require more upfront time to agree on contracts and APIs. Team members share varying skill sets based on the component they work on but might not be having a birds-eye view of the entire application making business requirements harder to visualize and cross-cutting issues harder to fix. Overhead: Complex microservices will have the additional overhead of running monitoring setup, messaging services, orchestration, service registry and so on. Initial development time will be higher due to the complexity making time to market slower. The overall cost of the initial infrastructure might be much higher than that of a similar monolith. In microservice architectures, there is always code duplication between services which also can be considered overhead. When you should not be considering Microservice architecturesYou should not be using microservice architecture unless you absolutely have to, remember not every application has the same scale requirements as Netflix, Google, Amazon or Spotify. Many of the benefits that microservices provide to these kinds of applications are due to their sheer scale which might not be applicable to you. So here are some reasons not to choose microservices and maybe stick to monoliths.  When your application‚Äôs scope is small and you know that it‚Äôs not going to grow and turn into something like Facebook. For well defined simple usecases a monolith is always the best fit. Examples are     A CRUD application for an internal use case in a company.    A small application with a very niche user base. Like a shopping site for some specialty items.     When the time to market is critical for a new application. The initial time to market would be higher for microservices.  When the size of your team is small or the average experience of the team is less. Its best to start with a monolith when you are a small or inexperienced team.  When your infrastructure budget is limited. Though on long-run microservice might help to save money, in the beginning, it is going to cost you more. Most importantly do not choose microservices because it is the hype or because it is used by a popular company or because it was suggested by a popular person. For most use cases monoliths are still a great solution and even if you start with a monolith you can always split away into microservices if required. When you could consider Microservice architecturesIn general, Microservices tend to be beneficial if you have one of the below scenarios.  When your use case domain is complex, you have a large team with experience and splitting it up would make it easier to implement.  When you are expecting to become the next Facebook, Netflix or Twitter in terms of user load. So ideally when you are expecting an exponential user base.  If your application is going to be an API provider for other applications with a large userbase. Like a payment gateway or inventory service that will be used by a social media application When you have a popular e-commerce application with a large userbase with an uneven load on different services in the application. Its time to split them into microservices. So in conclusion, don‚Äôt choose an architecture pattern because it works for someone else, choose a pattern that is appropriate for your use case, scale and requirements. Not everyone needs to handle millions of concurrent users or stream terabytes of data. If you liked this article you might like my book as well. You can get it from Packt and Amazon.  If you like this article, please leave a like or a comment. If you do decide to build microservices checkout JHipster and my below articles don‚Äôt forget to give it a star on Github.  Create full Microservice stack using JHipster Domain Language under 30 minutes Deploying JHipster Microservices on Azure Kubernetes Service (AKS) JHipster microservices with Istio service mesh on KubernetesYou can follow me on Twitter and LinkedIn. Cover image photo by Sergei Akulich on Unsplash Also published on Dev. to "
    }, {
    "id": 23,
    "url": "/functional-programming-in-typescript/",
    "title": "Easy functional programming techniques in TypeScript for everyone",
    "body": "2019/08/14 - There is a lot of hype around functional programming(FP) and a lot of cool kids are doing it but it is not a silver bullet. Like other programming paradigms/styles, functional programming also has its pros and cons and one may prefer one paradigm over the other. If you are a TypeScript/JavaScript developer and wants to venture into functional programming, do not worry, you don‚Äôt have to learn functional programming oriented languages like Haskell or Clojure since JavaScript and hence TypeScript has you covered and this post is for you. If you are looking for functional programming in Java or Golang check other posts in the series. I‚Äôm not gonna dive into all functional programming concepts in detail, instead, I‚Äôm gonna focus on things that you can do in TypeScript which are in line with functional programming concepts. I‚Äôm also not gonna discuss the pros and cons of functional programming in general. Please keep in mind, though this post is about TypeScript, you can easily do the same in JavaScript as well since TypeScript is just a typed superset of JavaScript. What is functional programming?: As per Wikipedia,  Functional programming is a programming paradigm‚Äîa style of building the structure and elements of computer programs‚Äîthat treats computation as the evaluation of mathematical functions and avoids changing-state and mutable data. Hence in functional programming, there are two very important rules  No Data mutations: It means a data object should not be changed after it is created.  No implicit state: Hidden/Implicit state should be avoided. In functional programming state is not eliminated, instead, its made visible and explicitThis means:  No side effects: A function or operation should not change any state outside of its functional scope. I. e, A function should only return a value to the invoker and should not affect any external state. This means programs are easier to understand.  Pure functions only: Functional code is idempotent. A function should return values only based on the arguments passed and should not affect(side-effect) or depend on global state. Such functions always produce the same result for the same arguments. Apart from these there are functional programming concepts below that can be applied in TypeScript, we will touch upon these further down.  Higher-order-functions Closures Currying Recursion Lazy evaluations Referential transparencyUsing functional programming doesn‚Äôt mean its all or nothing, you can always use functional programming concepts to complement Object-oriented concepts in TypeScript. The benefits of functional programming can be utilized whenever possible regardless of the paradigm or language you use. And that is exactly what we are going to see. Functional programming in TypeScript: TypeScript is not a purely functional language but offers a lot of concepts which are in line with functional languages, so let us see how we can apply some of the functional programming concepts above in TypeScript. First-class and higher-order functions: First-class functions(function as a first-class citizen) means you can assign functions to variables, pass a function as an argument to another function or return a function from another. TypeScript supports this and hence makes concepts like closures, currying, and higher-order-functions easy to write. A function can be considered as a higher-order-function only if it takes one or more functions as parameters or if it returns another function as a result. In TypeScript, this is quite easy to do 123456789101112131415161718type mapFn = (it: string) =&gt; number;// The higher-order-function takes an array and a function as argumentsfunction mapForEach(arr: string[], fn: mapFn): number[] {  const newArray: number[] = [];  arr. forEach(it =&gt; {    // We are executing the method passed    newArray. push(fn(it));  });  return newArray;}const list = [ Orange ,  Apple ,  Banana ,  Grape ];// we are passing the array and a function as arguments to mapForEach method. const out = mapForEach(list, (it: string): number =&gt; it. length);console. log(out); // [6, 5, 6, 5]But then in JavaScript/TypeScript we could also simply do it this way using built-in functional methods like map, reduce and so on. 123456const list = [ Orange ,  Apple ,  Banana ,  Grape ];// we are passing a function as arguments to the built-in map method. const out = list. map(it =&gt; it. length);console. log(out); // [6, 5, 6, 5]Closures and currying are also possible in TypeScript 123456789101112131415// this is a higher-order-function that returns a functionfunction add(x: number): (y: number) =&gt; number {  // A function is returned here as closure  // variable x is obtained from the outer scope of this method and memorized in the closure  return (y: number): number =&gt; x + y;}// we are currying the add method to create more variationsvar add10 = add(10);var add20 = add(20);var add30 = add(30);console. log(add10(5)); // 15console. log(add20(5)); // 25console. log(add30(5)); // 35There are also many built-in declarative higher-order-functions in TypeScript/JavaScript like map, reduce, forEach, filter and so on. There are also many libraries that provide functional interfaces to be used in TypeScript/JavaScript. Pure functions: As we saw already a pure function should return values only based on the arguments passed and should not affect or depend on global state. It is possible to do this in TypeScript easily. This is quite simple, take the below this is a pure function. It will always return the same output for the given input and its behavior is highly predictable. We can safely cache the method if needed. 123function sum(a: number, b: number): number {  return a + b;}If we add an extra line in this function, the behavior becomes unpredictable as it now has a side effect that affects an external state. 1234567const holder = {};function sum(a: number, b: number): number {  let c = a + b;  holder[`${a}+${b}`] = c;  return c;}So try to keep your functions pure and simple. Using tools like ESLint and typescript-eslint it is possible to enforce these. Recursion: Functional programming favors recursion over looping. Let us see an example for calculating the factorial of a number. In traditional iterative approach: 123456789function factorial(num: number): number {  let result = 1;  for (; num &gt; 0; num--) {    result *= num;  }  return result;}console. log(factorial(20)); // 2432902008176640000The same can be done using recursion as below which is favored in functional programming. 1234const factorial = (num: number): number =&gt;  num == 0 ? 1 : num * factorial(num - 1);console. log(factorial(20)); // 2432902008176640000The downside of the recursive approach is that it will be slower compared to an iterative approach most of the times(The advantage we are aiming for is code simplicity and readability) and might result in stack overflow errors since every function call needs to be saved as a frame to the stack. To avoid this tail recursion is preferred, especially when the recursion is done too many times. In tail recursion, the recursive call is the last thing executed by the function and hence the functions stack frame need not be saved by the compiler. Most compilers can optimize the tail recursion code the same way iterative code is optimized hence avoiding the performance penalty. Tail call optimization is part of the ECMAScript specs but unfortunately, most JavaScript engines do not support this yet. Now using tail recursion the same function can be written as below, but depending on the engine this might not be optimized, though there are workarounds, still it performed better in benchmarks. 123456const factorialTailRec = (num: number): number =&gt; factorial(1, num);const factorial = (accumulator: number, val: number): number =&gt;  val == 1 ? accumulator : factorial(accumulator * val, val - 1);console. log(factorialTailRec(20)); // 2432902008176640000Consider using recursion when writing TypeScript code for readability and immutability, but if performance is critical or if the number of iterations will be huge use standard loops. Lazy evaluation: Lazy evaluation or non-strict evaluation is the process of delaying evaluation of an expression until it is needed. In general, TypeScript does strict/eager evaluation but for operands like &amp;&amp;, || and ?: it does a lazy evaluation. We can utilize short-circuiting, higher-order-functions, closures, and memoization techniques to do lazy evaluations. Take this example where TypeScript eagerly evaluates everything. 1234567891011121314151617181920function add(x: number): number {  console. log( executing add ); // this is printed since the functions are evaluated first  return x + x;}function multiply(x: number): number {  console. log( executing multiply ); // this is printed since the functions are evaluated first  return x * x;}function addOrMultiply(  add: boolean,  onAdd: number,  onMultiply: number): number {  return add ? onAdd : onMultiply;}console. log(addOrMultiply(true, add(4), multiply(4))); // 8console. log(addOrMultiply(false, add(4), multiply(4))); // 16This will produce the below output and we can see that both functions are executed always 123456executing addexecuting multiply8executing addexecuting multiply16We can use higher-order-functions to rewrite this into a lazily evaluated version 12345678910111213141516171819202122function add(x: number): number {  console. log( executing add );  return x + x;}function multiply(x: number): number {  console. log( executing multiply );  return x * x;}type fnType = (t: number) =&gt; number;// This is now a higher-order-function hence evaluation of the functions are delayed in if-elsefunction addOrMultiply(  add: boolean,  onAdd: fnType,  onMultiply: fnType,  t: number): number {  return add ? onAdd(t) : onMultiply(t);}console. log(addOrMultiply(true, add, multiply, 4));console. log(addOrMultiply(false, add, multiply, 4));This outputs the below and we can see that only required functions were executed 1234executing add8executing multiply16Or by memoization like this 1234567891011121314151617181920212223242526272829303132const cachedAdded = {};function add(x: number): number {  if (cachedAdded[x]) {    return cachedAdded[x];  }  console. log( executing add );  const out = x + x;  cachedAdded[x] = out;  return out;}const cachedMultiplied = {};function multiply(x: number): number {  if (cachedMultiplied[x]) {    return cachedMultiplied[x];  }  console. log( executing multiply );  const out = x * x;  cachedMultiplied[x] = out;  return out;}function addOrMultiply(  add: boolean,  onAdd: number,  onMultiply: number): number {  return add ? onAdd : onMultiply;}console. log(addOrMultiply(true, add(4), multiply(4))); // 8console. log(addOrMultiply(false, add(4), multiply(4))); // 16This outputs the below and we can see that functions were executed only once for the same values 1234executing addexecuting multiply816Please note that memoization techniques will work only when your functions are pure and referentially transparent. There are also other ways of doing Lazy evaluations like this. Doing Lazy evaluations in TypeScript might not be worth the code complexity some of the times, but if the functions in question are heavy in terms of processing then its is absolutely worth it to lazy evaluate them. Type system: TypeScript has a strong type system and also has great type inference. While the underlying JavaScript itself is weakly typed, TypeScript along with a compatible IDE can bridge that gap. Referential transparency: From Wikipedia:  Functional programs do not have assignment statements, that is, the value of a variable in a functional program never changes once defined. This eliminates any chances of side effects because any variable can be replaced with its actual value at any point of execution. So, functional programs are referentially transparent. Unfortunately, there are not many ways to strictly limit data mutation in JavaScript, however by using pure functions and by explicitly avoiding data mutations and reassignment using other concepts we saw earlier this can be achieved. JavaScript by default passes primitive variables by value and objects by reference so we need to take care not to mutate data inside functions. Libraries like Immutable JS could also be considered. Use const as much as possible to avoid reassignments. For example, the below will produce an error 123const list = [ Apple ,  Orange ,  Banana ,  Grape ];list = [ Earth ,  Saturn ];But this will not help when variables are holding references to other objects, for example, the below mutation will work irrespective of the const keyword. 1234const list = [ Apple ,  Orange ,  Banana ,  Grape ];list. push( Earth ); // will mutate the listlist. push( Saturn ); // will mutate the listconst keyword allows the internal state of referenced variables to be mutated and hence from a functional programming perspective const keyword is useful only for primitive constants and to catch reassignments. However, with TypeScript, we can use special mapped types to make objects read-only and hence avoiding accidental data mutations which are caught during compile time. Thanks to @stereobooster and @juliang for pointing it out. Read my post about mapped and conditional types here to learn more. 123const list: Readonly&lt;string[]&gt; = [ Apple ,  Orange ,  Banana ,  Grape ];list. push( Earth ); // will cause compilation erroror 123const list: ReadonlyArray&lt;string&gt; = [ Apple ,  Orange ,  Banana ,  Grape ];list. push( Earth ); // will cause compilation errorOther techniques to follow are using Object. freeze or built-in methods like map, reduce, filter and so on as they do not mutate the data. We can also use this ESlint plugin to restrict mutations. Data structures: When using functional programming techniques it is encouraged to use data types such as Stacks, Maps and Queues which have functional implementations as well. Hence maps are better than arrays or hash sets in functional programming as data stores. Conclusion: This is just an introduction for those who are trying to apply some functional programming techniques in TypeScript. There are a lot more that can be done in TypeScript and with the ever-evolving ECMAScript underneath, this should be even easier. As I said earlier functional programming is not a silver bullet but it offers a lot of useful techniques for more understandable, maintainable and testable code. It can co-exist perfectly well with imperative and object-oriented programming styles. In fact, we all should be using the best of everything. I hope you find this useful. If you have any question or if you think I missed something please add a comment. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. Also published on Dev. to "
    }, {
    "id": 24,
    "url": "/functional-programming-in-go/",
    "title": "7 Easy functional programming techniques in Go",
    "body": "2019/08/14 - There is a lot of hype around functional programming(FP) and a lot of cool kids are doing it but it is not a silver bullet. Like other programming paradigms/styles, functional programming also has its pros and cons and one may prefer one paradigm over the other. If you are a Go developer and wants to venture into functional programming, do not worry, you don‚Äôt have to learn functional programming oriented languages like Haskell or Clojure(or even Scala or JavaScript though they are not pure functional programming languages) since Go has you covered and this post is for you. If you are looking for functional programming in Java then check this out                               7 Functional programming techniques in Java - A primer:             30-Jul-2019                           #java #functional #beginners #programming                                    I‚Äôm not gonna dive into all functional programming concepts in detail, instead, I‚Äôm gonna focus on things that you can do in Go which are in line with functional programming concepts. I‚Äôm also not gonna discuss the pros and cons of functional programming in general. What is functional programming?: As per Wikipedia,  Functional programming is a programming paradigm‚Äîa style of building the structure and elements of computer programs‚Äîthat treats computation as the evaluation of mathematical functions and avoids changing-state and mutable data. Hence in functional programming, there are two very important rules  No Data mutations: It means a data object should not be changed after it is created.  No implicit state: Hidden/Implicit state should be avoided. In functional programming state is not eliminated, instead, its made visible and explicitThis means:  No side effects: A function or operation should not change any state outside of its functional scope. I. e, A function should only return a value to the invoker and should not affect any external state. This means programs are easier to understand.  Pure functions only: Functional code is idempotent. A function should return values only based on the arguments passed and should not affect(side-effect) or depend on global state. Such functions always produce the same result for the same arguments. Apart from these there are functional programming concepts below that can be applied in Go, we will touch upon these further down.  Higher-order-functions Closures Currying Recursion Lazy evaluations Referential transparencyUsing functional programming doesn‚Äôt mean its all or nothing, you can always use functional programming concepts to complement Object-oriented or imperative concepts in Go. The benefits of functional programming can be utilized whenever possible regardless of the paradigm or language you use. And that is exactly what we are going to see. Functional programming in Go: Golang is a multi-paradigm language so let us see how we can apply some of the functional programming concepts above in Go. First-class and higher-order functions: First-class functions(function as a first-class citizen) means you can assign functions to variables, pass a function as an argument to another function or return a function from another. Go supports this and hence makes concepts like closures, currying, and higher-order-functions easy to write. A function can be considered as a higher-order-function only if it takes one or more functions as parameters or if it returns another function as a result. In Go, this is quite easy to do 12345678910111213141516171819func main() {	var list = []string{ Orange ,  Apple ,  Banana ,  Grape }	// we are passing the array and a function as arguments to mapForEach method. 	var out = mapForEach(list, func(it string) int {		return len(it)	})	fmt. Println(out) // [6, 5, 6, 5]}// The higher-order-function takes an array and a function as argumentsfunc mapForEach(arr []string, fn func(it string) int) []int {	var newArray = []int{}	for _, it := range arr {		// We are executing the method passed		newArray = append(newArray, fn(it))	}	return newArray}Closures and currying are also possible in Go 1234567891011121314151617181920// this is a higher-order-function that returns a functionfunc add(x int) func(y int) int {	// A function is returned here as closure	// variable x is obtained from the outer scope of this method and memorized in the closure	return func(y int) int {		return x + y	}}func main() {	// we are currying the add method to create more variations	var add10 = add(10)	var add20 = add(20)	var add30 = add(30)	fmt. Println(add10(5)) // 15	fmt. Println(add20(5)) // 25	fmt. Println(add30(5)) // 35}There are also many built-in higher-order-functions in Go standard libraries. There are also some functional style libraries like this and this offering map-reduce like functional methods in Go. Pure functions: As we saw already a pure function should return values only based on the arguments passed and should not affect or depend on global state. It is possible to do this in Go easily. This is quite simple, take the below this is a pure function. It will always return the same output for the given input and its behavior is highly predictable. We can safely cache the method if needed. 123func sum(a, b int) int {	return a + b}If we add an extra line in this function, the behavior becomes unpredictable as it now has a side effect that affects an external state. 1234567var holder = map[string]int{}func sum(a, b int) int {	c := a + b	holder[fmt. Sprintf( %d+%d , a, b)] = c	return c}So try to keep your functions pure and simple. Recursion: Functional programming favors recursion over looping. Let us see an example for calculating the factorial of a number. In traditional iterative approach: 1234567891011func factorial(num int) int {	result := 1	for ; num &gt; 0; num-- {		result *= num	}	return result}func main() {	fmt. Println(factorial(20)) // 2432902008176640000}The same can be done using recursion as below which is favored in functional programming. 123456789func factorial(num int) int {	if num == 0 {		return 1	}	return num * factorial(num-1)}func main() {	fmt. Println(factorial(20)) // 2432902008176640000}The downside of the recursive approach is that it will be slower compared to an iterative approach most of the times(The advantage we are aiming for is code simplicity and readability) and might result in stack overflow errors since every function call needs to be saved as a frame to the stack. To avoid this tail recursion is preferred, especially when the recursion is done too many times. In tail recursion, the recursive call is the last thing executed by the function and hence the functions stack frame need not be saved by the compiler. Most compilers can optimize the tail recursion code the same way iterative code is optimized hence avoiding the performance penalty. Go compiler, unfortunately, does not do this optimization. Now using tail recursion the same function can be written as below, but Go doesn‚Äôt optimize this, though there are workarounds, still it performed better in benchmarks. 1234567891011121314func factorialTailRec(num int) int {	return factorial(1, num)}func factorial(accumulator, val int) int {	if val == 1 {		return accumulator	}	return factorial(accumulator*val, val-1)}func main() {	fmt. Println(factorialTailRec(20)) // 2432902008176640000}I ran some benchmarks with all 3 approaches and here is the result, as you can see looping is still the most performing followed by the tail recursion. 12345678goos: linuxgoarch: amd64BenchmarkFactorialLoop-12    	100000000	    11. 7 ns/op	    0 B/op	    0 allocs/opBenchmarkFactorialRec-12    	30000000	    52. 9 ns/op	    0 B/op	    0 allocs/opBenchmarkFactorialTailRec-12  	50000000	    44. 2 ns/op	    0 B/op	    0 allocs/opPASSok 	_/home/deepu/workspace/deepu105. github. io/temp	5. 072sSuccess: Benchmarks passed. Consider using recursion when writing Go code for readability and immutability, but if performance is critical or if the number of iterations will be huge use standard loops. Lazy evaluation: Lazy evaluation or non-strict evaluation is the process of delaying evaluation of an expression until it is needed. In general, Go does strict/eager evaluation but for operands like &amp;&amp; and || it does a lazy evaluation. We can utilize higher-order-functions, closures, goroutines, and channels to emulate lazy evaluations. Take this example where Go eagerly evaluates everything. 123456789101112131415161718192021func main() {	fmt. Println(addOrMultiply(true, add(4), multiply(4))) // 8	fmt. Println(addOrMultiply(false, add(4), multiply(4))) // 16}func add(x int) int {	fmt. Println( executing add ) // this is printed since the functions are evaluated first	return x + x}func multiply(x int) int {	fmt. Println( executing multiply ) // this is printed since the functions are evaluated first	return x * x}func addOrMultiply(add bool, onAdd, onMultiply int) int {	if add {		return onAdd	}	return onMultiply}This will produce the below output and we can see that both functions are executed always 123456executing addexecuting multiply8executing addexecuting multiply16We can use higher-order-functions to rewrite this into a lazily evaluated version 12345678910111213141516171819202122func add(x int) int {	fmt. Println( executing add )	return x + x}func multiply(x int) int {	fmt. Println( executing multiply )	return x * x}func main() {	fmt. Println(addOrMultiply(true, add, multiply, 4))	fmt. Println(addOrMultiply(false, add, multiply, 4))}// This is now a higher-order-function hence evaluation of the functions are delayed in if-elsefunc addOrMultiply(add bool, onAdd, onMultiply func(t int) int, t int) int {	if add {		return onAdd(t)	}	return onMultiply(t)}This outputs the below and we can see that only required functions were executed 1234executing add8executing multiply16There are also other ways of doing it using Sync &amp; Futures like this and using channels and goroutines like this. Doing Lazy evaluations in Go might not be worth the code complexity most of the times, but if the functions in question are heavy in terms of processing then its is absolutely worth it to lazy evaluate them. Type system: Go has a strong type system and also has pretty decent type inference. The only thing missing compared to other functional programming languages are something like case classes and pattern matching. Referential transparency: From Wikipedia:  Functional programs do not have assignment statements, that is, the value of a variable in a functional program never changes once defined. This eliminates any chances of side effects because any variable can be replaced with its actual value at any point of execution. So, functional programs are referentially transparent. Unfortunately, there are not many ways to strictly limit data mutation in Go, however by using pure functions and by explicitly avoiding data mutations and reassignment using other concepts we saw earlier this can be achieved. Go by default passes variables by value, except for slices and maps. So, avoid passing them by reference(using pointers) as much as possible. For example, the below will mutate external state as we are passing a parameter by reference and hence doesn‚Äôt ensure referential transparency 12345678910111213141516171819func main() {	type Person struct {		firstName string		lastName string		fullName string		age    int	}	var getFullName = func(in *Person) string {		in. fullName = in. firstName + in. lastName // data mutation		return in. fullName	}	john := Person{		 john ,  doe ,   , 30,	}	fmt. Println(getFullName(&amp;john)) // johndoe	fmt. Println(john) // {john doe johndoe 30}}If we pass parameters by the value we can ensure referential transparency even if there is an accidental mutation of passed data within the function 12345678910111213141516171819func main() {	type Person struct {		firstName string		lastName string		fullName string		age    int	}	var getFullName = func(in Person) string {		in. fullName = in. firstName + in. lastName		return in. fullName	}	john := Person{		 john ,  doe ,   , 30,	}	fmt. Println(getFullName(john))	fmt. Println(john)}We cannot rely on this when passed parameters are maps or slices. Data structures: When using functional programming techniques it is encouraged to use functional data types such as Stacks, Maps and Queues. Hence maps are better than arrays or hash sets in functional programming as data stores. Conclusion: This is just an introduction for those who are trying to apply some functional programming techniques in Go. There are a lot more that can be done in Go and with the addition of generics in the next major version, this should be even easier. As I said earlier functional programming is not a silver bullet but it offers a lot of useful techniques for more understandable, maintainable and testable code. It can co-exist perfectly well with imperative and object-oriented programming styles. In fact, we all should be using the best of everything. I hope you find this useful. If you have any question or if you think I missed something please add a comment. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. Also published on Dev. to "
    }, {
    "id": 25,
    "url": "/static-site-generators-rundown-how-i-set-up-my-own-blog-with-jekyll/",
    "title": "Static Site Generators rundown - How I set up my own blog with Jekyll",
    "body": "2019/08/01 - Last month I decided to move my blogs from Medium to Dev. to, I have detailed the reasons in the below post.                               Why I‚Äôm moving away from Medium:             13-Jun-2019                           #writing #medium #development #tech                                    A lot of people suggested in the comments to set up my own blog and cross-post to Dev. to instead of relying only on one platform and I completely agree with them. I was procrastinating setting up my own blog for quite some time now. Finally, I decided to do it and set up my own blog at https://deepu. tech/blogs/ in the process I also updated my personal website to use the same platform. So when I decided to do this finally I had to choose a blogging platform and there were few requirements I was keen about which influenced my decision. Requirements:  The platform should support writing posts using Markdown with code syntax highlights I love the Dev community and hence wanted to cross-post everything to Dev. to as well without having to make any changes to the post. Means I would author once and publish to both my blog and Dev. This means some constraints/requirements     It should support customizable front matter so that I can align it with Dev   It should support the custom liquid tags used by Dev or I should be able to easily add those    I should be able to have custom pages for my personal website Should be open source and have a good stable community Should be theme-able, have plugins for SEO, search and so on Should be statically generated and reasonably fast Should be able to host using GitHub pages - This was an optional requirementThe options rundown: With these in mind, I started evaluating some of the popular options below. Jekyll: Pros:  I have experience with Jekyll since I built the new JHipster website using it Supports Markdown, Liquid tags and Front Matter Supports custom pages, themes, plugins and is statically generated Is OSS and has a vibrant community Can be hosted on GitHubCons:  I would have to build or find replacements for the custom Liquid tags used by Dev I don‚Äôt have much experience with Ruby and I‚Äôm not very familiar with the Ruby ecosystem Not the fastest among the options. Becomes slower as site size increasesHugo: Pros:  Is very fast I have extensive experience with Go and Go templates which would be helpful Supports Markdown and Front Matter Supports custom pages, themes and is statically generated Is OSS and has a vibrant community Can be hosted on GitHubCons:  Doesn‚Äôt support Liquid tags Doesn‚Äôt have plugins. The built-in options are enough for my requirements at the moment thoughVuePress: Pros:  Built with VueJS and I have good experience with JavaScript and quite familiar with Vue Supports Markdown and Front Matter Supports custom pages, themes, SEO, search and is statically generated Is OSS and has a vibrant community Can be hosted on GitHubCons:  Doesn‚Äôt support Liquid tags Doesn‚Äôt have plugins. The built-in options are enough for my requirements at the moment though Not geared towards blogging, but it‚Äôs possible to do it easily with some hackingGatsby: Pros:  Built with React and I have good experience with React Supports Markdown and Front Matter Supports custom pages, themes, plugins and is statically generated Is OSS and has a vibrant community Can be hosted on GitHubCons:  Doesn‚Äôt support Liquid tagsWordPress: Pros:  Have used it in the past and is a battle-tested solution Supports Markdown using plugins Supports custom pages, themes, plugins and can be statically generated using plugins Is OSS and has a vibrant community Can be hosted on GitHub with some workaroundsCons:  Doesn‚Äôt support Front Matter and Liquid tags Since most of my core requirements can only be achieved using plugins and workarounds it feels too clumsyThough I personally liked Hugo because of its speed, based on the above the most logical choice for me was Jekyll. Building a personal website and blog with Jekyll: Getting started: Setting up Jekyll is super easy, I followed the official guide and had a site up and running in minutes. The steps in order were as below  Install a full Ruby development environment Install Jekyll and bundler gems for my user - gem install jekyll bundler --user-install Create a new site - jekyll new DeepuKSasidharan --skip-bundle, skipped the bundle install as I want to install to a vendor folder Cd into the folder DeepuKSasidharan and install gems to a vendor folder - bundle install --path vendor/bundle --full-index Start server - bundle exec jekyll serve and go to http://localhost:4000Using a Theme: Up next was setting up a custom theme, since I really like the minimal design of Medium, I decided to use Mediumish Jekyll Theme so I did the below steps to switch to this. Steps 3-5 above can be skipped and instead step 2 from the below can be done directly as well.  Delete the folder DeepuKSasidharan we created above Clone the theme to this folder - git clone https://github. com/wowthemesnet/mediumish-theme-jekyll. git DeepuKSasidharan Cd into the folder DeepuKSasidharan and install gems to a vendor folder - bundle install --path vendor/bundle --full-index Customize the _config. yaml file with my own user details, Google Analytics, Disqus ID and so on     I had to update the exclude section to add vendor/ to it and to . gitignore as well   Updated the jekyll-paginate plugin to jekyll-paginate-v2 in the plugins section   Commented out the baseurl section    Start server - bundle exec jekyll serve and go to http://localhost:4000Customizations: So now I had a good looking website with an about page and blog up and running. I customized the look and feel a bit and changed the default page from blogs to about. You can check the source code at deepu105/deepu105. github. io Now the next challenge was to make sure I can author once and post to both my blog and Dev. to, this means I have to make sure the front matter supported by Dev. to also works on my blog and any custom Liquid tags from Dev I use in the blog needs to work on my site as well. The first part was easy, I just had to customize my sites includes and layouts to use cover_image instead of image and use the tag: [] syntax for tags. I also added support for Dev. to like series and read time with a custom ruby plugin. Adding custom liquid tags: In order to use Dev. to tags, first I tried if I can reuse them from Dev since its OSS, but it seems like they are heavily coupled with Rails and internal models to be extracted into Gems. I created a ticket asking for it as well. So decided to write my own Liquid tags in Ruby. I reused available OSS Liquid tags and customized them to work like the Dev. to ones in syntax and feature. I ended up creating the codesandbox, twitter, gist, link, speakerdeck and youtube tags. You can find them here. Probably will add more as I use them. This is not scalable and I would love to see the Dev. to tags published as Ruby gems. For example, here is a simple stub for the youtube tag. 123456789101112131415161718192021module Jekyll   # A simple stub for the Dev. to youtube tag  class YoutubeTag &lt; Liquid::Tag   def initialize(name, id, tokens)    super    @id = id   end   def render(context)    %(&lt;p&gt;      &lt;div class= embed-video-container &gt;        &lt;iframe width= 710  height= 399  src= https://www. youtube. com/embed/#{@id}  allowfullscreen&gt;&lt;/iframe&gt;      &lt;/div&gt;    &lt;/p&gt;)   end  end end Liquid::Template. register_tag('youtube', Jekyll::YoutubeTag)Publishing to GitHub: Now that I have a site up and running with markdown posts that work in both my blog and Dev. to without having to make any adjustments, I decided to publish this to my Github accounts Github pages. But there was an issue here. Github doesn‚Äôt allow running any custom Ruby code on GitHub pages, so I can‚Äôt just push to GitHub and get the site built and published so I decided to write a simple script to do the site generation on my machine from the source branch and push it to the master branch on GitHub. 12345678910111213141516171819202122232425262728293031323334353637#!/bin/bashrm -rf _siteif [ -z  $(git status --porcelain)  ]; then  echo  &gt;&gt;&gt; Working directory clean   TMP_LOC=/tmp/deepu. github. io  /bin/rm -rf _site  /bin/rm -rf $TMP_LOC  echo  &gt;&gt; Building site   bundle update listen  bundle exec jekyll build  echo  &gt;&gt; Move site to temp folder   mkdir --parents $TMP_LOC  mv _site/* $TMP_LOC  echo  &gt;&gt; Checkout and clean master   git checkout master  find -mindepth 1 -depth -print0 | grep -vEzZ '(temp(/|$)|vendor(/|$)|\. git(/|$)|/\. gitignore$)' | xargs -0 rm -rvf  echo  &gt;&gt; Move site form temp &amp; publish to GitHub   mv $TMP_LOC/* .   now=$(date)  git add --all  git commit -am  Updated site on $now   git push origin master --force  echo  $now: Published changes to GitHub   git checkout site_srcelse  echo  Working directory is not clean. Commit changes!   exitfiMy current workflow: So now that I have things in place, I author posts as markdown with a full front matter like below and publish on my blog first. Then I publish the same to Dev. to 12345678---title:  Static Site Generators rundown - How I set up my own blog with Jekyll published: falsedescription: Static Site Generators comparisontags: [showdev, ruby, Jekyll, blogging]cover_image:canonical_url: https://deepu. tech/setting-up-a-blog-with-jekyll/---I‚Äôm not using the RSS import option in Dev as it uses the rendered blog and hence might need adjustments. I also set the canonical_url to my blog site. Future plans: There are some things that can be improved.  Use the Dev. to API to publish this direct from my publish script when I author a new post or make updates to an existing one. Update: This is done Improve the link tag and add some more tags for GitHub.  Use local assets image for my own blog and generate the image URL for Dev. to when publishing.  Currently, all links point to Dev. to, make the link tag smart enough to point to my blog when published to my site(I don‚Äôt want my readers to switch between sites). This might be a bit hard since Dev. to links have a random suffix. Update: This is doneSo what do you think? If you have any suggestions on improvements or questions leave a comment. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. Cover image credit: Photo by Patrick Fore on Unsplash Also published on Dev. to "
    }, {
    "id": 26,
    "url": "/functional-programming-in-java-for-beginners/",
    "title": "7 Functional programming techniques in Java - A primer",
    "body": "2019/07/30 - There is a lot of hype around functional programming(FP) and a lot of cool kids are doing it but it is not a silver bullet. Like other programming paradigms/styles, functional programming also has its pros and cons and one may prefer one paradigm over the other. If you are a Java developer and wants to venture into functional programming, do not worry, you don‚Äôt have to learn functional programming oriented languages like Haskell or Clojure(or even Scala or JavaScript though they are not pure functional programming languages) since Java has you covered and this post is for you. I‚Äôm not gonna dive into all functional programming concepts in detail, instead, I‚Äôm gonna focus on things that you can do in Java which are in line with functional programming concepts. I‚Äôm also not gonna discuss the pros and cons of functional programming in general. What is functional programming?: As per Wikipedia,  Functional programming is a programming paradigm‚Äîa style of building the structure and elements of computer programs‚Äîthat treats computation as the evaluation of mathematical functions and avoids changing-state and mutable data. Hence in functional programming, there are two very important rules  No Data mutations: It means a data object should not be changed after it is created.  No implicit state: Hidden/Implicit state should be avoided. In functional programming state is not eliminated, instead, its made visible and explicitThis means:  No side effects: A function or operation should not change any state outside of its functional scope. I. e, A function should only return a value to the invoker and should not affect any external state. This means programs are easier to understand.  Pure functions only: Functional code is idempotent. A function should return values only based on the arguments passed and should not affect(side-effect) or depend on global state. Such functions always produce the same result for the same arguments. Apart from these there are functional programming concepts below that can be applied in Java, we will touch upon these further down.  Higher-order-functions Closures Currying Recursion Lazy evaluations Referential transparencyUsing functional programming doesn‚Äôt mean its all or nothing, you can always use functional programming concepts to complement Object-oriented concepts, especially in Java. The benefits of functional programming can be utilized whenever possible regardless of the paradigm or language you use. And that is exactly what we are going to see. Functional programming in Java: So let us see how we can apply some of the functional programming concepts above in Java. We will be using Java 11 as it is the LTS version currently. First-class and higher-order functions: First-class functions(function as a first-class citizen) means you can assign functions to variables, pass a function as an argument to another function or return a function from another. Unfortunately, Java doesn‚Äôt support this and hence makes concepts like closures, currying and higher-order-functions less convenient to write. The closest to first-class functions in Java is Lambda expressions. There are also some built-in functional interfaces like Function, Consumer, Predicate, Supplier and so on under the java. util. function package which can be used for functional programming. A function can be considered as a higher-order-function only if it takes one or more functions as parameters or if it returns another function as a result. The closest to higher-order-functions we can get in Java is using Lambda expressions and built-in Functional interfaces. This is not the nicest looking way of doing higher-order-functions, but this is how it is in Java and its not that bad IMO. 12345678910111213141516171819202122232425262728public class HocSample {  public static void main(String[] args) {    var list = Arrays. asList( Orange ,  Apple ,  Banana ,  Grape );    // we are passing an array and an anonymous inner class instance of FnFactory as arguments to mapForEach method.     var out = mapForEach(list, new FnFactory&lt;String, Object&gt;() {      @Override      public Object execute(final String it) {        return it. length();      }    });    System. out. println(out); // [6, 5, 6, 5]  }  // The method takes an array and an instance of FnFactory as arguments  static &lt;T, S&gt; ArrayList&lt;S&gt; mapForEach(List&lt;T&gt; arr, FnFactory&lt;T, S&gt; fn) {    var newArray = new ArrayList&lt;S&gt;();    // We are executing the method from the FnFactory instance    arr. forEach(t -&gt; newArray. add(fn. execute(t)));    return newArray;  }  @FunctionalInterface // this doesn't do anything it is just informative.   public interface FnFactory&lt;T, S&gt; {    // The interface defines the contract for the anonymous class    S execute(T it);  }}Fortunately, can actually simplify the above example further using the built-in Function interface and using the lambda expression syntax. 1234567891011121314151617public class HocSample {  public static void main(String[] args) {    var list = Arrays. asList( Orange ,  Apple ,  Banana ,  Grape );    // we are passing the array and a lambda expression as arguments to mapForEach method.     var out = mapForEach(list, it -&gt; it. length());    // This can be further simplified to  mapForEach(list, String::length); , I'm writing the expanded version for readability    System. out. println(out); // [6, 5, 6, 5]  }  // The method takes an array and an instance of Function as arguments (we have replaced the custom interface with the built-in one)  static &lt;T, S&gt; ArrayList&lt;S&gt; mapForEach(List&lt;T&gt; arr, Function&lt;T, S&gt; fn) {    var newArray = new ArrayList&lt;S&gt;();    // We are executing the method from the Function instance    arr. forEach(t -&gt; newArray. add(fn. apply(t)));    return newArray;  }}Using these concepts along with lambda expressions we can write closures and currying like below 1234567891011121314151617181920212223242526272829public class ClosureSample {  // this is a higher-order-function that returns an instance of Function interface  Function&lt;Integer, Integer&gt; add(final int x) {    // this is a closure, i. e, a variable holding an anonymous inner class instance of the Function interface    // which uses variables from the outer scope    Function&lt;Integer, Integer&gt; partial = new Function&lt;Integer, Integer&gt;() {      @Override      public Integer apply(Integer y) {        // variable x is obtained from the outer scope of this method which is declared as final        return x + y;      }    };    // The closure function instance is returned here    return partial;  }  public static void main(String[] args) {    ClosureSample sample = new ClosureSample();    // we are currying the add method to create more variations    Function&lt;Integer, Integer&gt; add10 = sample. add(10);    Function&lt;Integer, Integer&gt; add20 = sample. add(20);    Function&lt;Integer, Integer&gt; add30 = sample. add(30);    System. out. println(add10. apply(5)); // 15    System. out. println(add20. apply(5)); // 25    System. out. println(add30. apply(5)); // 35  }}We can simplify this further with lambda expressions like below 123456789101112131415161718192021public class ClosureSample {  // this is a higher-order-function that returns an instance of Function interface  Function&lt;Integer, Integer&gt; add(final int x) {    // The lambda expression is returned here as closure    // variable x is obtained from the outer scope of this method which is declared as final    return y -&gt; x + y;  }  public static void main(String[] args) {    ClosureSample sample = new ClosureSample();    // we are currying the add method to create more variations    Function&lt;Integer, Integer&gt; add10 = sample. add(10);    Function&lt;Integer, Integer&gt; add20 = sample. add(20);    Function&lt;Integer, Integer&gt; add30 = sample. add(30);    System. out. println(add10. apply(5));    System. out. println(add20. apply(5));    System. out. println(add30. apply(5));  }}There are also many built-in higher-order-functions in Java for example here is the sort method from java. util. Collections 12345678List&lt;String&gt; list = Arrays. asList( Apple ,  Orange ,  Banana ,  Grape );// This can be simplified as  Collections. sort(list, Comparator. naturalOrder()); , I'm writing the expanded version for readabilityCollections. sort(list, (String a, String b) -&gt; {  return a. compareTo(b);});System. out. println(list); // [Apple, Banana, Grape, Orange]The Java stream API also provides many interesting higher-order-functions like forEach, map and so on. Pure functions: As we saw already a pure function should return values only based on the arguments passed and should not affect or depend on global state. It is possible to do this in Java except for some cases when there are checked exceptions involved. This is quite simple, take the below this is a pure function. It will always return the same output for the given input and its behavior is highly predictable. We can safely cache the method if needed. 123public static int sum(int a, int b) {  return a + b;}If we add an extra line in this function, the behavior becomes unpredictable as it now has a side effect that affects an external state. 1234567static Map map = new HashMap&lt;String, Integer&gt;();public static int sum(int a, int b) {  var c = a + b;  map. put(a +  +  + b, c);  return c;}So try to keep your functions pure and simple. Recursion: Functional programming favors recursion over looping. In Java, this can be achieved either by using the stream API or by writing recursive functions. Let us see an example for calculating the factorial of a number. I also ran a benchmark on these using JMH and mentioned the nanoseconds/operation below In traditional iterative approach: 1234567891011121314public class FactorialSample {  // benchmark 9. 645 ns/op  static long factorial(long num) {    long result = 1;    for (; num &gt; 0; num--) {      result *= num;    }    return result;  }  public static void main(String[] args) {    System. out. println(factorial(20)); // 2432902008176640000  }}The same can be done using recursion as below which is favored in functional programming. 12345678910public class FactorialSample {  // benchmark 19. 567 ns/op  static long factorialRec(long num) {    return num == 1 ? 1 : num * factorialRec(num - 1);  }  public static void main(String[] args) {    System. out. println(factorialRec(20)); // 2432902008176640000  }}The downside of the recursive approach is that it will be slower compared to an iterative approach most of the times(The advantage we are aiming for is code simplicity and readability) and might result in stack overflow errors since every function call needs to be saved as a frame to the stack. To avoid this tail recursion is preferred, especially when the recursion is done too many times. In tail recursion, the recursive call is the last thing executed by the function and hence the functions stack frame need not be saved by the compiler. Most compilers can optimize the tail recursion code the same way iterative code is optimized hence avoiding the performance penalty. Java compiler, unfortunately, does not do this optimization :( Now using tail recursion the same function can be written as below, but Java doesn‚Äôt optimize this, though there are workarounds, still it performed better in benchmarks. 1234567891011121314public class FactorialSample {  // benchmark 16. 701 ns/op  static long factorialTailRec(long num) {    return factorial(1, num);  }  static long factorial(long accumulator, long val) {    return val == 1 ? accumulator : factorial(accumulator * val, val - 1);  }  public static void main(String[] args) {    System. out. println(factorialTailRec(20)); // 2432902008176640000  }}We can also use the Java stream library for recursion but its slower than normal recursion at the moment. 1234567891011public class FactorialSample {  // benchmark 59. 565 ns/op  static long factorialStream(long num) {    return LongStream. rangeClosed(1, num)        . reduce(1, (n1, n2) -&gt; n1 * n2);  }  public static void main(String[] args) {    System. out. println(factorialStream(20)); // 2432902008176640000  }}Consider using stream API or recursion when writing Java code for readability and immutability, but if performance is critical or if the number of iterations will be huge use standard loops. Lazy evaluation: Lazy evaluation or non-strict evaluation is the process of delaying evaluation of an expression until it is needed. In general, Java does strict evaluation but for operands like &amp;&amp;, || and ?: it does a lazy evaluation. We can utilize this to do lazy evaluations when writing java code. Take this example where Java eagerly evaluates everything. 1234567891011121314151617181920public class EagerSample {  public static void main(String[] args) {    System. out. println(addOrMultiply(true, add(4), multiply(4))); // 8    System. out. println(addOrMultiply(false, add(4), multiply(4))); // 16  }  static int add(int x) {    System. out. println( executing add ); // this is printed since the functions are evaluated first    return x + x;  }  static int multiply(int x) {    System. out. println( executing multiply ); // this is printed since the functions are evaluated first    return x * x;  }  static int addOrMultiply(boolean add, int onAdd, int onMultiply) {    return (add) ? onAdd : onMultiply;  }}This will produce the below output and we can see that both functions are executed always 123456executing addexecuting multiply8executing addexecuting multiply16We can use lambda expressions and higher-order-functions to rewrite this into a lazily evaluated version 1234567891011121314151617181920212223242526public class LazySample {  public static void main(String[] args) {    // This is a lambda expression behaving as a closure    Function&lt;Integer, Integer&gt; add = t -&gt; {      System. out. println( executing add );      return t + t;    };    // This is a lambda expression behaving as a closure    Function&lt;Integer, Integer&gt; multiply = t -&gt; {      System. out. println( executing multiply );      return t * t;    };    // Lambda closures are passed instead of plain functions    System. out. println(addOrMultiply(true, add, multiply, 4));    System. out. println(addOrMultiply(false, add, multiply, 4));  }  // This is a higher-order-function  static &lt;T, R&gt; R addOrMultiply(      boolean add, Function&lt;T, R&gt; onAdd,      Function&lt;T, R&gt; onMultiply, T t  ) {    // Java evaluates expressions on ?: lazily hence only the required method is executed    return (add ? onAdd. apply(t) : onMultiply. apply(t));  }}This outputs the below and we can see that only required functions were executed 1234executing add8executing multiply16Type system: Java has a strong type system and with the introduction of the var keyword it now also has pretty decent type inference. The only thing missing compared to other functional programming languages are case classes. There are proposals for value classes and case classes for future Java versions. Let‚Äôs hope they make it. Referential transparency: From Wikipedia:  Functional programs do not have assignment statements, that is, the value of a variable in a functional program never changes once defined. This eliminates any chances of side effects because any variable can be replaced with its actual value at any point of execution. So, functional programs are referentially transparent. Unfortunately, there are not many ways to limit data mutation in Java, however by using pure functions and by explicitly avoiding data mutations and reassignment using other concepts we saw earlier this can be achieved. For variables, we can use the final keyword which is a non-access modifier to avoid mutations by reassignments. For example, the below will produce an error at compilation 123final var list = Arrays. asList( Apple ,  Orange ,  Banana ,  Grape );list = Arrays. asList( Earth ,  Saturn );But this will not help when variables are holding references to other objects, for example, the below mutation will work irrespective of the final keyword. 1234final var list = new ArrayList&lt;&gt;();list. add( Test );list. add( Test 2 );final keyword allows the internal state of referenced variables to be mutated and hence from a functional programming perspective final keyword is useful only for constants and to catch reassignments. Data structures: When using functional programming techniques it is encouraged to use functional data types such as Stacks, Maps and Queues. Hence maps are better than arrays or hash sets in functional programming as data stores. Conclusion: This is just an introduction for those who are trying to apply some functional programming techniques in Java. There are lot more that can be done in Java and Java 8 added a lot of API to make it easy to do functional programming in Java, like the stream API, Optional interface, functional interfaces and so on. As I said earlier functional programming is not a silver bullet but it offers a lot of useful techniques for more understandable, maintainable and testable code. It can co-exist perfectly well with imperative and object-oriented programming styles. In fact, we all should be using the best of everything. This video from Venkat Subramaniam is a great resource to dive deep into functional programming in Java                         I hope you find this useful. If you have any question or if you think I missed something please add a comment. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. Also published on Dev. to "
    }, {
    "id": 27,
    "url": "/jhipster-microservices-with-istio-service-mesh-on-kubernetes/",
    "title": "How to set up Java microservices with Istio service mesh on Kubernetes",
    "body": "2019/07/23 - Originally published at Medium on 17-Nov-2018. This post has been updated since to work with the latest version of JHipster(6. 3. 0) and Istio(1. 3. 0). Istio is the coolest kid on the DevOps and Cloud block now. For those of you who aren‚Äôt following close enough ‚Äî Istio is a service mesh for distributed application architectures, especially the ones that you run on the cloud with Kubernetes. Istio plays extremely nice with Kubernetes, so nice that you might think that it‚Äôs part of the Kubernetes platform. If you are still wondering, what the heck is a service mesh or Istio? then let‚Äôs have an overview of Istio. Istio: Istio provides the following functionality in a distributed application architecture:    Service discovery ‚Äî Traditionally provided by platforms like Netflix Eureka or Consul.     Automatic load balancing ‚Äî You might have used Netflix Zuul for this.     Routing, circuit breaking, retries, fail-overs, fault injection ‚Äî Think of Netflix Ribbon, Hytrix and so on.     Policy enforcement for access control, rate limiting, A/B testing, traffic splits, and quotas ‚Äî Again you might have used Zuul to do some of these.     Metrics, logs, and traces ‚Äî Think of ELK or Stack driver     Secure service-to-service communication  Below is the architecture of Istio. Istio architecture It can be classified into 2 distinct planes. Data plane: Is made of Envoy proxies deployed as sidecars to the application containers. They control all the incoming and outgoing traffic to the container. Control plane: It uses Pilot to manages and configure the proxies to route traffic. It also configures Mixer to enforce policies and to collect telemetry. It also has other components like Citadel, to manage security, and Galley, to manage configurations. Istio can also configure an instance of Grafana, Prometheus, Jaeger, and Kiali for Monitoring and Observability. You can use this or use your existing monitoring stack as well if you wish to do so. I hope this provides an overview of Istio, now let‚Äôs focus on the goal of this article. Preparing the Kubernetes cluster: First, let us prepare a Kubernetes cluster to deploy Istio and our application containers. Follow the instructions for any one of the platforms you prefer. Prerequisites: We will be using Helm to install Istio on the Kubernetes cluster and kubectl for deploying the applications. Helm: The Kubernetes package manager. Install it. kubectl: The command-line tool to interact with Kubernetes. Install and configure it. Create a cluster on Azure Kubernetes Service(AKS): If you are going to use Azure, then install Azure CLI to interact with Azure. Install and login with your Azure account (you can create a free account if you don‚Äôt have one already). If not skip this section. First, let us create a resource group. You can use any region you like here instead of East-US. 1$ az group create --name eCommerceCluster --location eastusCreate the Kubernetes cluster: 1234567$ az aks create \ --resource-group eCommerceCluster \ --name eCommerceCluster \ --node-count 4 \ --kubernetes-version 1. 13. 7 \ --enable-addons monitoring \ --generate-ssh-keysThe node-count flag is important as the setup requires at least four nodes with the default CPU to run everything. You can try to use a higher kubernetes-version if it is supported, else stick to 1. 13 The cluster creation could take while so sit back and relax. üçπ Once the cluster is created, fetch its credentials to be used from kubectl by running the below command. It automatically injects the credentials to your kubectl configuration under ~/. kube/config 123$ az aks get-credentials \ --resource-group eCommerceCluster \ --name eCommerceClusterYou can view the created cluster in the Azure portal: Kubernetes cluster in AKS Run kubectl get nodes to see it in the command line and to verify that kubectl can connect to your cluster. Cluster Nodes Proceed to the Install and setup Istio section. Create a cluster on Google Kubernetes Engine(GKE): If you are going to use Google Cloud Platform(GCP) then install Gcloud CLI to interact with GCP. Install and login with your GCP account (you can create a free account if you don‚Äôt have one already). You can set a region and zone using below commands or you can pass the zone option while executing each command. 12$ gcloud config set compute/region europe-west1$ gcloud config set compute/zone europe-west1-bFirst, we need a GCP project, you can either use an existing project that you have or create a new one using GCloud CLI with below command: 1$ gcloud projects create jhipster-demo-deepuSet the project you want to use as the default project: 1$ gcloud config set project jhipster-demo-deepuNow let us create a cluster for our application with the below command: 1234$ gcloud container clusters create hello-hipster \  --cluster-version 1. 13 \  --num-nodes 4 \  --machine-type n1-standard-2The num-nodes and machine-type flags are important as the setup requires at least four nodes with a bigger CPU to run everything. You can try to use a higher cluster-version if it is supported, else stick to 1. 13. The cluster creation could take while so sit back and relax. üçπ Once the cluster is created, fetch its credentials to be used from kubectl by running the below command. It automatically injects the credentials to your kubectl configuration under ~/. kube/config 1$ gcloud container clusters get-credentials hello-hipsterYou can view the created cluster in the GCP GUI. Kubernetes cluster on GKE Run kubectl get nodes to see it in the command line and to verify that kubectl can connect to your cluster. Cluster Nodes Install and setup Istio: Install Istio on your local machine by following these steps: 123456789$ cd ~/$ export ISTIO_VERSION=1. 3. 0$ curl -L https://git. io/getLatestIstio | sh -$ ln -sf istio-$ISTIO_VERSION istio$ export PATH=~/istio/bin:$PATHFirst, create a role binding on the Kubernetes cluster for Istio. 1234$ kubectl create clusterrolebinding cluster-admin-binding \ --clusterrole=cluster-admin \ --user= $(gcloud config get-value core/account) Let us create a namespace for Istio. 1$ kubectl create namespace istio-systemNow let us install Istio on our Kubernetes cluster using the provided helm charts from Istio. 123456789101112$ cd ~/istio-$ISTIO_VERSION# Install the Istio CRDs$ helm template install/kubernetes/helm/istio-init --name istio-init --namespace istio-system | kubectl apply -f -# Run this to verify all CRDs are installed. It should output 23 for this version of Istio. $ kubectl get crds | grep 'istio. io\|certmanager. k8s. io' | wc -l# Install the Istio demo set up so that we get Grafana, Jaeger &amp; Kiali set up as well. # For production, use the Istio default setup. Refer https://istio. io/docs/setup/kubernetes/install/helm/$ helm template install/kubernetes/helm/istio --name istio --namespace istio-system \  --values install/kubernetes/helm/istio/values-istio-demo. yaml | kubectl apply -f -Wait for the pods to run, these will be deployed to the istio-system namespace. 1$ watch kubectl get pods -n istio-systemOnce the pods are in running status, exit the watch loop and run the below to get the Ingress gateway service details. This is the only service that is exposed to an external IP. 1234$ kubectl get svc istio-ingressgateway -n istio-systemNAME          TYPE      CLUSTER-IP   EXTERNAL-IPistio-ingressgateway  LoadBalancer  10. 27. 249. 83  35. 195. 81. 130If the istio-ingressgateway shows external IP as , wait a few minutes until an IP address has been assigned. The external IP is very important here, let us save this to an environment variable so that we can use it in further commands. 1234$ export \ INGRESS_IP=$(kubectl -n istio-system get svc \ istio-ingressgateway \ -o jsonpath='{. status. loadBalancer. ingress[0]. ip}')Now our Kubernetes cluster is ready for Istio. üéâ For advanced Istio setup options refer to https://istio. io/docs/setup/kubernetes/ Creating the microservice application stack: In one of my previous posts, I showcased how to create a full-stack microservice architecture using JHipster and JDL. You can read the post here if you want to learn more details about it. For this exercise, we will use the same application but we will not use the Eureka service discovery option we used earlier. Also, note that the store application is further split into Gateway and Product applications. Architecture: Here is the architecture of the microservice that we are going to create and deploy today. Microservice architecture with Istio It has a gateway application and three microservice applications. Each of them has its own database. You can see that each application has an Envoy proxy attached to the pod as a sidecar. Istio control plane components are also deployed to the same cluster along with Prometheus, Grafana, and Jaeger. The Ingress gateway from Istio is the only entry point for traffic and it routes traffic to all microservices accordingly. Telemetry is collected from all the containers running in the cluster, including the applications, databases, and Istio components. Compared to the architecture of the original application here, you can clearly see that we replaced the JHipster registry and Netflix OSS components with Istio. The ELK monitoring stack is replaced with Prometheus, Grafana and Jaeger configured by Istio. Here is the original architecture diagram without Istio for a quick visual comparison. Microservice architecture with Netflix OSS Application JDL: Let‚Äôs take a look at the modified JDL declaration. You can see that we have declared serviceDiscoveryType no here since we will be using Istio for that. 400: Invalid requestDeployment JDL: JHipster version 5. 7. 0 introduced support for deployment declaration straight in the JDL Towards the future of #JHipster, #ScaffoldingAsCodeCheck this out. Soon you will be able to define apps, entities and deployment options with a single JDL file and generate everything with a single command. Hopefully, we can demo this for @Devoxx https://t. co/u28cwaymfc &mdash; Deepu K Sasidharan ( ‡¥¶‡µÄ‡¥™‡µÅ, ‡Æ§‡ØÄ‡Æ™‡ØÅ, ‡§¶‡•Ä‡§™‡•Ç ) (@deepu105) October 28, 2018We have the below in our JDL which declares our Kubernetes deployment: 12345678910deployment { deploymentType kubernetes appsFolders [store, invoice, notification, product] dockerRepositoryName  deepu105  serviceDiscoveryType no istio true kubernetesServiceType Ingress kubernetesNamespace jhipster ingressDomain  35. 195. 81. 130. nip. io }The serviceDiscoveryType is disabled and we have enabled Istio support ‚Äî the Envoy sidecars are injected automatically for the selected applications. Istio routes are also generated for the applications automatically. The kubernetesServiceType is set as Ingress, which is very important as Istio can only work with an Ingress controller service type. For Ingress, we need to set the domain DNS and this is where the Istio ingress gateway IP is needed. Now we need a DNS for our IP. For real use-cases, you should map a DNS for the IP, but for testing and demo purposes we can use a wildcard DNS service like nip. io to resolve our IP. Just append nip. io to our IP and use that as the ingressDomain. Note: I was switching between multiple clusters while writing this article as I didn‚Äôt want to keep them running and hence my istio-ingressgateway IP might be different between samples and screenshots. Use the IP based on your own setup if you are running these samples. Generate the applications and deployment manifests: Now that our JDL is ready, let us scaffold our applications and Kubernetes manifests. Create a new directory and save the above JDL in the directory. Let us name it app-istio. jdl and then run the import-jdl command. 12$ mkdir istio-demo &amp;&amp; cd istio-demo$ jhipster import-jdl app-istio. jdlThis will generate all the applications and install the required NPM dependencies in each of them. Once the applications are generated the deployment manifests will be generated and some useful instruction will be printed to the console. Generation output Open the generated code in your favorite IDE/Editor and explore the code. Interim issues with generated code: There was a bug in the latest JHipster version which creates some incorrect URLs for Istio, it has been fixed as of JHipster version 6. 3. 0 here is the PR for the issue. Deploy to Kubernetes cluster using Kubectl: Now let us build and deploy our applications. Run the . /gradlew bootJar -Pprod jibDockerBuild command in the store, product, invoice, and notification folders to build the docker images. Once the images are built, push them to your docker repo with these commands. Note to change the Docker hub id from deepu105 to your id. 1234567891011$ docker image tag store deepu105/store$ docker push deepu105/store$ docker image tag invoice deepu105/invoice$ docker push deepu105/invoice$ docker image tag notification deepu105/notification$ docker push deepu105/notification$ docker image tag product deepu105/product$ docker push deepu105/productOnce the images are pushed, navigate into the generated Kubernetes directory and run the provided startup script. (If you are on windows you can run the steps in kubectl-apply. sh manually one by one. ) 12$ cd kubernetes$ . /kubectl-apply. shRun watch kubectl get pods -n jhipster to monitor the status. Deployed applications: Once all the pods are in running status we can explore the deployed applications Application gateway: The store gateway application is the entry point for our microservices. Get the URL for the store app by running echo store. jhipster. $INGRESS_IP. nip. io, we already stored the INGRESS_IP to environment variables while creating the Istio setup. The URLs are also printed on console by the kubectl-apply. sh script. Visit the URL in your favorite browser and explore the application. Try creating some entities for the microservices: Store gateway application Monitoring: Istio setup includes Grafana and Prometheus configured to collect and show metrics from our containers. Let‚Äôs take a look. Let us look at Grafana by visiting the provided URL. Get it by running echo grafana. istio-system. $INGRESS_IP. nip. io: Grafana dashboard for the Store application Grafana uses the metrics scraped by Prometheus. By default, only Grafana is exposed to external IP and hence we will use kubectl port forwarding to set up a secure tunnel to Prometheus available on localhost:9090: 123$ kubectl -n istio-system \  port-forward $(kubectl -n istio-system get pod -l \  app=prometheus -o jsonpath='{. items[0]. metadata. name}') 9090:9090Prometheus dashboard Observability: Istio configures Jaeger for distributed tracing and Kiali for service observability. Let us take a look at them. Get the Jaeger URL by running echo jaeger. istio-system. $INGRESS_IP. nip. io: Jaeger tracing dashboard You can make some requests in the application and find it in the tracing dashboard by querying for the service. Click on any request to see tracing details. Let us now look at Kiali. Get the URL by running echo kiali. istio-system. $INGRESS_IP. nip. io, use the credentials user: admin, password: admin to log in: Kiali service graph Conclusion: Istio provides building blocks to build distributed microservices in a more Kubernetes-native way and takes the complexity and responsibility of maintaining those blocks away from you. This means you do not have to worry about maintaining the code or deployments for service discovery, tracing and so on. Istio documentation says  Deploying a microservice-based application in an Istio service mesh allows one to externally control service monitoring and tracing, request (version) routing, resiliency testing, security and policy enforcement, etc. , in a consistent way across the services, for the application as a whole. Werner Vogels (CTO of AWS) quoted at AWS Re:Invent  ‚ÄúIn the future, all the code you ever write will be business logic. ‚Äù Istio Service mesh helps to make that reality closer. This lets you worry only about the applications that you are developing and with JHipster that future is truly here and you just need to worry about writing your business logic. While this is great, it is not a silver bullet. Keep in mind that Istio is fairly new compared to other stable and battle-tested solutions like JHipster Registry (Eureka) or Consul and overall such architectures are suitable only for complex distributed applications. Also, another thing to keep in mind is the resource requirements. The same microservices with JHipster Registry or Consul can be deployed to a 2 node cluster with 1 vCPU and 3. 75 GB of memory per node in GCP while you need a 4 node cluster with 2 vCPUs and 7. 5 GB of memory per node for Istio enabled deployments. The demo profile from Istio, we used, doesn‚Äôt apply any request limits for resources, and by adding and tuning those, the minimum requirement could be reduced. But still, I don‚Äôt think you can get it as low as that is needed for the JHipster registry option. In a real-world use case, the advantages of not having to maintain the complex parts of your infra vs having to pay for more resources might be a decision that has to be taken based on your priorities and goals. A huge shout out to Ray Tsang for helping me figure out an optimal cluster size for this application originally. Also a huge thank you from myself and the community to both Ray and Srinivasa Vasu for adding the Istio support to JHipster. JHipster provides a great Kubernetes setup to start with which you can further tweak as per your needs and platform. The Istio support will improve further over time, but it‚Äôs still a great starting point especially to learn. To learn more about JHipster and Full stack development, check out my book ‚ÄúFull Stack Development with JHipster‚Äù on Amazon and Packt. There is a great Istio tutorial from Ray Tsang here. If you liked this article you might like my book as well. You can get it from Packt and Amazon.  Devoxx 2018: I did a talk at Devoxx 2018 along with Julien Dubois doing the same demo and promised that I‚Äôd write a detailed blog about it. This blog was originally based on that. Had a wonderful time at #devoxx2018, sad that I had to leave early due to work commitments. Had 3 talks and 1 of them with my friend and the real hipster @juliendubois, all the talks were well received and I&#39;m grateful for all the positive feedback. Will write blogs about it soon &mdash; Deepu K Sasidharan ( ‡¥¶‡µÄ‡¥™‡µÅ, ‡Æ§‡ØÄ‡Æ™‡ØÅ, ‡§¶‡•Ä‡§™‡•Ç ) (@deepu105) November 15, 2018You can watch this video to see JHipster + Istio in action.                          Here are the slides on Speaker Deck.                                                 If you like JHipster don‚Äôt forget to give it a star on Github. If you like this article, please leave likes/comments. I hope to write more about Istio soon. You can follow me on Twitter and LinkedIn. Also published on Dev. to "
    }, {
    "id": 28,
    "url": "/make-the-most-out-of-vscode/",
    "title": "My VS Code setup - Making the most out of VS Code",
    "body": "2019/07/17 - Please follow me on Twitter for updates. Visual Studio Code(I like the sound of VS Code better), I just love it. It is my primary IDE. I always loved lightweight editors over IDEs. Many years ago I was using Eclipse for development and Notepad++ with some plugins for all other lightweight stuff. Then I discovered sublime text and was using it for a while. I still was finding Eclipse too heavyweight when I was doing web development. Then came Brackets from Adobe. It was a fairly nice editor especially for web development and I started using it heavily for web development. But Brackets was bit slow back then on a large codebase. Then came Atom which revolutionized the NodeJS desktop application landscape by introducing the Atom shell which ultimately became Electron. So I switched to Atom and loved its slick interface and nice pluggable features. It became my primary editor for all web development. So Electron paved the way for VS Code and though at first, I was skeptical due to the association with Visual Studio, I tried it out and was amazed by its speed and user experience. There was no turning back now. I slowly started using VS Code for most of my day to day development, except for Java which I was using IntelliJ by now. Fast forward now below are the editor/IDE I use for development.  VS Code: JavaScript, TypeScript, EJS, HTML, CSS, Golang, Python, Ruby, Shell, Docker, Kubernetes, Terraform and everything in between including writing this blog post.  IntelliJ Idea: Java, Scala, Kotlin (Though I use VS Code for minor edits and to read the code, etc) VIM: For quick edits from the command line. PluginsOf course VS Code makes all this possible by allowing the use of plugins and there is a lot to choose from. Here are the plugins that I personally use to work on the above-said languages. You can use the code --install-extension command to install them from the terminal. Language support: Based on the Languages you work with you can add syntax, utility and language support plugins for those. I use the below JavaScript/TypeScript/Web:  EJS language support - Adds EJS template support.      code --install-extension DigitalBrainstem. javascript-ejs-support     Close HTML/XML tag - Auto close HTML/XML tags.      code --install-extension Compulim. compulim-vscode-closetag     ESLint - Adds support for ESLint rules.      code --install-extension dbaeumer. vscode-eslint     TSLint - Adds support for TSLint rules.      code --install-extension ms-vscode. vscode-typescript-tslint-plugin     Prettier - Adds support for Prettier formatter.      code --install-extension esbenp. prettier-vscode     es-beautifier - Formats JS according to Eslint rules.      code --install-extension dai-shi. vscode-es-beautifier    Go:  Go - Adds rich language support for Golang.      code --install-extension ms-vscode. Go    JVM:  Language Support for Java - Adds Java language support.      code --install-extension redhat. java     Debugger for Java - Adds lightweight Java debugging support.      code --install-extension vscjava. vscode-java-debug     JHipster JDL - Adds syntax support for JHipster JDL files.      code --install-extension jhipster-ide. jdl    The Java support indeed is getting better and better, so I hope one day I can completely switch to VS Code. Announcing the Visual Studio Code Installer for #Java https://t. co/u6lyKW0xFS &mdash; Markus Eisele (@myfear) June 16, 2019Python:  Language Support for Python - Adds Python language support, linting and debugging support.      code --install-extension ms-python. python    Cloud, Container &amp; others:  Docker - Adds Docker support(view and manage containers) and support for Docker, docker-compose files.      code --install-extension ms-azuretools. vscode-docker     Jenkinsfile Support - Adds syntax highlighting support for Jenkinsfile‚Äôs.      code --install-extension secanis. jenkinsfile-support     Terraform - Adds support for Terraform files.      code --install-extension mauve. terraform     Markdown all in one - Full markdown support with live preview, keyboard shortcuts, etc.      code --install-extension yzhang. markdown-all-in-one     PlantUML - Rich PlantUML support with live preview.      code --install-extension jebbs. plantuml     Visual Studio IntelliCode - Adds AI assisted intellisense support for multiple languages.      code --install-extension VisualStudioExptTeam. vscodeintellicode     YAML - Adds YAML support.      code --install-extension redhat. vscode-yaml    Theme: Dark++ Italic: My default theme. Similar to VS Code default dark theme but has support for FiraCode and Operator Mono fonts. I personally use FiraCode.  code --install-extension idbartosz. darkpp-italic Material icon theme: A nice icon theme based on material icons.  code --install-extension PKief. material-icon-theme Peacock: Subtly changes the workspace color of your workspace. Helpful to identify when you have many windows open.  code --install-extension johnpapa. vscode-peacock Tools: Auto rename tag: Automatically rename paired HTML/XML tags  code --install-extension formulahendry. auto-rename-tag Bracket pair colorizer 2: Marks matching bracket pairs with unique colors. This really makes reading code nicer  code --install-extension CoenraadS. bracket-pair-colorizer-2 Change case: Convert between different cases. Trust me this is so handy  code --install-extension wmaurer. change-case Code spell checker: Fairly useful for spell checking within code. Takes cameCase etc into account  code --install-extension streetsidesoftware. code-spell-checker Easy snippet maker: Useful to store re usable snippets.  code --install-extension tariky. easy-snippet-maker EditorConfig for VS Code: Add support for EditorConfig.  code --install-extension EditorConfig. EditorConfig Git History: Enable viewing Git history within VS Code.  code --install-extension donjayamanne. githistory Gitignore: Makes it easy to work with . gitignore files.  code --install-extension codezombiech. gitignore Hide gitignored: Hides patterns defined in . gitignore from the editors explorer.  code --install-extension npxms. hide-gitignored Mark as excluded: Exclude stuff right from the explorer tree.  code --install-extension jcmordan. mark-as-excluded Toggle Excluded Files: Easily toggle between showing and hiding excluded files/folders.  code --install-extension eamodio. toggle-excluded-files IntelliJ IDEA Keybindings: I have bad muscle memory so wanted to use the same keyboard shortcuts as IntelliJ. There are mappings available for Sublime, Atom and so on.  code --install-extension k--kato. intellij-idea-keybindings Sort JSON: Sorts JSON object keys.  code --install-extension richie5um2. vscode-sort-json Test Explorer UI: Adds an explorer panel for running tests. Supports multiple languages and testing frameworks.  code --install-extension hbenl. vscode-test-explorer Todo Tree: Aggregate TODO, FIXME, etc in a tree view in explorer.  code --install-extension Gruntfuggly. todo-tree Terminal setupIf you are using Zsh shell with Oh-my-zsh like me as explained here, you might want to do the below to get the same terminal experience in the integrated VSCode terminal as well.  Follow these steps  Download and install a patched font.  On Linux, run fc-cache -f -v to refresh font cache.  On VSCode, open Preferences ‚Üí Settings and click on the {} icon to open JSON mode and set the below  123456  terminal. integrated. shell. linux :  /usr/bin/zsh ,  terminal. integrated. fontFamily :  'SauceCodePro Nerd Font Mono','Source Code Pro' ,  terminal. integrated. rightClickCopyPaste : true,  terminal. integrated. fontSize : 14,  terminal. integrated. cursorStyle :  underline ,  terminal. integrated. cursorBlinking : true    Replace linux with osx if you are on a Mac.  ConclusionThis might seem like too many plugins but on my configuration VS Code is lightning fast and loads up immediately and is faster then IntelliJ to load and work with. The beauty of VS Code is that you don‚Äôt need all the plugin all the time, you can disable the ones not required per workspace to make it even faster. Many people ask me why I use VS Code when I have IntelliJ and my answer have been always the same. IntelliJ is great but its also quite heavy. While all those advanced features are needed for Java, Scala or Kotlin development, VS Code is perfectly capable of giving a nice developer experience for lightweight languages like JS, TS, Go, Python, Rust, Ruby, etc. As a regular user of both IntelliJ and VS Code, I prefer VS Code as much as possible. The user experience is much nicer for my taste. In fact, I like the developer experience in VS Code better for JavaScript, TypeScript, Web, Python, and Golang. Also switching between them for JVM projects and others don‚Äôt feel weird for me as I have the same keyboard mappings for both. The only time I fire up IntelliJ these days is when I want to do full-fledged Java development. For everything else, I use VS Code. I hope you find this useful. If you have any questions or if you think I missed something please add a comment. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. Also published on Dev. to "
    }, {
    "id": 29,
    "url": "/reflection-on-golang/",
    "title": "My reflections on Golang",
    "body": "2019/07/12 - Please follow me on Twitter for updates. Do I like Go? Yes. Would I use it for every use case I have? Definitely not. Having worked on most of these said languages I won&#39;t choose Go for general purpose atleast not current version of Go, may be 2. 0 has more potential. &mdash; Deepu K Sasidharan ( ‡¥¶‡µÄ‡¥™‡µÅ, ‡Æ§‡ØÄ‡Æ™‡ØÅ, ‡§¶‡•Ä‡§™‡•Ç ) (@deepu105) March 7, 2019Don‚Äôt get me wrong, I like Go for what it is but like every other programming language, it is always a love-hate relationship. No programming language is perfect and all of them have their own merits and use cases. I hate it when I see people overusing something and I see that pattern with Go these days. To be fair, I have done my fair share of overusing in my career as well (mostly with JavaScript) and I can see why people do it. This is not gonna be a blog bashing Go or praising Go, it is just what I think of it after using it for over 9 months. Before I start a rant on the good and bad of Go, here is some background. After being in the tech industry for over 10 years, I would like to think of myself as a pragmatic programmer or at least as someone getting closer to that - that should be a programmer‚Äôs Nirvana. I didn‚Äôt even plan to be a programmer, if you ask the 18-year-old self of me, he would say that he wanted to be an astrophysicist or a robotics engineer(Yes building space robots were my dream). Like most teenage dreams, it didn‚Äôt happen and I ended up in tech instead. Though landing an IT Job was an accident, programming wasn‚Äôt alien to me. I did learn some C/C++ when I was in high school to help my girlfriend with her project and did dabble in some PHP, JavaScript, HTML and Flash(ActionScript) during my early college years for personal projects and blogs. So when I got a real IT job without having an IT background, I did what many in that situation did, I started learning the language that I stumbled upon first based on the task I was given, which happened to be Java. Being a quick learner and having some idea of programming concepts from C/C++ Java wasn‚Äôt that hard to learn and I was a pretty decent Java programmer in a few months. Then I was tasked with building some Web UI and I dived deep into the world of HTML, CSS, and JavaScript and honestly fell in love with JavaScript due to its flexibility and ease. I mastered JQuery and soon become the go-to guy for front end stuff in the office. I was anything but pragmatic back then, I was preaching JavaScript to everyone and would vehemently debate anyone who thought JS was a bad language. Fast forward to now and if I look back I have done projects in C/C++, PHP, JavaScript, TypeScript, HTML, CSS, Java, Groovy, Scala, Python and recently Go. I think this exposure probably helped me become more pragmatic as I have started to look at programming languages as tools and each of them has their own strengths and weaknesses. Well, there is more to this story but that‚Äôs for another time, the point is to set a baseline for the below reflections so that I don‚Äôt sound like someone just trying Go and going on a rant. Go is the latest language I learned and worked with, I have worked on a CLI project built with Go for over 9 months now, building a powerful scaffolding engine with my team(Yes, pretty much like JHipster) that uses Go templates where you could create what we call blueprints at XebiaLabs. So yes I have done much more than a hello world app with Go. Without wasting more time on unrelated things here is what I like about Go and what I don‚Äôt like. What I like about Go: Simplicity: I like the fact that Go is a simple language(Going through the entire language features on the tour page literally takes 15 minutes unless you do the exercises) and unlike Scala, Rust or even JavaScript Go doesn‚Äôt have many ways of doing the same thing which is extremely valuable for people working in teams and companies wanting to write maintainable code where even a newly joined employee can read and understand the code without needing much help. I think this is one of the biggest reasons that is driving Go adoption. If you have worked on large scale projects you know how difficult it is when the code is unreadable and every new team member has to spend so much time trying to understand what a piece of code does. So I was really happy when I saw that Go doesn‚Äôt have features that rely heavily on implicit and such. The language features and concepts are easy to grasp and you can start being productive in Go quite soon. The only concepts that might seem bit complex are the concurrency part and even that is simpler compared to other languages. Language provided code style and vetting: This is such a time saver. IMO every language should just do this so that you don‚Äôt waste time debating code style and setting up lint rules. Go provides opinionated formatting, linting &amp; vet tool as part of the package and the Go compiler even enforces things like unused variables and stuff. Most of the IDE/Editor plugins also use these tools for formatting and linting and hence helps to keep consistent code style across Go projects which again adds to readability and maintenance. Goroutines &amp; Channels: This is one of the biggest strengths of Go. The native support for concurrency and parallelism. This makes Go an ideal candidate for applications that require heavy concurrent and/or parallel processing, networking and so on. Goroutines makes it so easy to start lightweight threads and channels provide a way to communicate between these threads acting like a message bus. 1234567891011func main() {	messages := make(chan string)	collected := make([]string, 2)	go func() { messages &lt;-  ping  }()	go func() { messages &lt;-  pong  }()	collected = append(collected, &lt;-messages)	collected = append(collected, &lt;-messages)	fmt. Println(collected) // [ pong ping ]}Closures &amp; callbacks: If you have used JavaScript you would know how useful closures and callbacks are. Go like JavaScript treats functions as objects and hence can be assigned to variables, stored in maps, passed as function parameters and returned from functions. It also supports creating nested closures and anonymous functions which helps to encapsulate context. The behavior is pretty much similar to JavaScript. So you can apply some functional programming concepts in Go as well. 123456789101112131415161718192021222324func main() {	// an unnecessarily complicated example	type fnType = func(a int, b int) int	fnMap := map[string]fnType{		 ADD : func(a int, b int) int {			return a + b		},		 SUB : func(a int, b int) int {			return a - b		},	}	// this is a closure	localFn := func(method string) fnType {		return fnMap[method] // returns a function	}	printer := func(fn func(method string) fnType, method string) {		fmt. Println(fn(method)(10, 5)) // callback	}	// function passed as parameter	printer(localFn,  ADD )	printer(localFn,  SUB )}Type assertion and switches: Go provides a nice way of asserting types and can be used with a switch statement which makes it easier to do reflection and such. Multiple returns: This is quite a handy feature like in Python, we are used to deconstructing objects/arrays to achieve this in JavaScript and using Tuples and such in some languages. The returns can also be named which is nice for readability. Tooling: The in-code test coverage highlight in VsCode for @golang is slick. This is the best way to ensure you have good coverage@code pic. twitter. com/nk8iMwenCz &mdash; Deepu K Sasidharan ( ‡¥¶‡µÄ‡¥™‡µÅ, ‡Æ§‡ØÄ‡Æ™‡ØÅ, ‡§¶‡•Ä‡§™‡•Ç ) (@deepu105) February 14, 2019As mentioned earlier Go provides standard tooling for formatting, linting and so on and the language design makes it easy to build tooling for Go and hence editors/IDE has nice features like test generation, code coverage and so on. For example, the VSCode integration for Go provides the below options which helps with consistency and less boilerplate to write by hand.  Doesn‚Äôt need a runtime: Go doesn‚Äôt need a runtime like JVM or NodeJS, Go applications can be compiled into an executable cross-platform binary using the standard Go tooling. This makes Go applications portable and platform-independent. What I don‚Äôt like about Go: Simplicity: This is where the love-hate relationship starts, Go is a simple language which is nice but at times it feels too simple &amp; verbose and coming from Java/JavaScript ecosystem you are spoiled with some nice features &amp; syntax sugars which IMO makes the code more expressive and helps to keep it DRY. The things that I miss the most are  Generics: This is currently being considered in the next major iteration of Go, but until then this just makes you repeat code unnecessarily. I have lost count of the number of times I had to repeat the same block of code for different types where Generics would have kept it nice and simple. This is also one reason you don‚Äôt see libraries like Lodash for Go.  Standard error handling: This also seems to be coming in the next major iteration of Go but until it lands I can complain. Anyone writing Go will remember doing if err != nil uncountable times in your code. Removing those might cut the codebase in size by at least 20% Default values: I would love to see this in Go, this is quite useful. Maybe I‚Äôm just spoiled by JS. Too much boilerplate(not suitable for DRY): Go being too simple means you would have to write a lot of code as the language doesn‚Äôt offer constructs like map, reduce, and so on, and add the lack of generic on top means you would end up writing a lot of utility code and a lot of that will be repeated to accommodate different types. Imagine writing a map function in Go, you would have to write one for every combination of maps that can be used. These factors don‚Äôt make it easy to do DRY programming in Go. Dependency management: The dependency management in the Go ecosystem feels immature and too basic compared to other mainstream languages. Importing packages from Git is nice but it also makes it more fragile. What can go wrong when you are depending on a Git branch on your production application right! There is no way to use relative dependencies(Can‚Äôt beat NPM link!). These problems are similar to the issues with the dependency range in Node package managers. Glide seems to be a popular choice but still is not as mature as solutions in other languages. In the project, I work on we used Gradle along with Gogradle and though it works fine the developer experience is not as good as using Gradle/Maven for Java project or using NPM on a NodeJS project. Source code in GOPATH: Go recommends you to create your Go projects under the GOPATH. Maybe it is just me, but I hate this as I would normally like to organize my code. For example, I have a ~/workspace/ folder where I organize my projects by the organization. If I follow the Go recommendation I have to put the project under /home/deepu/go/src along with all the library source code that is downloaded. If you don‚Äôt follow this then most of the Go tooling just doesn‚Äôt work. Currently, I have a specific Gradle task that copies over all the vendor libs to my local Gopath inside ~/workspace/XL/&lt;project&gt; to workaround this. Confusing pointer behaviors: Go has pretty good pointer support and the default behavior is to pass an object by value. If you want to pass something by reference you have to mark it specifically. But this behavior is not very consistent as Maps and Slices by default are passed by reference and hence this could be a bit surprising to beginners. Struct hell: This is more of a nitpick. Structs are what you would use to create data structures in Go. It might look like an object but they are not exactly objects. While structs are fine functionally, in many cases you will end up with structs that look like the ugly brother of JSON. In real-world projects, you always will end up creating complex structs, especially if the application is doing some generic json or yaml parsing and soon your code will start to look like this. This is not that big of a concern but it just hurts my eyes every time I debug something or write tests. 123456789101112131415161718192021222324252627282930313233343536373839	func main() {	type MyYamlDoc struct {		foo []map[interface{}][]map[interface{}]interface{}		bar interface{}	}	ohno := MyYamlDoc{		[]map[interface{}][]map[interface{}]interface{}{			{				 Foo : {					{ Bar : map[interface{}][]map[interface{}]interface{}{						 Foo : {							{ Bar : map[interface{}][]map[interface{}]interface{}{								 Foo : {									{ Bar : map[interface{}][]map[interface{}]interface{}{										 Foo : {											{ Bar : map[interface{}][]map[interface{}]interface{}{}},										},									}},								},							}},						},					}},				},			},			map[interface{}][]map[interface{}]interface{}{				 Foo : {					{ Bar : map[interface{}][]map[interface{}]interface{}{}},				},			},		},		map[interface{}][]map[interface{}]interface{}{			 Foo : {				{ Bar : map[interface{}][]map[interface{}]interface{}{}},			},		},	}	fmt. Println(ohno)}Weird interface construct: The interface concept in Go is weird. These are the only implicit construct in Go. If you come from other languages that have interfaces then this will feel weird. The fact that they are implicit means its really easy to mess things up. Refactoring is messy unless you have a smart IDE, and you can accidentally implement someone‚Äôs interface by just naming your method a certain way. While implicit interfaces certainly help with polymorphism and decoupling code I personally would still prefer interfaces that are explicit. Another interface Gotcha is nil value checks, in Go, an interface is made up of two parts a type and a value, so an interface is nil only when both type and value are nil, this means you can‚Äôt just simply do nil checks on interfaces. This is so confusing the Go has a specific FAQ for this. Below article explains this in more detail         https://dev. to/pauljlucas/go-tcha-when-nil--nil-hic      Single GC algorithm: Go implements a concurrent tri-color mark-sweep collector as its garbage collector. This specific GC implementation is optimized for better pause times while ignoring program throughput, pause frequency and many other parameters that are considered during GC. Some people in the Go community claims this as the best ever GC. Having some Java background I would have to disagree as most JVM implementations provide multiple GC algorithms you can choose from which includes a concurrent mark-sweep collector as well and most of these are balanced to take care of many more parameters than just pause times. This articles analyses this in detail. So some use cases that produce a high amount of garbage might actually be slower in Go compared to another language due to frequent GC. Developer experience: This is purely based on personal experience and hence will vary from others. Being a polyglot developer who has worked with many languages, the developer experience from Go is not the best I have experienced. The DX of the JavaScript ecosystem is the best I have experienced so far. It feels like there are things missing in the Go ecosystem. Dependency management and toolchains need improvement. A bit more sensible language features and some syntax sugar wouldn‚Äôt hurt as well. Conclusion: Having worked with many major languages I can‚Äôt just use Go for every use case but I can see why people would use Go for every use-case out there if they haven‚Äôt worked with other languages. So where would I use Go?:  I would definitely use Go when the use case requires a lot of parallel processing and/or concurrency(both are not the same thing but are closer to each other) as you can make use of Goroutines for this and is much simpler and efficient than managing threads like in a Java application or working around it in JavaScript using callback hell since JS is actually single-threaded. Here is a nice article explaining the advantage of Goroutines.  Simple microservices where boilerplate is not a concern Networking applications or web servers, especially with async workloads, can greatly benefit from Go. But to be fair you can do these in Java, Python, JS, etc as well but Go in the end will provide better efficiency and would be easier to implement.  System programming. While Rust or C is a much better choice for this but if those are not in your arsenal then Go is the next best thing. With decent support for pointers and its standard library its easier for system programs than other mainstream languages. Many popular system tools like Docker, Kubernetes, etc are indeed written in Go. Where I wouldn‚Äôt use Go?:  Complex web application: I would choose Java with a framework like Spring or Micronaut as its much more maintainable and battle-tested and you would focus more on business logic than writing boilerplate infrastructure code. One common argument against this stack is its memory footprint but it is possible to get lower memory footprint with Spring and frameworks like Micronaut and Quarkus actually promises that OOB.  After writing a high-level CLI tool in Go, I hate the experience, I kept thinking that doing it in JavaScript would have been 10 times more productive and a nicer experience. SO I would choose JavaScript or TypeScript running on NodeJS for CLI tool any day. Mainly due to the ecosystem and the sheer joy and speed of getting things done without spending all your time writing boilerplate code. But this wouldn‚Äôt be applicable if the CLI in question a system tool or a networking tool, in those cases Go could be a good option. I do hope Go evolves into a general-purpose language over time and many of these concerns are solved. In the meantime, I‚Äôll try to follow this mantra. Remember this manthra &quot;right tools for the right job, right pattern for the use-case&quot; #engineering #development #architecture #microservices https://t. co/SA42jQ5TLH &mdash; Deepu K Sasidharan ( ‡¥¶‡µÄ‡¥™‡µÅ, ‡Æ§‡ØÄ‡Æ™‡ØÅ, ‡§¶‡•Ä‡§™‡•Ç ) (@deepu105) July 2, 2019But then you can always choose to fasten a screw using a hammer. Using the wrong tool for the job. #programming pic. twitter. com/5RdVqGuZoj &mdash; Rory Preddyü•ë (@rorypreddy) June 24, 2019If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. Cover image credit: Image from Gophercises created by @joncalhoun, Marcus Olsson (@marcusolsson), and Jon Calhoun. Also published on Dev. to "
    }, {
    "id": 30,
    "url": "/configure-a-beautiful-terminal-on-unix/",
    "title": "Configure a beautiful terminal on Unix with Zsh",
    "body": "2019/07/01 - Please follow me on Twitter for updates. I was a long-time Windows user, a fairly happy one, but as a developer, there were a lot of things that were missing for me and one of the main was the terminal experience. I‚Äôm not a fan of the closed ecosystem of Apple so Linux was an easy choice for me and I switched to Linux almost 3 years ago. I did start out with Ubuntu and later switched to Fedora which is my primary OS now. You can read about my setup here As a senior developer and open source community lead, I spent a lot of time on the terminal and a terminal with a nice developer experience instantly makes you happier and more productive. The default bash terminal is good for beginners but if you really want a powerful terminal you need something more than bash. Let‚Äôs see how to configure a powerful and productive terminal experience. The setup is based on what I have configured on my Fedora machine. The same setup can be recreated on any other Linux distribution, BSD or Mac as well. You just need to use the installation instruction from the tools for the given platform.  Below are the tools we would need for this. Zsh: Zsh is one of the most feature-rich shells for Unix. It works on Linux, Mac, WSL, and BSD. There are alternatives like Fish which also offers similar features but I personally like Zsh.  Check if Zsh is already installed by running zsh --version on your terminal. If not found, install it using your package manager.      Fedora: sudo dnf install zsh   Mac: brew install zsh zsh-completions   RHEL/CentOS: sudo yum update &amp;&amp; sudo yum -y install zsh   Ubuntu/Debian: sudo apt install zsh   For other platform refer this    Now make Zsh your default shell by running chsh -s $(which zsh).  Log out and log in back again to use your new default shell.  Test that it worked with echo $SHELL. Expected result: /bin/zsh or similar.  Test with $SHELL --version. Expected result: zsh 5. 6. 2 or similarNote: If you have installed Zsh for the first time and launch the shell it would prompt you to configure some settings. You can choose to ignore that by hitting q as we will configure it later on. Oh-My-Zsh: Oh-My-Zsh gives the Zsh shell superpowers. Its a framework to manage Zsh configuration. It has plugins and themes for Zsh(A lot of them). From their Github page:  Once installed, your terminal shell will become the talk of the town or your money back! With each keystroke in your command prompt, you‚Äôll take advantage of the hundreds of powerful plugins and beautiful themes. Strangers will come up to you in caf√©s and ask you, ‚Äúthat is amazing! are you some sort of genius?‚Äù Just install it. You need it :) 1sh -c  $(curl -fsSL https://raw. githubusercontent. com/robbyrussell/oh-my-zsh/master/tools/install. sh) Terminal emulator/multiplexer: Optionally you can use a Terminal emulator that can manage windows and panes for you. For Linux I would recommend using Tilix, I have been using it for 3 years and its just amazing. For Mac, you can use iTerm2 which is very popular. Alternatively, you can also use tmux if you want something lighter on your existing Terminal app on Linux, BSD or Mac. Configuring Zsh: This is the fun part. Let us make the terminal awesome. Install plugins: First, let us install some additional plugins that are not bundled with Oh-My-Zsh. zsh-autosuggestions: Provides auto completion for shell commands. Run git clone https://github. com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/. oh-my-zsh/custom}/plugins/zsh-autosuggestions to install zsh-syntax-highlighting: Provides syntax highlighting on the shell. Run git clone https://github. com/zsh-users/zsh-syntax-highlighting. git ${ZSH_CUSTOM:-~/. oh-my-zsh/custom}/plugins/zsh-syntax-highlighting to install autojump: Provides a smarter directory navigation system. Install autojump for your OS following instructions here. Now let us configure the ~/. zshrc file with some settings. Here is my full . zshrc file. Your mileage may vary. Add exports: We will start with some exports. 1234567891011121314export TERM= xterm-256color  # This sets up colors properly# set shellexport SHELL=/usr/bin/zsh# If you come from bash you might have to change your $PATH. export NODE_PATH=$NODE_PATH:$HOME/. npm-global/lib/node_modulesexport JAVA_HOME=/usr/java/latestexport PATH=$JAVA_HOME/bin:~/. npm-global/bin:$HOME/bin:/usr/local/bin:$PATH# Add exports from your profilesource ~/. profile# Path to your oh-my-zsh installation. export ZSH=$HOME/. oh-my-zshZsh settings: Now we can configure some Zsh specific settings 1234DISABLE_MAGIC_FUNCTIONS=trueZSH_AUTOSUGGEST_MANUAL_REBIND=1COMPLETION_WAITING_DOTS=trueDISABLE_UNTRACKED_FILES_DIRTY=trueZsh theme: Now, Let‚Äôs set up a nice theme. I‚Äôm using powerlevel10k as my current theme and it‚Äôs fast and looks great. You can use the default or you can choose any theme you like from the list here. If you like my theme then follow these instructions. Thanks to Roman Perepelitsa for some cool tips Run git clone https://github. com/romkatv/powerlevel10k. git ${ZSH_CUSTOM:-~/. oh-my-zsh/custom}/themes/powerlevel10k to install the theme. Install a Powerline font. I use Adobe Source Code Pro Add the below configuration to the ~/. zshrc file. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182# Set name of the theme to load. Optionally, if you set this to  random # it'll load a random theme each time that oh-my-zsh is loaded. # See https://github. com/robbyrussell/oh-my-zsh/wiki/ThemesZSH_THEME= powerlevel10k/powerlevel10k ############ POWERLEVEL THEME SETTINGS ##############POWERLEVEL9K_MODE='awesome-fontconfig'POWERLEVEL9K_LEFT_PROMPT_ELEMENTS=(dir vcs nvm)POWERLEVEL9K_RIGHT_PROMPT_ELEMENTS=(disk_usage time)POWERLEVEL9K_PROMPT_ADD_NEWLINE=truePOWERLEVEL9K_PROMPT_ON_NEWLINE=truePOWERLEVEL9K_SHOW_RULER=truePOWERLEVEL9K_RULER_CHAR='‚îÄ'POWERLEVEL9K_RULER_BACKGROUND=nonePOWERLEVEL9K_RULER_FOREGROUND=237POWERLEVEL9K_LEFT_SEGMENT_END_SEPARATOR=POWERLEVEL9K_LEFT_SEGMENT_SEPARATOR=POWERLEVEL9K_LEFT_SUBSEGMENT_SEPARATOR=' 'POWERLEVEL9K_RIGHT_SEGMENT_END_SEPARATOR=POWERLEVEL9K_RIGHT_SEGMENT_SEPARATOR=POWERLEVEL9K_RIGHT_SUBSEGMENT_SEPARATOR=POWERLEVEL9K_WHITESPACE_BETWEEN_LEFT_SEGMENTS=POWERLEVEL9K_SHORTEN_DIR_LENGTH=2POWERLEVEL9K_SHORTEN_STRATEGY= truncate_middle POWERLEVEL9K_DIR_SHOW_WRITABLE=truePOWERLEVEL9K_DISK_USAGE_NORMAL_BACKGROUND=nonePOWERLEVEL9K_DISK_USAGE_WARNING_BACKGROUND=magentaPOWERLEVEL9K_DISK_USAGE_CRITICAL_BACKGROUND=redPOWERLEVEL9K_TIME_BACKGROUND=nonePOWERLEVEL9K_TIME_FOREGROUND=whitePOWERLEVEL9K_DIR_HOME_BACKGROUND=nonePOWERLEVEL9K_DIR_HOME_SUBFOLDER_BACKGROUND=nonePOWERLEVEL9K_DIR_ETC_BACKGROUND=nonePOWERLEVEL9K_DIR_DEFAULT_BACKGROUND=nonePOWERLEVEL9K_DIR_NOT_WRITABLE_BACKGROUND=nonePOWERLEVEL9K_DIR_HOME_FOREGROUND=bluePOWERLEVEL9K_DIR_HOME_SUBFOLDER_FOREGROUND=bluePOWERLEVEL9K_DIR_ETC_FOREGROUND=bluePOWERLEVEL9K_DIR_DEFAULT_FOREGROUND=bluePOWERLEVEL9K_DIR_NOT_WRITABLE_FOREGROUND=redPOWERLEVEL9K_OS_ICON_BACKGROUND= white POWERLEVEL9K_OS_ICON_FOREGROUND= blue POWERLEVEL9K_VCS_GIT_ICON='%fon %F{040}\uf1d3 'POWERLEVEL9K_VCS_GIT_GITHUB_ICON='%fon %F{040}\uf09b 'POWERLEVEL9K_VCS_GIT_BITBUCKET_ICON='%fon %F{040}\uf171 'POWERLEVEL9K_VCS_GIT_GIT_GITLAB_ICON='%fon %F{040}\uf296 'POWERLEVEL9K_VCS_CLEAN_BACKGROUND=nonePOWERLEVEL9K_VCS_UNTRACKED_BACKGROUND=nonePOWERLEVEL9K_VCS_MODIFIED_BACKGROUND=nonePOWERLEVEL9K_VCS_LOADING_BACKGROUND=nonePOWERLEVEL9K_VCS_CLEAN_FOREGROUND= 040 POWERLEVEL9K_VCS_UNTRACKED_FOREGROUND= red POWERLEVEL9K_VCS_MODIFIED_FOREGROUND= yellow POWERLEVEL9K_VCS_LOADING_FOREGROUND= grey POWERLEVEL9K_VCS_UNTRACKED_ICON=$'%{\b?%}'POWERLEVEL9K_VCS_UNSTAGED_ICON=$'%{\b!%}'POWERLEVEL9K_VCS_STAGED_ICON=$'%{\b+%}'POWERLEVEL9K_DIR_NOT_WRITABLE_VISUAL_IDENTIFIER_COLOR=redPOWERLEVEL9K_LOCK_ICON=$'\uf023'POWERLEVEL9K_MULTILINE_FIRST_PROMPT_PREFIX=''local p='%F{%(?. green. red)}${${${KEYMAP:-0}:#vicmd}:+‚ùØ}${${$((!${#${KEYMAP:-0}:#vicmd})):#0}:+‚ùÆ}%f 'POWERLEVEL9K_MULTILINE_LAST_PROMPT_PREFIX= $p POWERLEVEL9K_NVM_BACKGROUND=nonePOWERLEVEL9K_NVM_FOREGROUND=greenPOWERLEVEL9K_NODE_ICON='%fvia %F{green}‚¨¢'############ END- POWERLEVEL THEME SETTINGS ##############Enable plugins: We can finish off by enabling the plugins and some tweaks 1234plugins=(zsh-autosuggestions git docker docker-compose autojump zsh-syntax-highlighting dnf npm)source $ZSH/oh-my-zsh. shAnd that‚Äôs it we are ready. Start a new terminal session and enjoy. Issues &amp; workarounds: If you use Tilix as your terminal emulator, then this might be required for proper pane splitting. Add this to your ~/. zshrc 123if [[ $TILIX_ID ]]; then    source /etc/profile. d/vte. shfiIf you are getting errors from the zsh-completion plugin, you might want to add this to the beginning of your ~/. zshrc 1234# workaround as per https://superuser. com/questions/1222867/zsh-completion-functions-brokenFPATH=$HOME/. oh-my-zsh/plugins/git:$HOME/. oh-my-zsh/functions:$HOME/. oh-my-zsh/completions:/usr/share/zsh/site-functions:/usr/share/zsh/$ZSH_VERSION/functionsexport FPATHIf you encounter an error from Oh-My-Zsh saying [oh-my-zsh] Insecure completion-dependent directories detected, set ZSH_DISABLE_COMPFIX=true right before the line source $ZSH/oh-my-zsh. sh in your ~/. zshrc file and restart your session or run exec zsh Dockerized playground. : If you have Docker installed then you can use the below snippet to try this setup in a sandbox without installing anything or affecting your existing setup. 123456789docker run -e LANG=C. UTF-8 -e LC_ALL=C. UTF-8 -e TERM=$TERM -it --rm ubuntu bash -uexc ' apt update &amp;&amp; apt install -y git curl zsh autojump &amp;&amp; cd /root sh -c  $(curl -fsSL https://raw. githubusercontent. com/robbyrussell/oh-my-zsh/master/tools/install. sh)  --skip-chsh --unattended git clone https://github. com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/. oh-my-zsh/custom}/plugins/zsh-autosuggestions git clone https://github. com/zsh-users/zsh-syntax-highlighting. git ${ZSH_CUSTOM:-~/. oh-my-zsh/custom}/plugins/zsh-syntax-highlighting git clone https://github. com/romkatv/powerlevel10k. git ${ZSH_CUSTOM:-~/. oh-my-zsh/custom}/themes/powerlevel10k curl -fsSLO http://bit. ly/Spaceship10kTheme echo  source ~/Spaceship10kTheme  &gt;~/. zshrc exec zsh'VSCode Tip: If you are using VSCode like me, you might want to do the below to get the same terminal experience in the integrated VSCode terminal as well.  Follow these steps  Download and install a patched font.  On Linux, run fc-cache -f -v to refresh font cache.  On VSCode, open Preferences ‚Üí Settings and click on the {} icon to open JSON mode and set the below  123456  terminal. integrated. shell. linux :  /usr/bin/zsh ,  terminal. integrated. fontFamily :  'SauceCodePro Nerd Font Mono','Source Code Pro' ,  terminal. integrated. rightClickCopyPaste : true,  terminal. integrated. fontSize : 14,  terminal. integrated. cursorStyle :  underline ,  terminal. integrated. cursorBlinking : true    Replace linux with osx if you are on a Mac.  I hope you like it. If you have any questions or if you think I missed something please add a comment. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. Also published on Dev. to "
    }, {
    "id": 31,
    "url": "/must-have-gnome-plugins/",
    "title": "Must have GNOME extensions",
    "body": "2019/06/24 - I‚Äôm a sucker for nice polished UI and great UX. While there are a lot of Linux Desktop environments out there providing great UX and UI, I found GNOME to be the perfect one for my liking. Yes, I have seen/tried a few others. I also found some which are more polished and providing a better default UX out of the box than GNOME like Deepin and Elementary. But below plugins bridge that gap and hence I choose to stick with GNOME which is the default in Fedora, hence quite stable, unless I had a compelling reason to switch. So if you like me are a GNOME fan then below are some of the GNOME plugins you must try if you haven‚Äôt already. I have listed the plugins I use in my earlier post in the series. here I detail the ones that are a must-have. GNOME Tweaks: This nifty tool lets you tweak/configure a lot of GNOME configuration and should have been included by default in every distro shipping with GNOME. You can customize the appearance, install extensions, configure mouse &amp; keyboard and so on. It can be found in the software center of your distro. Search for ‚ÄúTweaks‚Äù.  Gnome extensions: You can install below extensions by visiting the link in the title of the extension below and by clicking on the on switch on the top right corner. On Chrome, you would need the GNOME Shell integration plugin to enable the switch. On Firefox, it will prompt you to install the plugin if it doesn‚Äôt exist. Dash to Dock: GNOME without this plugin almost feels annoying. IMO this plugin also should be the default GNOME setting. This one moves your GNOME dash into a highly configurable dock which can be placed on the sides or top/bottom of the screen. I find it perfect on the left side of the screen in GNOME. It can be a floating dock or fixed to look like those on Mint or KDE.  Always Zoom Workspaces: By default, the GNOME launcher does not show the workspaces, you have to hover over the right edge to see it. I find it unnecessary given you have enough real estate on the full-screen launcher and the workspace view takes only a little bit. This plugin keeps it zoomed by default.  Steal My Focus/NoAnnoyance: This is another default in GNOME that is annoying. When something needs focus these plugins brings the window up instead of the default notification. You can use any one of the plugins as both do the same thing. AlternateTab: This replaces the default Alt+Tab with a more classical window-based switcher which IMO is more user-friendly as the default requires more keyboard navigation using the arrow keys.  Window List: This is a classic plugin that adds the window list to the bottom of the screen and is a must if you use multiple monitors as the windows are grouped and placed in the right monitor screen. Caffeine: This one adds the ability to temporarily disable screensaver/auto-suspend and automatically activates when you go full-screen. A must-have if you are using your computer for watching videos, presentations, screencast and so on. Clipboard Indicator: This is one my favorite. It adds a nifty clipboard manager to the top bar and provides shortcuts to cycle through clipboard entries. A real time saver.  Gistnotes: As a developer using GitHub gist a lot, this one is a very useful plugin. It lets you manage your Gists right from the desktop and you can use it like a notes app.  System-monitor: A nice system monitor plugin that sits on the top bar with a detailed view as a popup.  TopIcons Plus: This moves legacy icons form applications to the top bar for consistent UX. I hope you find this useful. If you have any question or if you think I missed something please add a comment. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. Cover image photo by Brigitta Schneiter on Unsplash Also published on Dev. to "
    }, {
    "id": 32,
    "url": "/my-beautiful-linux-development-environment/",
    "title": "My beautiful Linux development environment",
    "body": "2019/06/16 - Please follow me on Twitter for updates. One of the questions that I get quite often after a conference talk is weirdly not about what I presented but about my Linux desktop environment. People are more curious about that beautiful distro rather than the awesome presentation I just did üòÇ Not that I‚Äôm complaining, I love my desktop setup. I love it so much that I was afraid of getting a new PC when I was due for one. I was afraid that I would mess things up(I have done that many times in the past, I think Linux users can relate to me) So I decided to capture the most important aspects of my distro for anyone interested in using Linux as their primary OS for development.  This is not just my work laptop, it‚Äôs my primary machine which I use for all of the below  Java, JS, TS, Go, Python &amp; web development JHipster development Running multiple web applications locally Running Docker containers VirtualBox for Windows testing &amp; other VM stuff Kubernetes, Terraform, CloudFormation development and deployments Azure, AWS &amp; GCP deployments using required CLI tools Heavy browser usage Email, chat &amp; video conferencing Plex media server Blogging Youtube &amp; Social mediaMachine configuration: The configuration of the machine is also quite important for any development setup. So my laptop is a Dell Precision 5530 Mobile Workstation. I had the exact same setup with my old Dell 5510 as well, which is quite a similar configuration to 5530. I still have it as a backup Laptop, its 2 years old now but can still give most of the top-end laptops today a run for its money. I used the custom configuration option from Dell to get the best possible setup at that time. it‚Äôs not cheap but my company, XebiaLabs, provided a handsome budget and I think it is worth every penny. This, in my opinion, is one of the best Laptops for developers. So here is what I have. Processor: Intel¬Æ Core‚Ñ¢ i9-8950HK CPU @ 2. 90GHz √ó 12 Memory: 32GB, DDR4-2666MHz SDRAM, 2 DIMMS, Non-ECC HDD: M. 2 1TB NVMe PCIe SED class 40 SSD Graphics: NVIDIA Quadro P2000 with 4 GB GDDR5 memory &amp; Intel¬Æ UHD Graphics 630 (Coffeelake 3x8 GT2) Wireless: Intel Wifi Link 9260 2x2 802. 11AC + BT 4. 2 vPro wireless card Keyboard: English QWERTY US, backlit Display: 15. 6‚Äù FHD 1920x1080 Anti-Glare LED-backlit Non-touch IPS UltraSharp‚Ñ¢ Battery: 6-cell (97Wh) Lithium-Ion battery with ExpressCharge‚Ñ¢ Operating system and desktop environment: The most important of course is the operating system, I‚Äôm running Fedora 30 at the moment with GNOME 3. 32. 2 as the Desktop and I‚Äôm very happy with it. I find Fedora more suitable for development machines than other distros as it has a short release cycle and is fairly stable so you get the latest &amp; stable software all the time.  What good is a desktop without a nice theme right? GNOME is great when it comes to themes and I went with Arc-Flatabulous theme and never looked back. For icons, I use Paper as I like the material icon theme.  Of course, it won‚Äôt be complete without some nice GNOME plugins. Below are the plugins that I use.  Dash to Dock Always Zoom Workspaces Auto Move Windows Native Window Placement Launch new instance Steal My Focus AlternateTab Window List Applications Menu Caffeine Clipboard Indicator Gistnotes OpenWeather Places Status Indicator System-monitor Todo. txt TopIcons Plus User ThemesDevelopment tools: Now, these are mostly objective choices and really doesn‚Äôt matter as long as you are comfortable with the tools you choose. Below are my choices for some of the important categories for development. I‚Äôm not including obvious things like Vim, Git, NodeJS, Docker, Kubernetes, etc. Shell: This is one of the most important for a developer. I use ZSH along with the awesome Oh My ZSH as my shell. Now, this won‚Äôt be complete without some nice plugins and themes. I use powerlevel9k theme with some customizations. I also use zsh-autosuggestions, git, docker, docker-compose, autojump, zsh-syntax-highlighting, dnf, and npm plugins for Oh My ZSH. Here is my . zshrc with all the customizations. Update: A comment on this post suggested powerlevel10k as an alternative theme and I tried it and turns out it is really way faster than powerlevel9k. So I think I‚Äôm gonna use powerlevel10k as my shell theme. Terminal: What good is a nice shell without a good terminal. Fortunately, we have Tilix one of the best terminal applications out there. It has workspaces, tabs, split windows, Quake mode and so on.  Integrated development environment(IDE): IntelliJ IDEA ultimate - I use this only for Java &amp; other JVM language Development Code Editors: Visual Studio Code - My go-to editor. I love it. I use VSCode for web development, Go, Python, JS development, DevOps and everything other than JVM languages. A VSCode setup is never complete without some good plugins. Here are the plugins that I‚Äôm using. You can run the script to install those. Other notable development tools I use are GitKraken for Git repo management, Beyond Compare for code comparisons, VirtualBox, NVM for NodeJS version management and SDKMan for JDK version management. Productivity tools: Productivity tools are also quite important and below are my choices. Browser: Google Chrome is my primary browser. I also use Firefox &amp; Opera sometimes. I do love Opera in terms of its UX, I would love to use it as my primary browser but I miss everything I have synchronized with my Google account in Chrome. Email: I use Mailspring as my e-mail client. Its a fairly decent mail client with nice themes and a simple UI. Office suite: I mostly use Google Docs &amp; Microsoft office online but when I have to work on something on my Desktop I use LibreOffice which is a good office suite and even handles Microsoft Office &amp; Keynote formats. Communication: Of course I use Slack and for video conference I use BlueJeans. Screen capture: I use this nifty tool called Peek for screen recording and Shutter for screenshots. Conclusion: There are many other small and nifty utilities that I use, most are command-line utilities. There are some notable mentions like Timeshift which is nice for backing up your machine. Of course, not everything is perfect in the Linux world, but it is the same with every OS. I was a long-time Windows user before switching to Linux. So like every Linux user I have from time to time messed things up(With great power comes great responsibility, Peter). There are many quirks in the Linux world but there is nothing that bothers me much. Some of the most annoying issues I had in the past are below and for now, I don‚Äôt have any noticeable issues.  Scroll position jumping when switching apps - Fixed after upgrading to Fedora 30 Hibernation was broken - Fixed after upgrading to Fedora 30 Audio output selection was broken when plugging in headphones- Fixed after Fedora 28 for meThis has been a good day, upgraded to #Fedora 30 and hibernate started to work again. Sweet. I was putting off tinkering that for a long time. #Linux &mdash; Deepu K Sasidharan ( ‡¥¶‡µÄ‡¥™‡µÅ, ‡Æ§‡ØÄ‡Æ™‡ØÅ, ‡§¶‡•Ä‡§™‡•Ç ) (@deepu105) June 14, 2019I hope you find this useful. If you have any questions or if you think I missed something please add a comment. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. Also published on Dev. to "
    }, {
    "id": 33,
    "url": "/why-im-moving-away-from-medium/",
    "title": "Why I‚Äôm moving away from Medium",
    "body": "2019/06/13 - After much deliberation, I have decided to move my blogs away from Medium. I was considering setting up my own blog with Hugo but then decided to go with Dev. to. Below are the reasons why I decided to leave Medium and why I chose Dev. to. All considerations were purely from a technical writing perspective as I was using Medium for publishing technical content. The love-hate relationship with Medium: I loved Medium when I started writing here, reasons being;    A simple minimal &amp; clean UI ‚Äî It still is one of the best     Ease of authoring and publishing     Community and visibility     Publications     Ease of customization  But there were also things I didn‚Äôt like much which slowly become quite annoying  The weird commenting mechanism(Every comment is a post, and they literally mess up your stories listing page)    Medium had a weird WYSIWYG editor interface which is great for normal content creation but not so great for technical content creation. It had some markdown like shortcuts, but it could never match the ease of using proper markdown editors.     Export only in HTML (Duh!!)  But these annoyances were not the main reason I decided to switch platforms. Below are the main reasons why I decided Medium isn‚Äôt a good fit for me. Medium has been aggressively pushing for content to be put behind a paywall and they have made it clear that content not opting in will not get any push inside the platform. This means the community and visibility part is applicable only if you opt-in for the paywall. I understand why Medium does and I think its a great monetary source for established authors but it doesn‚Äôt work for mere mortals like me.  As a result of the above, the traffic you get from Medium itself is very low compared to external sources. See one of my stories below for an example. For newer stories, it is even lower.  So writing in Medium seems to have no benefit over other platforms as I could get similar views from external sources and might get better writing experience elsewhere. UpdateSo after a week of moving to the Dev community below are my stats and its incredible, I have ~50k views, ~1k reactions and ~300 followers and one of my post was featured in top 7 of the week and all this in just 1 week. I didn‚Äôt get anything remotely close to this from Medium in a year.  Enter Dev. to: When I was trying to find a different platform, some of the most important aspects I considered were below    Community: A community without paywall and a community were your blogs get visibility and get traffic.     Ease of authoring: Authoring experience was important, hence at minimum Markdown support was a must. This way I can author posts in my favorite IDE(VsCode in this case) and doesn‚Äôt have to be restricted with the platform‚Äôs capability. Also, this ensures that I can easily move my posts to another platform in the future if needed.  Dev. to satisfied these needs and provided a nice and clean UI and descent publishing experience on top. Conclusion: I think Medium is still perfect for normal blogging and for content creators who have subscribers willing to pay even if they put articles behind a paywall. But for technical content creators who do not want their content behind a paywall, there are better platforms. I might still crosspost between Dev. to and Medium from time to time but Dev. to will be my primary blogging platform. Originally published in Medium on June 13, 2019 Cover image credit: Photo by MILKOV√ç on Unsplash Also published on Dev. to "
    }, {
    "id": 34,
    "url": "/deploy-a-web-app-to-azure-app-service-using-terraform/",
    "title": "Deploy a web app to Azure App Service using Terraform",
    "body": "2019/06/12 - Deploying Java web applications to Azure is easy and has been tried, tested and explained many times by many people. My friend Julien Dubois has a nice series on it here. Azure makes it really easy to use its App Service as it provides many different ways of deploying a web app. If you are a modern full-stack Java developer there is a high chance that you are deploying your application as a Docker image. Hence today let‚Äôs see how we can deploy a Java web application to Azure App Service using Docker and Terraform in the true spirit of infrastructure as code. The approach is pretty much the same for any web application that is built as a docker image and not necessarily tied down to just Java. To try this out you would need to have Java, NodeJS, Terraform, Docker and Azure CLI installed. Follow the links to install them if needed. As one of the lead developer of JHipster (A handy development platform to generate, develop and deploy Spring Boot + Angular/React/Vue Web applications and Spring microservices), I would use a JHipster web application as the example here. So let‚Äôs get started. Let‚Äôs build a very simple web application using JHipster. We will use the JDL feature to scaffold our application. We will use the below JDL for our application. Save it to a file named app. jdl in a directory where you want to create the application. application {  config {    baseName helloJHipster,    applicationType monolith,    packageName tech. jhipster. demo,    authenticationType jwt,    buildTool gradle,    clientFramework react,    databaseType sql,    prodDatabaseType mysql,    languages [en, nl]  }}Now let us scaffold this using JHipster. Open your favorite console/terminal and run the below command in the directory where you saved the above JDL file, make sure it‚Äôs an empty directory. 1$ npx generator-jhipster import-jdl app. jdlIf you already have JHipster installed you can just run 1$ jhipster import-jdl app. jdlThis will scaffold the application and install the required client-side dependencies. It might take a few minutes(NPM!) so maybe its time for that coffee. You can see the application in action by running . /gradlew on the same terminal once the scaffolding is done. You can refer to the generated Readme. md for more instructions regarding the application. Now let‚Äôs move on to the focus of this post, deploying this to Azure App Service with Terraform. Let us first build and publish the docker image for our application. JHipster conveniently provides everything that is required to build docker images. Let us use the provided docker integration using JIB to build the images. Run the below Gradle command. 1$ . /gradlew bootJar -Pprod jibDockerBuildNow let us tag and push this to our docker registry, make sure you have logged into docker and run these commands. Use your own docker hub account name. 123$ docker tag hellojhipster:latest deepu105/hellojhipster:latest$ docker push deepu105/hellojhipster:latestYou can also push to Azure Container registry instead of Docker Hub if you like. Now that our application and Docker images are ready, let‚Äôs prepare the Terraform infrastructure for App Service and MySQL database. For other ways of deploying a JHipster web app to Azure check this out. First, create a folder for our terraform files. Let‚Äôs name the folder terraform. Now create three files called main. tf, outputs. tf, and variables. tf in this folder. Let us define the variables we will use. Save the below in variables. tf. 12345678910111213141516171819202122232425variable  prefix  { description =  The prefix used for all resources in this example  default   =  xl }variable  location  { description =  The Azure location where all resources in this example should be created }variable  subscription_id  { description =  Azure Subscription ID to be used for billing }variable  my_sql_master_password  { description =  MySql master password }variable  docker_image  { description =  Docker image name }variable  docker_image_tag  { description =  Docker image tag }Now let us define our main. tf First, let us add a configuration for Azure resource manager and create an Azure resource group to hold our resources. 123456789provider  azurerm  { version     =  =1. 24. 0  subscription_id =  ${var. subscription_id} }resource  azurerm_resource_group   main  { name   =  ${var. prefix}-resources  location =  ${var. location} }Now let us add the configuration to create a MySQL database server along with the required firewall rules to let App Service access the DB. If you want to add local access from your machine add a firewall rule block for your IP as well. 12345678910111213141516171819202122232425262728293031323334353637383940414243# This creates a MySQL serverresource  azurerm_mysql_server   main  { name        =  ${var. prefix}-mysql-server  location      =  ${azurerm_resource_group. main. location}  resource_group_name =  ${azurerm_resource_group. main. name}  sku {  name   =  B_Gen5_2   capacity = 2  tier   =  Basic   family  =  Gen5  } storage_profile {  storage_mb      = 5120  backup_retention_days = 7  geo_redundant_backup =  Disabled  } administrator_login     =  mysqladminun  administrator_login_password =  ${var. my_sql_master_password}  version           =  5. 7  ssl_enforcement       =  Disabled }# This is the database that our application will useresource  azurerm_mysql_database   main  { name        =  ${var. prefix}_mysql_db  resource_group_name =  ${azurerm_resource_group. main. name}  server_name     =  ${azurerm_mysql_server. main. name}  charset       =  utf8  collation      =  utf8_unicode_ci }# This rule is to enable the 'Allow access to Azure services' checkboxresource  azurerm_mysql_firewall_rule   main  { name        =  ${var. prefix}-mysql-firewall  resource_group_name =  ${azurerm_resource_group. main. name}  server_name     =  ${azurerm_mysql_server. main. name}  start_ip_address  =  0. 0. 0. 0  end_ip_address   =  0. 0. 0. 0 }This will create a MySQL server, a database for our app on the server and enable access from App Service. Now let us configure the App Service itself along with a service plan. 123456789101112131415161718192021222324252627282930313233343536373839# This creates the plan that the service useresource  azurerm_app_service_plan   main  { name        =  ${var. prefix}-asp  location      =  ${azurerm_resource_group. main. location}  resource_group_name =  ${azurerm_resource_group. main. name}  kind        =  Linux  reserved      = true sku {  tier =  Standard   size =  S1  }}# This creates the service definitionresource  azurerm_app_service   main  { name        =  ${var. prefix}-appservice  location      =  ${azurerm_resource_group. main. location}  resource_group_name =  ${azurerm_resource_group. main. name}  app_service_plan_id =  ${azurerm_app_service_plan. main. id}  site_config {  app_command_line =     linux_fx_version =  DOCKER|${var. docker_image}:${var. docker_image_tag}   always_on    = true } app_settings = {   WEBSITES_ENABLE_APP_SERVICE_STORAGE  =  false    DOCKER_REGISTRY_SERVER_URL      =  https://index. docker. io   # These are app specific environment variables   SPRING_PROFILES_ACTIVE    =  prod,swagger    SPRING_DATASOURCE_URL    =  jdbc:mysql://${azurerm_mysql_server. main. fqdn}:3306/${azurerm_mysql_database. main. name}?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false&amp;useLegacyDatetimeCode=false&amp;serverTimezone=UTC    SPRING_DATASOURCE_USERNAME  =  ${azurerm_mysql_server. main. administrator_login}@${azurerm_mysql_server. main. name}    SPRING_DATASOURCE_PASSWORD  =  ${var. my_sql_master_password}  }}In this configuration, under site_config we use linux_fx_version to declare our docker image and set always_on to true so that the application is not shut down when there is inactivity for some time. In the app_settings section we need to disable storage using the flag WEBSITES_ENABLE_APP_SERVICE_STORAGE and also specify DOCKER_REGISTRY_SERVER_URL. Everything else is specific to our app. The flags passed to the MySQL connection URL is important. Now that our main. tf is ready let us define some output properties that are handy. In the outputs. tf file add the below 1234567output  app_service_name  { value =  ${azurerm_app_service. main. name} }output  app_service_default_hostname  { value =  https://${azurerm_app_service. main. default_site_hostname} }Now we are ready to rock and roll! let us deploy the app. Make sure you have set up your Azure CLI and have logged in using az login. Now in a terminal/console navigate to the terraform folder we created and execute these commands. Please change the values for prefix, location &amp; docker_image accordingly. 1234567$ terraform init$ terraform apply \-var prefix=myAwesomeApp \-var location=northeurope \-var docker_image=deepu105/hellojhipster \-var docker_image_tag=latestThis will prompt you to enter a master password for MySQL server and your Azure subscription ID(You can find this from Azure portal or by running az account list- the id field is the subscription ID). Once you provide the values and confirm, Terraform will get to work and will start creating the resources. this could take a while since we are provisioning a Database server. Wait for it or go have that second coffee ;) Once the deployment is complete, Terraform will print out the outputs which include the app_service_default_hostname. Copy the URL and open it in your favorite browser. The first time could take a while since the app will be started(cold start) only during the first request.  I hope you found this useful. This is my first post in dev. to, I hope to migrate my blogs from Medium to dev. to soon. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. My other related posts:  Create full Microservice stack using JHipster Domain Language under 30 minutes Deploying JHipster Microservices on Azure Kubernetes Service (AKS) How to set up JHipster microservices with Istio service mesh on Kubernetes Continuous delivery of Microservices with XebiaLabs‚Ää‚Äî‚Ääa. k. a DevOps as CodeAlso published on Dev. to "
    }, {
    "id": 35,
    "url": "/react-done-right-with-typescript/",
    "title": "React components done right with TypeScript mapped and conditional types",
    "body": "2018/11/19 - You‚Äôve probably heard about TypeScript, If not you should check it out. You may have heard someone claiming how great type safety is. TypeScript is great. As someone who hates to transpile his code, I would definitely do it with TypeScript if I had to. So much has been said about TypeScript, and there isn‚Äôt really anything new that I can add. But I do believe that type safety is not all about making your code ugly with type definitions everywhere. So how can we write type-safe code without having to litter type declarations everywhere? Type inference and advanced features like derived and dynamic types are the answer. Editors and IDEs we use are smart enough to handle code with inferred type gracefully without us having to see the types all the time visually. (Of course, they all usually show you the type when you hover over an inferred type. ) TypeScript has very good type inference. As a rule of thumb, you can always start without declaring the type for any variable and see if the compiler infers it. With modern editors like VSCode, you can see this immediately. So set your tsconfig to the strict mode. Then start declaring types when the compiler complains. Additionally, TypeScript 2. 1 and 2. 8 introduced a bunch of cool lookup types. Now you can dynamically infer types using different techniques like Intersection types, Union types, Index types, mapped types and conditional types. Index types: Index types enable us to check properties and types of an interface or type dynamically using the keyof T (index type query operator) and T[K] (indexed access operator). Let‚Äôs take the below interface for example. 123456interface Person {  name: string;  age: number;  address: string;  sayHi: (msg: string) =&gt; string;}The keyof T operator gets a union type of all the key names of the type T and hence keyof Person will give us 'name' | 'age' | 'address' | sayHi' as result. The T[K] operator gets the type for the provided key. Person['name'] will result in string and Person[*keyof* Person] will result in string | number | ((msg: string) =&gt; string). Mapped types: Let us see what mapped types are. Let us say we have the below interface for a Person. 123456interface Person {  name: string;  age: number;  address: string;  sayHi: (msg: string) =&gt; string;}Now in every project, it is almost always a common requirement to have variations of a certain interface. For example, let‚Äôs say we need a read-only version of the person as below. 123456interface ReadonlyPerson {  readonly name: string;  readonly age: number;  readonly address: string;  readonly sayHi: (msg: string) =&gt; string;}In this case, we would have to replicate the Person interface and we have to keep them in sync manually. This is where mapped types will come in handy, so let us use the builtin mapped type, Readonly, for this. 1type ReadonlyPerson = Readonly&lt;Person&gt;;If you hover over the ReadonlyPerson type you can see the inferred type as below. Inferred type view in VsCode That is cool, right? Now we can create types from existing types and don‚Äôt have to worry about keeping them in sync. How does it work, what does Readonly&lt;Person&gt; do? Let‚Äôs take a look at the mapped type. 123type Readonly&lt;T&gt; = {  readonly [K in keyof T]: T[K];};The in operator from TypeScript does the trick here. It maps all the declarations of the existing type into the new type. The keyof operator provides the keys from our type for the mapping. Let us build our own mapped type. Let us say we need a read-only Person interface where all the fields are nullable as well. We can build a mapped type as below for that. 123type ReadonlyNullablePerson = {  readonly [P in keyof Person]: Person[P] | null;};And it is inferred as below Let‚Äôs make it generic so that it can be used with any interface. 12345type ReadonlyNullable&lt;T&gt; = {  readonly [K in keyof T]: T[K] | null;};type ReadonlyNullablePerson = ReadonlyNullable&lt;Person&gt;;TypeScript includes Readonly&lt;T&gt;, Partial&lt;T&gt;, Pick&lt;T, K extends keyof T&gt; and Record&lt;K extends string, T&gt; as built-in mapped types. Pick and Record can be used as below, check them in your editor to see what types they produce. 123type PersonMinimal = Pick&lt;Person,  name  |  age &gt;;type RecordedPerson = Record&lt; name  |  address , string&gt;;For every other use case, you can build your own mapped types. Conditional types:  A conditional type selects one of two possible types based on a condition expressed as a type relationship test. Let us look at an example. 1234567type Foo&lt;T, U&gt; = T extends U ? string : boolean;interface Me {}interface You extends Person {}type FooBool = Foo&lt;Me, Person&gt;; // will result in booleantype FooString = Foo&lt;You, Person&gt;; // will result in stringThe type dynamically inferred from Foo&lt;T, U&gt; will be either string or boolean depending on what the first generic is extended from. Let us see how we can mix conditional types with mapped types to infer a new type from Person which only includes the non-function properties. 123456789101112131415type NonFunctionPropNames&lt;T&gt; = {  [K in keyof T]: T[K] extends Function ? never : K;}[keyof T];type NonFunctionProps&lt;T&gt; = Pick&lt;T, NonFunctionPropNames&lt;T&gt;&gt;;type PersonProps = NonFunctionProps&lt;Person&gt;;/* Produces the below type  type PersonProps = {    name: string;    age: number;    address: string;  }  */We first get all the non-function property names from the interface. Then use the Pick mapped type to pick those from the interface to form the new interface. TypeScript provides the following inbuilt conditional types:    Exclude&lt;T, U&gt; ‚Äì Exclude from T those types that are assignable to U.     Extract&lt;T, U&gt; ‚Äì Extract from T those types that are assignable to U.     NonNullable&lt;T&gt; ‚Äì Exclude null and undefined from T.     ReturnType&lt;T&gt; ‚Äì Obtain the return type of a function type.     InstanceType&lt;T&gt; ‚Äì Obtain the instance type of a constructor function type.  Let us put it into use: These advanced types become even more powerful when you combine them together. Let‚Äôs see some practical uses of this in React. React component and Redux reducer in ES6: Let see a simple React component with a reducer written in ES6. Take a look at index. jsx in the below code sandbox:                         As you can see, we use the prop-types library to define the component props. It is not the most efficient way, as it includes considerable overhead during development. It doesn‚Äôt provide full type safety anyway. React component and Redux reducer in TypeScript: Now let us convert this simple example to TypeScript so that it is type safe. Take a look at index. tsx in the below code sandbox:                         As you can see, the code is more type-safe now. It is also much more verbose even without PropTypes library and all the type inference. React component and Redux reducer in TypeScript with advanced types: Now let us apply the advanced types that we learned to make this example less verbose and even more type safe. Take a look at index. tsx in the below code sandbox:                         As you can see, we used Readonly and ReturnType mapping along with some other type inference techniques to write a more type-safe but less verbose version of the component. Conclusion: If you are using React with TypeScript, then these are some of the techniques you must apply. If you are considering a type system for React, then look no further than TypeScript. It has great features, great tooling, excellent IDE/Editor support and an awesome community. I gave a talk on TypeScript for Devoxx 2018, and you can see the video and slides if you like here.                                                                         Check out my book ‚ÄúFull Stack Development with JHipster‚Äù on Amazon and Packt if you like to learn about Full stack development with an awesome stack that includes TypeScript and React. If you like JHipster don‚Äôt forget to give it a star on Github. If you like this article, please like or comment. You can follow me on Twitter and LinkedIn. Originally published in Medium on November 19, 2018 Also published on Dev. to "
    }, {
    "id": 36,
    "url": "/deploying-jhipster-microservices-on-azure-kubernetes-service-aks/",
    "title": "Deploying JHipster Microservices on Azure Kubernetes Service (AKS)",
    "body": "2018/10/01 - If you are developing and deploying applications to production, especially cloud, you would have heard about Kubernetes. Kubernetes(k8s) is a container orchestration platform originally developed by Google and makes deploying containerized/dockerized applications to production more manageable and scalable. Kubernetes has been crowned as the undeniable champion of container orchestration for a while now and every other K*S offering that we see sprouting up are testimonials for that. The K obviously stands for Kubernetes and S/E stands for Service/Engine and the first letter stands for the product offering it. So far we have AKS(Azure), GKE(Google), and EKS(Amazon ECS) and PKS(Pivotal) and also some flavors from Oracle and RedHat(read Openshift) One of my colleagues have written a nice article about it, I highly recommend you read it as well. In this article, we will see how we can deploy a microservice architecture created by JHipster to Azure Kubernetes Service. Azure Kubernetes Service(AKS) is the managed Kubernetes platform offering from Microsoft to host your containerized applications. Creating the microservice application: In one of my previous posts, I showcased how to create a full stack microservice architecture using JHipster and JDL, read the post here if you want to learn more details about it. For this exercise, we will use the same application. Let us recap the steps required. Create a JDL file, let‚Äôs say app. jdl, and copy the below content into it. 400: Invalid requestNow create a directory called ecommerce and navigate into it. Run the JHipster import-jdl command. It could take a few minutes, especially the NPM install step. 12$ mkdir ecommerce &amp;&amp; cd ecommerce$ jhipster import-jdl app. jdlOnce the JHipster process is complete, you will see that we have our store gateway, invoice service and notification service created and ready for us. The process until this is explained in more detail in my previous post here and you can deploy the application locally using Docker as explained in that post. If you haven‚Äôt done that before I strongly suggest that step so that you get an idea of the application and you also can make sure it works locally on your machine. Generating the Kubernetes configuration: Now that our application is ready, let us create the required configurations for Kubernetes using JHipster. This can also be done using JDL by adding below snippet to the JDL file we used earlier. 123456789deployment { deploymentType kubernetes appsFolders [store, invoice, notification] serviceDiscoveryType eureka dockerRepositoryName  deepu105  // use your own docker repo username here kubernetesNamespace jhipster kubernetesServiceType LoadBalancer monitoring no}For now, let us use the JHipster CLI to do this. In the ecommerce folder, we created earlier, create a new directory, let‚Äôs call in k8s so that we get the below structure. 12345‚îú‚îÄ‚îÄ app. jdl‚îú‚îÄ‚îÄ invoice‚îú‚îÄ‚îÄ kubernetes‚îú‚îÄ‚îÄ notification‚îî‚îÄ‚îÄ storeCreate the kubernetes directory and navigate to it. Now run the JHipster Kubernetes command there. 12$ mkdir kubernetes &amp;&amp; cd kubernetes$ jhipster kubernetesThe generator will ask you a few questions and choose the answers as highlighted below, as you can see the questions are very similar to the ones asked by jhipster docker-compose command. For the ‚Äúbase Docker repository name‚Äù provide your own docker hub account id(For example, my Docker Hub id is deepu105). For real-world use cases, you could also use a private image repository like the Azure Container Registry and in that case, you would have to provide the ACR login server name here. For now, let us keep it simple. 12345678910111213141516171819202122232425262728‚éà Welcome to the JHipster Kubernetes Generator ‚éàFiles will be generated in folder: /home/deepu/workspace/temp/ecommerce/kubernetes‚úî Docker is installed? Which *type* of application would you like to deploy? Microservice application? Enter the root directory where your gateway(s) and microservices are located . . /3 applications found at /home/deepu/workspace/temp/ecommerce/? Which applications do you want to include in your configuration? invoice, notification, store? Do you want to setup monitoring for your applications ? No? Which applications do you want to use with clustered databases (only available with MongoDB and Couchbase)? JHipster registry detected as the service discovery and configuration provider used by your apps? Enter the admin password used to secure the JHipster Registry admin? What should we use for the Kubernetes namespace? jhipster? What should we use for the base Docker repository name? &lt;your Docker hub account id&gt;? What command should we use for push Docker image to repository? docker push? Do you want to enable Istio? No? Choose the kubernetes service type for your edge services LoadBalancer - Let a kubernetes cloud provider automatically assign an IPThe generator will go to work with this and will create the following files and output. 123456789101112131415161718192021222324252627282930313233343536373839404142  create invoice/invoice-deployment. yml  create invoice/invoice-service. yml  create invoice/invoice-mysql. yml  create notification/notification-deployment. yml  create notification/notification-service. yml  create notification/notification-mongodb. yml  create store/store-deployment. yml  create store/store-service. yml  create store/store-mysql. yml  create README. md  create registry/jhipster-registry. yml  create registry/application-configmap. yml  create kubectl-apply. shWARNING! Kubernetes configuration generated with missing images!To generate the missing Docker image(s), please run: . /gradlew -Pprod bootWar jibDockerBuild in /home/deepu/workspace/temp/ecommerce/invoice . /gradlew -Pprod bootWar jibDockerBuild in /home/deepu/workspace/temp/ecommerce/notification . /gradlew -Pprod bootWar jibDockerBuild in /home/deepu/workspace/temp/ecommerce/storeWARNING! You will need to push your image to a registry. If you have not done so, use the following commands to tag and push the images: docker image tag invoice deepu105/invoice docker push deepu105/invoice docker image tag notification deepu105/notification docker push deepu105/notification docker image tag store deepu105/store docker push deepu105/storeYou can deploy all your apps by running the following script: . /kubectl-apply. shUse these commands to find your application's IP addresses: kubectl get svc storeCongratulations, JHipster execution is complete!As you can see the generator creates all the required Kubernetes configuration files and prints out useful information to proceed further (Note that the docker hub id you provided will be in the instructions in place of deepu105 here). Go through the generated k8s files and familiarize yourself. Now we are ready. Let us build and push the docker images for our application. Follow the instructions above and build docker images in each of the application folders and then tag and push the images to your Docker hub account. Preparing AKS Cluster: Now that our applications are built and pushed its time for us to deploy them to AKS. But before that let‚Äôs make sure we have all the prerequisites ready. You will need the below tools.    kubectl: The command line tool to interact with Kubernetes. Install and configure it.     Azure CLI: The command line tool to interact with Azure. Install and log in with your Azure account(You can create a free account if you don‚Äôt have one already).  Once the tools are ready let us prepare our Kubernetes cluster. First, let us create a resource group. Run the below command. This will create a resource group named eCommerceCluster in US east location(You can use other Azure regions as well). 1$ az group create --name eCommerceCluster --location eastusNow let us create an AKS cluster on the resource group we just created. Run the below command to create a cluster named eCommerceCluster with two nodes(We would need some room to run all those containers). It also enables the Azure monitor on the cluster through the add-on specified. 123$ az aks create --resource-group eCommerceCluster \--name eCommerceCluster --node-count 2 \--enable-addons monitoring --generate-ssh-keysThis would take several minutes to complete hence be patient and have a coffee :) Did I emphasize on several minutes? Once it‚Äôs done you should see the cluster information printed out as JSON. Now, let us configure kubectl to connect to the AKS cluster we just created. This can be done automatically using the Azure CLI by running the below handy command. Note: Some Azure CLI commands might take a while to execute, especially if you are on a slow network, sometimes if the below commands seem stalled or if it is timed out, kill it and retry again. 1$ az aks get-credentials --resource-group eCommerceCluster --name eCommerceClusterVerify that we are able to connect to the cluster by running kubectl get nodes 1234$ kubectl get nodesNAME            STATUS  ROLES   AGE    VERSIONaks-nodepool1-34429729-0  Ready   agent   22m    v1. 9. 9aks-nodepool1-34429729-1  Ready   agent   22m    v1. 9. 9Deploying the application to AKS: Now that our cluster is ready, let us deploy our microservice stack to this cluster. We can deploy our application using the kubectl apply command for this we have to navigate to the k8s folder we created earlier and run the below commands in the same order 1234567$ kubectl apply -f registry$ kubectl apply -f invoice$ kubectl apply -f notification$ kubectl apply -f storeOr you could also just run the handy kubectl-apply. sh script generated which runs the above. So we are deploying the JHipster Registry first as it is required for other services, followed by the microservices and finally our gateway(store). If you get a timeout during any of these, as I did, just try the command again. Though the services get created fast, the actual applications might not be up and running yet, give the entire thing a minute or two to start. Now run kubectl get pods to see the status of our containers. 1234567891011$ kubectl get pods -wNAME                  READY STATUS invoice-5ffb46d944-h8x42        1/1  Runninginvoice-mysql-66bc4b7874-p7ghk     1/1  Runningjhipster-registry-0           1/1  Runningjhipster-registry-1           1/1  Runningnotification-76847b7667-d7xjb      1/1  Runningnotification-mongodb-6db986b556-8bw8z  1/1  Runningstore-8dc5cd6f7-s2dpx          1/1  Runningstore-mysql-779d66685d-tmkqd      1/1  RunningNote: I have removed some info for brevity in the above output. Wait until all the containers are in Running status. Once the containers are running we can run the kubectl get service command to get the external IP for the application. 1234$ kubectl get service storeNAME  TYPE     CLUSTER-IP  EXTERNAL-IP  PORT(S)     AGEstore LoadBalancer 10. 0. 189. 145 40. 117. 140. 228 8080:30143/TCP 18mIn this case, the external IP for our gateway application is 40. 117. 140. 228 running on port 8080. Let us open it up in a web browser. The Gateway application login page The JHipster registry is deployed as a headless service by default. If we need to access the registry we need to create a secondary service with a Load Balancer. Run the below command to expose the second service. 1$ kubectl expose service jhipster-registry --type=LoadBalancer --name=exposed-registryNow run the kubectl get service command to get the IP. 1234$ kubectl get service exposed-registryNAME       TYPE     CLUSTER-IP  EXTERNAL-IP  PORT(S)exposed-registry LoadBalancer 10. 0. 107. 121 104. 211. 15. 142 8761:32628/TCPVisit the URL in a browser to see the registry in action JHipster Registry home page We can now scale any of our services by simply running kubectl scale command. For example, let us scale our Invoice service. 1$ kubectl scale --replicas=2 deployment/invoiceNow we can visit the Eureka -&gt; Instances on our Registry and see that the Invoice service has two instances. JHipster Registry instances page Running kubectl get pods will also show you the new instance. 123456789101112$ kubectl get pods NAME                 READY STATUS  AGEinvoice-5ffb46d944-g8j6j       1/1  Running 4minvoice-5ffb46d944-h8x42       1/1  Running 2hinvoice-mysql-66bc4b7874-p7ghk    1/1  Running 2hjhipster-registry-0          1/1  Running 2hjhipster-registry-1          1/1  Running 2hnotification-76847b7667-d7xjb     1/1  Running 2hnotification-mongodb-6db986b556-8bw8z 1/1  Running 2hstore-8dc5cd6f7-s2dpx         1/1  Running 2hstore-mysql-779d66685d-tmkqd     1/1  Running 2hThat is it, we have successfully got our application deployed to AKS and scaled our service on demand. Cleanup: Once you are done its always a good idea to clean up especially since we don‚Äôt want to keep unnecessary resources that might eat up our free credits on Azure. Let us delete the cluster from AKS and related resources created by deleting the entire resource group. 1$ az group delete --name eCommerceCluster --yes --no-waitCluster related activities like creation/update/deletion could take several minutes on AKS so we have to be patient again here. Conclusion: Kubernetes is definitely the best way to deploy microservice applications to production but creating and managing Kubernetes clusters itself is not an easy task, but Kubernetes services like GKE and AKS makes it a cakewalk. In my personal experience, the Kubernetes service from Google(GKE) and Azure(AKS) are by far the best in terms of ease of use and available tooling. These services provide very handy command line tools which work nicely together with kubectl to provide a very nice experience. They also have nice UI portals if you are not a fan of the CLI. JHipster provides a great Kubernetes setup to start with which you can further tweak as per your needs and platform. In upcoming posts, we will look at more services like GKE(Google), EKS(Amazon) and Openshift(RedHat) To learn more about JHipster, check out my book ‚ÄúFull Stack Development with JHipster‚Äù on Amazon and Packt. If you like JHipster don‚Äôt forget to give it a star on Github. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. My other related posts:    Create full Microservice stack using JHipster Domain Language under 30 minutes     JHipster microservices with Istio service mesh on Kubernetes  Originally published in Medium on Oct 01, 2018 Also published on Dev. to "
    }, {
    "id": 37,
    "url": "/create-full-microservice-stack-using-j-hipster-domain-language-under-30-minutes/",
    "title": "Create full Microservice stack using JHipster Domain Language under 30 minutes",
    "body": "2018/09/22 - It‚Äôs been quite a while since I wrote a blog, I did a few some years ago but never really continued writing. So when I decided to start writing again, I didn‚Äôt have to think a lot about a topic as it was very obvious ‚Äî JHipster. JHipster is a development platform for Java web applications and microservices development. If you are a JVM developer you might have already heard about JHipster. If not, well, you are missing out on a lot and I highly recommend you check it out. You can also check out my book ‚ÄúFull Stack Development with JHipster‚Äù on Amazon and Packt to learn about JHipster. I have been working on JHipster from April 2015 and the coolest feature that I got to implement so far is definitely multiple applications generation using JDL. This feature is available in the latest version of JHipster. If you are not familiar with JDL, I recommend you to check out the docs at https://www. jhipster. tech/jdl/ The E-Commerce application: So let us see how we can create a microservice stack using JHipster. We will build an e-commerce store today. The stack includes-    Service discovery using JHipster Registry, a Spring boot application that packs Eureka server and Spring cloud config server.     API management and Gateway using Spring Boot, Netflix Zuul, ReactJS, and Swagger.     Microservices using Spring Boot.     Monitoring using JHipster Console which is made of the Elastic stack(ELK) and Zipkin.  Microservice application architecture The Gateway routes incoming requests to two microservices, Invoice application, and Notification application. Requirements: In order to follow this tutorial, you would need a recent version of Docker, Docker-compose, NodeJS and Java installed on your computer. The below are the versions I have installed(Update: With JHipster 6+ you can use Java 11 &amp; 12). 12345678910111213$ docker -v                                                            Docker version 18. 06. 1-ce, build e68fc7a$ docker-compose -v                docker-compose version 1. 20. 1, build 5d8c71b$ node -v        v8. 11. 4$ java -version     openjdk version  1. 8. 0_212 OpenJDK Runtime Environment (Zulu 8. 38. 0. 13-CA-linux64) (build 1. 8. 0_212-b04)OpenJDK 64-Bit Server VM (Zulu 8. 38. 0. 13-CA-linux64) (build 25. 212-b04, mixed mode)First, install the latest version of JHipster 1$ npm install generator-jhipster -gVerify that you have version 5. 3. 4 or above by running 1$ jhipster --versionCreating the JDL: Now let us create our JDL. Head over to the JDL Studio or your favorite IDE/Editor(You can use JHipster IDE plugin if you like). First, let us define our applications. We will start with the Gateway 123456789101112131415application { config {  baseName store,  applicationType gateway,  packageName com. jhipster. demo. store,  serviceDiscoveryType eureka,  authenticationType jwt,  prodDatabaseType mysql,  cacheProvider hazelcast,  buildTool gradle,  clientFramework react,  testFrameworks [protractor] } entities *}Most of the options are self-explanatory, we are building an application named Store of type Gateway with JWT authentication and Eureka-based service discovery. The application uses a MySQL database and Hazelcast for the cache. It‚Äôs built using Gradle. For the client-side, it uses React and Sass. It also has Protractor for end-to-end testing. At the end of the definition you can see entities *, we will come to this later. Now let us define our Invoice microservice 12345678910111213application { config {  baseName invoice,  applicationType microservice,  packageName com. jhipster. demo. invoice,  serviceDiscoveryType eureka,  authenticationType jwt,  prodDatabaseType mysql,  buildTool gradle,  serverPort 8081 } entities Invoice, Shipment}It follows similar options like our Gateway and since it is microservice it doesn‚Äôt define any client-side options and also skips user management as it will be handled by the Gateway. Additionally, we have also mentioned a custom port 8081 since we do not want this application to conflict with the default port 8080 used by the Gateway. Now let us define the second microservice, the Notification application 123456789101112131415application { config {  baseName notification,  applicationType microservice,  packageName com. jhipster. demo. notification,  serviceDiscoveryType eureka,  authenticationType jwt,  databaseType mongodb,  cacheProvider no,  enableHibernateCache false,  buildTool gradle,  serverPort 8082 } entities Notification}This application follows many options similar to the Gateway and Invoice application but instead of using MySQL it uses MongoDB as its database and also disables cache. Now that our application definitions are done, we will proceed to define our entity model. For our Gateway store application, let us define the below entities and enums 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071/** Product sold by the Online store */entity Product {  name String required  description String  price BigDecimal required min(0)  size Size required  image ImageBlob}enum Size {  S, M, L, XL, XXL}entity ProductCategory {  name String required  description String}entity Customer {  firstName String required  lastName String required  gender Gender required  email String required pattern(/^[^@\s]+@[^@\s]+\. [^@\s]+$/)  phone String required  addressLine1 String required  addressLine2 String  city String required  country String required}enum Gender {  MALE, FEMALE, OTHER}entity ProductOrder {  placedDate Instant required  status OrderStatus required  code String required  invoiceId Long}enum OrderStatus {  COMPLETED, PENDING, CANCELLED}entity OrderItem {  quantity Integer required min(0)  totalPrice BigDecimal required min(0)  status OrderItemStatus required}enum OrderItemStatus {  AVAILABLE, OUT_OF_STOCK, BACK_ORDER}relationship OneToOne {  Customer{user(login) required} to User}relationship ManyToOne {  OrderItem{product(name) required} to Product}relationship OneToMany {  Customer{order} to ProductOrder{customer(email) required},  ProductOrder{orderItem} to OrderItem{order(code) required},  ProductCategory{product} to Product{productCategory(name)}}service Product, ProductCategory, Customer, ProductOrder, OrderItem with serviceClasspaginate Product, Customer, ProductOrder, OrderItem with paginationThe JDL defines the entities, enums, the relationship between entities and options like pagination and service layer. The entity field definition follows the syntax 123entity &lt;entity name&gt; { &lt;field name&gt; &lt;type&gt; [&lt;validation&gt;*]}The relationship definition follows the syntax 12345relationship (OneToMany | ManyToOne | OneToOne | ManyToMany) {  &lt;from entity&gt;[{&lt;relationship name&gt;[(&lt;display field&gt;)]}]   to   &lt;to entity&gt;[{&lt;relationship name&gt;[(&lt;display field&gt;)]}]}Refer the JDL docs for full DSL reference. The Invoice microservice application has the following entities 12345678910111213141516171819202122232425262728293031entity Invoice {  code String required  date Instant required  details String  status InvoiceStatus required  paymentMethod PaymentMethod required  paymentDate Instant required  paymentAmount BigDecimal required}enum InvoiceStatus {  PAID, ISSUED, CANCELLED}entity Shipment {  trackingCode String  date Instant required  details String}enum PaymentMethod {  CREDIT_CARD, CASH_ON_DELIVERY, PAYPAL}relationship OneToMany {  Invoice{shipment} to Shipment{invoice(code) required}}service Invoice, Shipment with serviceClasspaginate Invoice, Shipment with paginationmicroservice Invoice, Shipment with invoicePay attention to the last microservice option declared here, it specifies that these entities belong to the microservice named invoice so that our Gateway knows where to route requests for these entities. Now let us see the entities for the Notification microservice application 1234567891011121314entity Notification {  date Instant required  details String  sentDate Instant required  format NotificationType required  userId Long required  productId Long required}enum NotificationType {  EMAIL, SMS, PARCEL}microservice Notification with notificationNow let us go back to the entities keyword we used in our application definitions. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061application { config {  . . .  } entities *}application { config {  . . .  } entities Invoice, Shipment}application { config {  . . .  } entities Notification}/* Entities for Store Gateway */entity Product {  . . . }entity ProductCategory {  . . . }entity Customer {  . . . }entity ProductOrder {  . . . }entity OrderItem {  . . . }microservice Invoice, Shipment with invoice/* Entities for Invoice microservice */entity Invoice {  . . . }entity Shipment {  . . . }/* Entities for notification microservice */entity Notification {  . . . }microservice Notification with notificationHere we instruct the store gateway application that it should contain all the entities defined in the JDL and the gateway will know to skip server-side code for the entities that belong to another microservice and hence will only generate the client-side code for those, here namely Invoice, Shipment, and Notification. We also instruct the Invoice application and Notification application to include its entities. Generating the applications: Create a folder where we want to create our microservice stack. 1$ mkdir ecommerce &amp;&amp; cd ecommerceNow, let us put everything together into a JDL file. Let us call it app. jdl and save it into this folder. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169application { config {  baseName store,  applicationType gateway,  packageName com. jhipster. demo. store,  serviceDiscoveryType eureka,  authenticationType jwt,  prodDatabaseType mysql,  cacheProvider hazelcast,  buildTool gradle,  clientFramework react,  testFrameworks [protractor] } entities *}application { config {  baseName invoice,  applicationType microservice,  packageName com. jhipster. demo. invoice,  serviceDiscoveryType eureka,  authenticationType jwt,  prodDatabaseType mysql,  buildTool gradle,  serverPort 8081 } entities Invoice, Shipment}application { config {  baseName notification,  applicationType microservice,  packageName com. jhipster. demo. notification,  serviceDiscoveryType eureka,  authenticationType jwt,  databaseType mongodb,  cacheProvider no,  enableHibernateCache false,  buildTool gradle,  serverPort 8082 } entities Notification}/* Entities for Store Gateway *//** Product sold by the Online store */entity Product {  name String required  description String  price BigDecimal required min(0)  size Size required  image ImageBlob}enum Size {  S, M, L, XL, XXL}entity ProductCategory {  name String required  description String}entity Customer {  firstName String required  lastName String required  gender Gender required  email String required pattern(/^[^@\s]+@[^@\s]+\. [^@\s]+$/)  phone String required  addressLine1 String required  addressLine2 String  city String required  country String required}enum Gender {  MALE, FEMALE, OTHER}entity ProductOrder {  placedDate Instant required  status OrderStatus required  code String required  invoiceId Long}enum OrderStatus {  COMPLETED, PENDING, CANCELLED}entity OrderItem {  quantity Integer required min(0)  totalPrice BigDecimal required min(0)  status OrderItemStatus required}enum OrderItemStatus {  AVAILABLE, OUT_OF_STOCK, BACK_ORDER}relationship OneToOne {  Customer{user(login) required} to User}relationship ManyToOne { OrderItem{product(name) required} to Product}relationship OneToMany {  Customer{order} to ProductOrder{customer(email) required},  ProductOrder{orderItem} to OrderItem{order(code) required} ,  ProductCategory{product} to Product{productCategory(name)}}service Product, ProductCategory, Customer, ProductOrder, OrderItem with serviceClasspaginate Product, Customer, ProductOrder, OrderItem with pagination/* Entities for Invoice microservice */entity Invoice {  code String required  date Instant required  details String  status InvoiceStatus required  paymentMethod PaymentMethod required  paymentDate Instant required  paymentAmount BigDecimal required}enum InvoiceStatus {  PAID, ISSUED, CANCELLED}entity Shipment {  trackingCode String  date Instant required  details String}enum PaymentMethod {  CREDIT_CARD, CASH_ON_DELIVERY, PAYPAL}relationship OneToMany {  Invoice{shipment} to Shipment{invoice(code) required}}service Invoice, Shipment with serviceClasspaginate Invoice, Shipment with paginationmicroservice Invoice, Shipment with invoice/* Entities for notification microservice */entity Notification {  date Instant required  details String  sentDate Instant required  format NotificationType required  userId Long required  productId Long required}enum NotificationType {  EMAIL, SMS, PARCEL}microservice Notification with notificationNow let us invoke JHipster CLI to import this file 1$ jhipster import-jdl app. jdlThis will create the store, invoice and notification folders and will do the below in each of the folders    Generate the appropriate application and entities configuration.     Generate the application and entities source code based on the configurations.     Install the NPM dependencies for the application.  Once the process is complete you should see the below on your console 123456789Entity Product generated successfully. Entity ProductCategory generated successfully. Entity Customer generated successfully. Entity ProductOrder generated successfully. Entity OrderItem generated successfully. Entity Invoice generated successfully. Entity Shipment generated successfully. Entity Notification generated successfully. Congratulations, JHipster execution is complete!Walk around the generated code to familiarize yourself. Running the applications with Docker: Now that our applications are created its time to test them locally using Docker. To do this first let us generate some docker compose configurations using JHipster. Create a new folder inside the ecommerce folder and run the JHipster docker-compose command 12$ mkdir docker-compose &amp;&amp; cd docker-compose$ jhipster docker-composeIt will prompt you with a few questions, choose the answers as highlighted below 12345678910111213141516171819202122üê≥ Welcome to the JHipster Docker Compose Sub-Generator üê≥Files will be generated in folder: /home/deepu/workspace/temp/ecommerce/docker-compose‚úî Docker is installed? Which *type* of application would you like to deploy? Microservice application? Which *type* of gateway would you like to use? JHipster gateway based on Netflix Zuul? Enter the root directory where your gateway(s) and microservices are located . . /3 applications found at /home/deepu/workspace/temp/ecommerce/? Which applications do you want to include in your configuration? invoice, notification, store? Which applications do you want to use with clustered databases (only available with MongoDB and Couchbase)? ? Do you want to setup monitoring for your applications ? Yes, for logs and metrics with the JHipster Console (based on ELK and Zipkin)? You have selected the JHipster Console which is based on the ELK stack and additional technologies, which one do you want to use ? Zipkin, for distributed tracing (only compatible with JHipster &gt;= v4. 2. 0)JHipster registry detected as the service discovery and configuration provider used by your apps? Enter the admin password used to secure the JHipster Registry? adminThis will generate all the required docker-compose configurations for the stack and will also print out further instructions to build the docker images. Note: In the latest JHipster versions we migrated to using Jib for creating Docker images. This is a huge improvement over the Docker Maven plugin that we were using, as a result the command to create an image has changed to . /gradlew -Pprod bootWar jibDockerBuild. 12345Docker Compose configuration generated with missing images!To generate the missing Docker image(s), please run: . /gradlew -Pprod bootWar jibDockerBuild in /home/deepu/workspace/temp/ecommerce/invoice . /gradlew -Pprod bootWar jibDockerBuild in /home/deepu/workspace/temp/ecommerce/notification . /gradlew -Pprod bootWar jibDockerBuild in /home/deepu/workspace/temp/ecommerce/storeFollow the instructions and build the docker images. Once all 3 images are built run the below command from the docker-compose folder to fire everything up. 1$ docker-compose up -dOnce the containers start you can stream the logs using below command 1$ docker-compose logs -fNow point your favorite browser to http://localhost:8080/ and see the E-Commerce microservice application in action. Gateway application(Store) You can see the JHipster registry in action at http://localhost:8761/ JHipster Registry And finally the JHipster console at http://localhost:5601/ JHipster Console- Kibana dashboard Once you are done playing around, you can shut everything down by running the below command on the docker-compose folder 1docker-compose downHope you had fun creating microservices using JHipster. To learn how to convert a JHipster monolith to microservices check out my book ‚ÄúFull Stack Development with JHipster‚Äù on Amazon and Packt. In the coming weeks, I‚Äôll write some posts about deploying this microservice stack to various cloud providers like GCP, Azure, AWS, Heroku and so on. If you like JHipster don‚Äôt forget to give it a star on Github. If you like this article, please leave a like or a comment. You can follow me on Twitter and LinkedIn. My other related posts:    Deploying JHipster Microservices on Azure Kubernetes Service (AKS)     JHipster microservices with Istio service mesh on Kubernetes  Originally published in Medium on Sep 22, 2018 Also published on Dev. to "
    }];

var idx = lunr(function () {
    this.ref('id')
    this.field('title')
    this.field('body')

    documents.forEach(function (doc) {
        this.add(doc)
    }, this)
});
function lunr_search(term) {
    document.getElementById('lunrsearchresults').innerHTML = '<ul></ul>';
    if(term) {
        document.getElementById('lunrsearchresults').innerHTML = "<p>Search results for '" + term + "'</p>" + document.getElementById('lunrsearchresults').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>No results found...</li>";
        }
    }
    return false;
}

function lunr_search(term) {
    $('#lunrsearchresults').show( 400 );
    $( "body" ).addClass( "modal-open" );
    
    document.getElementById('lunrsearchresults').innerHTML = '<div id="resultsmodal" class="modal fade show d-block"  tabindex="-1" role="dialog" aria-labelledby="resultsmodal"> <div class="modal-dialog shadow-lg" role="document"> <div class="modal-content"> <div class="modal-header" id="modtit"> <button type="button" class="close" id="btnx" data-dismiss="modal" aria-label="Close"> &times; </button> </div> <div class="modal-body"> <ul class="mb-0"> </ul>    </div> <div class="modal-footer"><button id="btnx" type="button" class="btn btn-danger btn-sm" data-dismiss="modal">Close</button></div></div> </div></div>';
    if(term) {
        document.getElementById('modtit').innerHTML = "<h5 class='modal-title'>Search results for '" + term + "'</h5>" + document.getElementById('modtit').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><small><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></small></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>Sorry, no results found. Close & try a different search!</li>";
        }
    }
    return false;
}
    
$(function() {
    $("#lunrsearchresults").on('click', '#btnx', function () {
        $('#lunrsearchresults').hide( 5 );
        $( "body" ).removeClass( "modal-open" );
    });
});